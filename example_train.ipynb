{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1024 and xlm-roberta-longformer-16384 and dataset-0516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fengxai.ml.hf_sagemaker import FxHfSagemaker\n",
    "\n",
    "fxMl=FxHfSagemaker(\n",
    "    # 设定 sagemaker 训练机器\n",
    "    sagemaker_config={\n",
    "        # 'instance_type': 'ml.p3.8xlarge',\n",
    "        # 'instance_type': 'ml.p3.16xlarge',\n",
    "        'instance_type': 'ml.p3dn.24xlarge',\n",
    "        'instance_count': 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "fxMl.play(\n",
    "    config={\n",
    "        # 训练类型，目前只有两种训练类型 BERT and LLAMA\n",
    "        'training_model': 'BERT',\n",
    "        'clone_repo': 'rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-0516',\n",
    "        'model_name_or_path':'severinsimmler/xlm-roberta-longformer-base-16384',\n",
    "        'dataset_name': 'rjx/ai-and-human-0516',\n",
    "        'model_max_length': 1024,\n",
    "        'task_type': 'text-generation',\n",
    "        # 'max_train_samples': 20,\n",
    "        # 'max_eval_samples': 4,\n",
    "        # 'max_test_samples': 4,\n",
    "    }, \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1024 and xlm-roberta-longformer-16384 and dataset-0522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fengxai.ml.hf_sagemaker import FxHfSagemaker\n",
    "\n",
    "fxMl=FxHfSagemaker(\n",
    "    # 设定 sagemaker 训练机器\n",
    "    sagemaker_config={\n",
    "        # 'instance_type': 'ml.p3.8xlarge',\n",
    "        # 'instance_type': 'ml.p3.16xlarge',\n",
    "        'instance_type': 'ml.p3dn.24xlarge',\n",
    "        'instance_count': 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "fxMl.play(\n",
    "    config={\n",
    "        # 训练类型，目前只有两种训练类型 BERT and LLAMA\n",
    "        'training_model': 'BERT',\n",
    "        'clone_repo': 'rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-0522',\n",
    "        'model_name_or_path':'severinsimmler/xlm-roberta-longformer-base-16384',\n",
    "        'dataset_name': 'rjx/ai-and-human-0522',\n",
    "        'model_max_length': 1024,\n",
    "        'task_type': 'text-generation',\n",
    "        # 'max_train_samples': 20,\n",
    "        # 'max_eval_samples': 4,\n",
    "        # 'max_test_samples': 4,\n",
    "    }, \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1024 and xlm-roberta-longformer-16384 and dataset-en-0523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fengxai.ml.hf_sagemaker import FxHfSagemaker\n",
    "\n",
    "fxMl=FxHfSagemaker(\n",
    "    # 设定 sagemaker 训练机器\n",
    "    sagemaker_config={\n",
    "        # 'instance_type': 'ml.p3.8xlarge',\n",
    "        # 'instance_type': 'ml.p3.16xlarge',\n",
    "        'instance_type': 'ml.p3dn.24xlarge',\n",
    "        'instance_count': 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "fxMl.play(\n",
    "    config={\n",
    "        # 训练类型，目前只有两种训练类型 BERT and LLAMA\n",
    "        'training_model': 'BERT',\n",
    "        'clone_repo': 'rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-en-0523',\n",
    "        'model_name_or_path':'severinsimmler/xlm-roberta-longformer-base-16384',\n",
    "        'dataset_name': 'rjx/ai-and-human-en-0523',\n",
    "        'model_max_length': 1024,\n",
    "        'task_type': 'text-generation',\n",
    "        'index_output': 'labels',\n",
    "        # 'max_train_samples': 20,\n",
    "        # 'max_eval_samples': 4,\n",
    "        # 'max_test_samples': 4,\n",
    "    }, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file fengxai/config/accelerator/local_train.yaml auto_train.py \\\n",
    "    --training_model BERT \\\n",
    "    --clone_repo rjx/test-v1 \\\n",
    "    --model_name_or_path bert-base-chinese \\\n",
    "    --dataset_name rjx/ai-and-human-20 \\\n",
    "    --task_type text-generation \\\n",
    "    --index_output labels \\\n",
    "    --do_save False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20230619 训练的时候评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "Configuring Amazon SageMaker environment\n",
      "Converting Arguments to Hyperparameters\n",
      "Creating Estimator\n",
      "Using provided s3_resource\n",
      "2023-06-19 08:32:16 Starting - Starting the training job...\n",
      "2023-06-19 08:32:31 Starting - Preparing the instances for training......\n",
      "2023-06-19 08:33:47 Downloading - Downloading input data\n",
      "2023-06-19 08:33:47 Training - Downloading the training image..................\n",
      "2023-06-19 08:37:18 Training - Training image download completed. Training in progress....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-06-19 08:37:46,887 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-06-19 08:37:46,901 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-06-19 08:37:46,911 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-06-19 08:37:46,913 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-06-19 08:37:47,516 sagemaker-training-toolkit INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: appdirs in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.4.4)\u001b[0m\n",
      "\u001b[34mCollecting loralib\u001b[0m\n",
      "\u001b[34mDownloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting black\u001b[0m\n",
      "\u001b[34mDownloading black-23.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 32.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.9.0)\u001b[0m\n",
      "\u001b[34mCollecting fire\u001b[0m\n",
      "\u001b[34mDownloading fire-0.5.0.tar.gz (88 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.3/88.3 kB 29.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.39.0-py3-none-any.whl (92.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.2/92.2 MB 32.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft\u001b[0m\n",
      "\u001b[34mDownloading peft-0.3.0-py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 20.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mERROR: Could not find a version that satisfies the requirement accelerate==0.21.0 (from versions: 0.0.1, 0.1.0, 0.2.0, 0.2.1, 0.3.0, 0.4.0, 0.5.0, 0.5.1, 0.6.0, 0.6.1, 0.6.2, 0.7.0, 0.7.1, 0.8.0, 0.9.0, 0.10.0, 0.11.0, 0.12.0, 0.13.0, 0.13.1, 0.13.2, 0.14.0, 0.15.0, 0.16.0, 0.17.0, 0.17.1, 0.18.0, 0.19.0, 0.20.0, 0.20.1, 0.20.2, 0.20.3)\u001b[0m\n",
      "\u001b[34mERROR: No matching distribution found for accelerate==0.21.0\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 23.1.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-06-19 08:37:50,069 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-06-19 08:37:50,069 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-06-19 08:37:50,070 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2023-06-19 08:37:50,070 sagemaker-training-toolkit ERROR    InstallModuleError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.9 -m pip install . -r requirements.txt\"\u001b[0m\n",
      "\u001b[34m2023-06-19 08:37:50,070 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2023-06-19 08:38:05 Uploading - Uploading generated training model\n",
      "2023-06-19 08:38:05 Failed - Training job failed\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accel\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33merate/commands/\u001b[0m\u001b[1;33maccelerate_cli.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accel\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33merate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m916\u001b[0m in \u001b[92mlaunch_command\u001b[0m                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m913 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m914 \u001b[0m\u001b[2m│   │   │   \u001b[0mtpu_launcher(args)                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m915 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m defaults \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m defaults.compute_environment == Comp \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m916 \u001b[2m│   │   \u001b[0msagemaker_launcher(defaults, args)                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m917 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m918 \u001b[0m\u001b[2m│   │   \u001b[0msimple_launcher(args)                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m919 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accel\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33merate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m764\u001b[0m in \u001b[92msagemaker_launcher\u001b[0m                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m761 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m762 \u001b[0m\u001b[2m│   \u001b[0mhuggingface_estimator = HuggingFace(**args)                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m763 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m764 \u001b[2m│   \u001b[0mhuggingface_estimator.fit(inputs=sagemaker_inputs)                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m765 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mYou can find your model data at: \u001b[0m\u001b[33m{\u001b[0mhuggingface_estimator.mo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m766 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m767 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/workflow/\u001b[0m\u001b[1;33mpipeline_context.py\u001b[0m:\u001b[94m300\u001b[0m in \u001b[92mwrapper\u001b[0m                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m297 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m _StepArguments(retrieve_caller_name(self_instance), \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m300 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m run_func(*args, **kwargs)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m301 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m302 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m303 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m1221\u001b[0m in \u001b[92mfit\u001b[0m                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1218 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.latest_training_job = _TrainingJob.start_new(\u001b[96mself\u001b[0m, input \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1219 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.jobs.append(\u001b[96mself\u001b[0m.latest_training_job)                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1220 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m wait:                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1221 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.latest_training_job.wait(logs=logs)                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1222 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1223 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_compilation_job_name\u001b[0m(\u001b[96mself\u001b[0m):                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1224 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Placeholder docstring\"\"\"\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m2367\u001b[0m in \u001b[92mwait\u001b[0m                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2364 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogs = log_string_map[logs]                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2365 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# If logs are requested, call logs_for_jobs.\u001b[0m                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2366 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m logs != \u001b[33m\"\u001b[0m\u001b[33mNone\u001b[0m\u001b[33m\"\u001b[0m:                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2367 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.logs_for_job(\u001b[96mself\u001b[0m.job_name, wait=\u001b[94mT\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.wait_for_job(\u001b[96mself\u001b[0m.job_name)        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2370 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m4665\u001b[0m in \u001b[92mlogs_for_job\u001b[0m                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4662 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mexceptions.CapacityError: If the training job fails with \u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4663 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mexceptions.UnexpectedStatusException: If waiting and the \u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4664 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m4665 \u001b[2m│   │   \u001b[0m_logs_for_job(\u001b[96mself\u001b[0m.boto_session, job_name, wait, poll, log_ty \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4666 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4667 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mlogs_for_processing_job\u001b[0m(\u001b[96mself\u001b[0m, job_name, wait=\u001b[94mFalse\u001b[0m, poll=\u001b[94m10\u001b[0m): \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4668 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Display logs for a given processing job, optionally tailin\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m6527\u001b[0m in \u001b[92m_logs_for_job\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6524 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlast_profiler_rule_statuses = profiler_rule_statuses  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6525 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6526 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m wait:                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m6527 \u001b[2m│   │   \u001b[0m_check_job_status(job_name, description, \u001b[33m\"\u001b[0m\u001b[33mTrainingJobStatus\u001b[0m\u001b[33m\"\u001b[0m) \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6528 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m dot:                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6529 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m()                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6530 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Customers are not billed for hardware provisioning, so bill\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m6580\u001b[0m in \u001b[92m_check_job_status\u001b[0m                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6577 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6578 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mactual_status=status,                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6579 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m6580 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m exceptions.UnexpectedStatusException(                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6581 \u001b[0m\u001b[2m│   │   │   \u001b[0mmessage=message,                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6582 \u001b[0m\u001b[2m│   │   │   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6583 \u001b[0m\u001b[2m│   │   │   \u001b[0mactual_status=status,                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mUnexpectedStatusException: \u001b[0mError for Training job \n",
      "example-training-v1-\u001b[1;36m2023\u001b[0m-\u001b[1;92m06-19-08-32-05-55\u001b[0m4: Failed. Reason: AlgorithmError: \n",
      "InstallModuleError:\n",
      "ExitCode \u001b[1;36m1\u001b[0m\n",
      "ErrorMessage \u001b[32m\"\"\u001b[0m\n",
      "Command \u001b[32m\"/opt/conda/bin/python3.9 -m pip install . -r requirements.txt\"\u001b[0m, exit \n",
      "code: \u001b[1;36m1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file fengxai/config/accelerator/sagemaker_train_gpu.yaml auto_train.py \\\n",
    "    --training_model BERT \\\n",
    "    --clone_repo rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-0522 \\\n",
    "    --model_name_or_path severinsimmler/xlm-roberta-longformer-base-16384 \\\n",
    "    --dataset_name rjx/ai-and-human-0522 \\\n",
    "    --model_max_length 512 \\\n",
    "    --task_type text-generation \\\n",
    "    --metric_type seqeval \\\n",
    "    --index_output labels \\\n",
    "    --wandb_project rjxai-cls-zh-v1-test \\\n",
    "    --max_train_samples 20 \\\n",
    "    --max_eval_samples 4 \\\n",
    "    --max_test_samples 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "Configuring Amazon SageMaker environment\n",
      "Converting Arguments to Hyperparameters\n",
      "Creating Estimator\n",
      "Using provided s3_resource\n",
      "2023-06-19 08:22:50 Starting - Starting the training job...\n",
      "2023-06-19 08:23:04 Starting - Preparing the instances for training......\n",
      "2023-06-19 08:24:25 Downloading - Downloading input data\n",
      "2023-06-19 08:24:25 Training - Downloading the training image...............\n",
      "2023-06-19 08:27:11 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-06-19 08:27:41,975 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-06-19 08:27:41,990 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-06-19 08:27:41,999 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-06-19 08:27:42,001 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-06-19 08:27:42,600 sagemaker-training-toolkit INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: appdirs in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.4.4)\u001b[0m\n",
      "\u001b[34mCollecting loralib\u001b[0m\n",
      "\u001b[34mDownloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting black\u001b[0m\n",
      "\u001b[34mDownloading black-23.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 26.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.9.0)\u001b[0m\n",
      "\u001b[34mCollecting fire\u001b[0m\n",
      "\u001b[34mDownloading fire-0.5.0.tar.gz (88 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.3/88.3 kB 28.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.39.0-py3-none-any.whl (92.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.2/92.2 MB 28.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft\u001b[0m\n",
      "\u001b[34mDownloading peft-0.3.0-py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 17.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (0.16.0)\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.30.1\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.2/7.2 MB 117.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (0.1.97)\u001b[0m\n",
      "\u001b[34mCollecting gradio\u001b[0m\n",
      "\u001b[34mDownloading gradio-3.35.2-py3-none-any.whl (19.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.7/19.7 MB 82.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting wandb\u001b[0m\n",
      "\u001b[34mDownloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 108.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting nvidia-ml-py3\u001b[0m\n",
      "\u001b[34mDownloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting pytest\u001b[0m\n",
      "\u001b[34mDownloading pytest-7.3.2-py3-none-any.whl (320 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 320.9/320.9 kB 54.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting evaluate\u001b[0m\n",
      "\u001b[34mDownloading evaluate-0.4.0-py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.4/81.4 kB 26.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting graphviz\u001b[0m\n",
      "\u001b[34mDownloading graphviz-0.20.1-py3-none-any.whl (47 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 14.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard\u001b[0m\n",
      "\u001b[34mDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 118.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting trl\u001b[0m\n",
      "\u001b[34mDownloading trl-0.4.4-py3-none-any.whl (68 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 68.4/68.4 kB 14.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting seqeval\u001b[0m\n",
      "\u001b[34mDownloading seqeval-1.2.2.tar.gz (43 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 15.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.1->-r requirements.txt (line 10)) (3.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.1->-r requirements.txt (line 10)) (2.28.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.1->-r requirements.txt (line 10)) (0.13.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.1->-r requirements.txt (line 10)) (4.64.1)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.1\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 94.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.14.1\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 236.8/236.8 kB 49.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.1->-r requirements.txt (line 10)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.1->-r requirements.txt (line 10)) (23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.1->-r requirements.txt (line 10)) (2022.10.31)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.1->-r requirements.txt (line 10)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting mypy-extensions>=0.4.3\u001b[0m\n",
      "\u001b[34mDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting tomli>=1.1.0\u001b[0m\n",
      "\u001b[34mUsing cached tomli-2.0.1-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.9/site-packages (from black->-r requirements.txt (line 3)) (4.4.0)\u001b[0m\n",
      "\u001b[34mCollecting pathspec>=0.9.0\u001b[0m\n",
      "\u001b[34mDownloading pathspec-0.11.1-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.9/site-packages (from black->-r requirements.txt (line 3)) (8.1.2)\u001b[0m\n",
      "\u001b[34mCollecting platformdirs>=2\u001b[0m\n",
      "\u001b[34mDownloading platformdirs-3.6.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ipython>=7.8.0 in /opt/conda/lib/python3.9/site-packages (from black->-r requirements.txt (line 3)) (8.10.0)\u001b[0m\n",
      "\u001b[34mCollecting tokenize-rt>=3.2.0\u001b[0m\n",
      "\u001b[34mDownloading tokenize_rt-5.1.0-py2.py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 5)) (11.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 5)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 5)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 5)) (3.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 5)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 5)) (1.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 5)) (2023.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 5)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from fire->-r requirements.txt (line 6)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting termcolor\u001b[0m\n",
      "\u001b[34mDownloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from peft->-r requirements.txt (line 8)) (5.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from peft->-r requirements.txt (line 8)) (1.13.1+cu117)\u001b[0m\n",
      "\u001b[34mCollecting aiofiles\u001b[0m\n",
      "\u001b[34mDownloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\u001b[0m\n",
      "\u001b[34mCollecting semantic-version\u001b[0m\n",
      "\u001b[34mDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments>=2.12.0 in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 12)) (2.14.0)\u001b[0m\n",
      "\u001b[34mCollecting ffmpy\u001b[0m\n",
      "\u001b[34mDownloading ffmpy-0.3.0.tar.gz (4.8 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 12)) (3.6.3)\u001b[0m\n",
      "\u001b[34mCollecting mdit-py-plugins<=0.3.3\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 15.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting markdown-it-py[linkify]>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.5/87.5 kB 25.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting python-multipart\u001b[0m\n",
      "\u001b[34mDownloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.7/45.7 kB 16.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 12)) (1.10.4)\u001b[0m\n",
      "\u001b[34mCollecting orjson\u001b[0m\n",
      "\u001b[34mDownloading orjson-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 136.9/136.9 kB 30.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting websockets>=10.0\u001b[0m\n",
      "\u001b[34mDownloading websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 129.7/129.7 kB 36.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting gradio-client>=0.2.7\u001b[0m\n",
      "\u001b[34mDownloading gradio_client-0.2.7-py3-none-any.whl (288 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 288.4/288.4 kB 53.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting uvicorn>=0.14.0\u001b[0m\n",
      "\u001b[34mDownloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 20.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting fastapi\u001b[0m\n",
      "\u001b[34mDownloading fastapi-0.97.0-py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.0/57.0 kB 17.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting httpx\u001b[0m\n",
      "\u001b[34mDownloading httpx-0.24.1-py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.4/75.4 kB 25.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markupsafe in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 12)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 12)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 12)) (9.4.0)\u001b[0m\n",
      "\u001b[34mCollecting altair>=4.2.0\u001b[0m\n",
      "\u001b[34mDownloading altair-5.0.1-py3-none-any.whl (471 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 471.5/471.5 kB 66.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pydub\u001b[0m\n",
      "\u001b[34mDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker-pycreds>=0.4.0\u001b[0m\n",
      "\u001b[34mDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting setproctitle\u001b[0m\n",
      "\u001b[34mDownloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 13)) (65.6.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 13)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting GitPython!=3.1.29,>=1.0.0\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.31-py3-none-any.whl (184 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 46.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pathtools\u001b[0m\n",
      "\u001b[34mDownloading pathtools-0.1.2.tar.gz (11 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting sentry-sdk>=1.0.0\u001b[0m\n",
      "\u001b[34mDownloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 206.7/206.7 kB 43.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.9/site-packages (from pytest->-r requirements.txt (line 15)) (1.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.9/site-packages (from pytest->-r requirements.txt (line 15)) (1.1.0)\u001b[0m\n",
      "\u001b[34mCollecting iniconfig\u001b[0m\n",
      "\u001b[34mDownloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34mDownloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 36.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 18)) (0.38.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 18)) (3.4.1)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.8.0,>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 118.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.20.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.5/181.5 kB 40.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.48.2\u001b[0m\n",
      "\u001b[34mDownloading grpcio-1.54.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 112.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 18)) (2.2.3)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<1.1,>=0.5\u001b[0m\n",
      "\u001b[34mDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.9/site-packages (from seqeval->-r requirements.txt (line 20)) (1.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 12)) (4.17.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: toolz in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 12)) (0.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.8.2)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.10-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 17.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 18)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 18)) (1.26.14)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 36.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 3)) (0.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: stack-data in /opt/conda/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 3)) (0.6.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 3)) (0.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 3)) (5.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 3)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /opt/conda/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 3)) (3.0.36)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 3)) (0.1.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 3)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 3)) (5.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 18)) (4.13.0)\u001b[0m\n",
      "\u001b[34mCollecting mdurl~=0.1\u001b[0m\n",
      "\u001b[34mDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting linkify-it-py<3,>=1\u001b[0m\n",
      "\u001b[34mDownloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting mdit-py-plugins<=0.3.3\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.4/50.4 kB 15.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.5/46.5 kB 13.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.7/43.7 kB 15.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.0/41.0 kB 13.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.0/41.0 kB 13.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mDownloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of markdown-it-py[linkify] to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting markdown-it-py[linkify]>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.5/84.5 kB 27.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->-r requirements.txt (line 5)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->-r requirements.txt (line 5)) (2022.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.30.1->-r requirements.txt (line 10)) (2022.12.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.30.1->-r requirements.txt (line 10)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 20)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 20)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 20)) (1.10.0)\u001b[0m\n",
      "\u001b[34mCollecting h11>=0.8\u001b[0m\n",
      "\u001b[34mDownloading h11-0.14.0-py3-none-any.whl (58 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 18.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting starlette<0.28.0,>=0.27.0\u001b[0m\n",
      "\u001b[34mDownloading starlette-0.27.0-py3-none-any.whl (66 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.0/67.0 kB 20.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting httpcore<0.18.0,>=0.15.0\u001b[0m\n",
      "\u001b[34mDownloading httpcore-0.17.2-py3-none-any.whl (72 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.5/72.5 kB 25.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting sniffio\u001b[0m\n",
      "\u001b[34mDownloading sniffio-1.3.0-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->gradio->-r requirements.txt (line 12)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->gradio->-r requirements.txt (line 12)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->gradio->-r requirements.txt (line 12)) (1.0.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->gradio->-r requirements.txt (line 12)) (4.38.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->gradio->-r requirements.txt (line 12)) (1.4.4)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mCollecting anyio<5.0,>=3.0\u001b[0m\n",
      "\u001b[34mDownloading anyio-3.7.0-py3-none-any.whl (80 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.9/80.9 kB 17.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 18)) (3.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.8.0->black->-r requirements.txt (line 3)) (0.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 12)) (0.19.3)\u001b[0m\n",
      "\u001b[34mCollecting uc-micro-py\u001b[0m\n",
      "\u001b[34mDownloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.8.0->black->-r requirements.txt (line 3)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=7.8.0->black->-r requirements.txt (line 3)) (0.2.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 18)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34mDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 36.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=7.8.0->black->-r requirements.txt (line 3)) (2.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pure-eval in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=7.8.0->black->-r requirements.txt (line 3)) (0.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=7.8.0->black->-r requirements.txt (line 3)) (1.2.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: assisted-intelligence, fire, nvidia-ml-py3, seqeval, ffmpy, pathtools\u001b[0m\n",
      "\u001b[34mBuilding wheel for assisted-intelligence (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for assisted-intelligence (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for assisted-intelligence: filename=assisted_intelligence-0.0.1-py3-none-any.whl size=73501 sha256=d0e9c33a2f0d58352404abd6ca7ff83ec6f61e63afbdc5b94fdc15b11d50952e\u001b[0m\n",
      "\u001b[34mStored in directory: /tmp/pip-ephem-wheel-cache-pwkqfbuj/wheels/40/03/3a/5f39818cea87b3c154b54d046a775b3da4b8ed9b642b8d50e6\u001b[0m\n",
      "\u001b[34mBuilding wheel for fire (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for fire (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116931 sha256=723dbdf40754cf00e6026f1442dd6c6b98333a5be72101317b7ba02b13c31424\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/f7/f1/89/b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\u001b[0m\n",
      "\u001b[34mBuilding wheel for nvidia-ml-py3 (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for nvidia-ml-py3 (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=ff2fe52649fa0b9139d0e37fc27cdc6da399c90385d5ce5531bd3e7df458e5a0\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/f6/d8/b0/15cfd7805d39250ac29318105f09b1750683387630d68423e1\u001b[0m\n",
      "\u001b[34mBuilding wheel for seqeval (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for seqeval (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16164 sha256=c866ab9cec76723fa4eab40b7517ccf62359dd3d5ebea258a91787488cc4d75c\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\u001b[0m\n",
      "\u001b[34mBuilding wheel for ffmpy (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for ffmpy (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=e292ed64e0ea610dd79076551a0ef3a40075b2618ef1d5c28ab35f61362f7d3c\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/91/e2/96/f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\u001b[0m\n",
      "\u001b[34mBuilding wheel for pathtools (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for pathtools (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=11b65df6187afa029bf6d7b0252fd71f50b2751b08e04361f057033d0296f033\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\u001b[0m\n",
      "\u001b[34mSuccessfully built assisted-intelligence fire nvidia-ml-py3 seqeval ffmpy pathtools\u001b[0m\n",
      "\u001b[34mInstalling collected packages: safetensors, pydub, pathtools, nvidia-ml-py3, ffmpy, bitsandbytes, websockets, uc-micro-py, tomli, tokenize-rt, termcolor, tensorboard-data-server, sniffio, smmap, setproctitle, sentry-sdk, semantic-version, python-multipart, pyasn1-modules, platformdirs, pathspec, orjson, oauthlib, mypy-extensions, mdurl, loralib, iniconfig, h11, grpcio, graphviz, docker-pycreds, cachetools, assisted-intelligence, aiofiles, absl-py, uvicorn, requests-oauthlib, pytest, markdown-it-py, linkify-it-py, huggingface-hub, google-auth, gitdb, fire, black, anyio, transformers, starlette, seqeval, mdit-py-plugins, httpcore, google-auth-oauthlib, GitPython, altair, wandb, tensorboard, peft, httpx, fastapi, trl, gradio-client, evaluate, gradio\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.12.0\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.12.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.12.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.26.0\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.26.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.26.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed GitPython-3.1.31 absl-py-1.4.0 aiofiles-23.1.0 altair-5.0.1 anyio-3.7.0 assisted-intelligence-0.0.1 bitsandbytes-0.39.0 black-23.3.0 cachetools-5.3.1 docker-pycreds-0.4.0 evaluate-0.4.0 fastapi-0.97.0 ffmpy-0.3.0 fire-0.5.0 gitdb-4.0.10 google-auth-2.20.0 google-auth-oauthlib-1.0.0 gradio-3.35.2 gradio-client-0.2.7 graphviz-0.20.1 grpcio-1.54.2 h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 huggingface-hub-0.15.1 iniconfig-2.0.0 linkify-it-py-2.0.2 loralib-0.1.1 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 mypy-extensions-1.0.0 nvidia-ml-py3-7.352.0 oauthlib-3.2.2 orjson-3.9.1 pathspec-0.11.1 pathtools-0.1.2 peft-0.3.0 platformdirs-3.6.0 pyasn1-modules-0.3.0 pydub-0.25.1 pytest-7.3.2 python-multipart-0.0.6 requests-oauthlib-1.3.1 safetensors-0.3.1 semantic-version-2.10.0 sentry-sdk-1.25.1 seqeval-1.2.2 setproctitle-1.3.2 smmap-5.0.0 sniffio-1.3.0 starlette-0.27.0 tensorboard-2.13.0 tensorboard-data-server-0.7.1 termcolor-2.3.0 tokenize-rt-5.1.0 tomli-2.0.1 transformers-4.30.1 trl-0.4.4 uc-micro-py-1.0.2 uvicorn-0.22.0 wandb-0.15.4 websockets-11.0.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 23.1.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:11,459 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:11,459 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:11,475 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:11,501 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:11,526 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:11,536 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"clone_repo\": \"rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-0522\",\n",
      "        \"dataset_name\": \"rjx/ai-and-human-0522\",\n",
      "        \"index_output\": \"labels\",\n",
      "        \"max_eval_samples\": 4,\n",
      "        \"max_test_samples\": 4,\n",
      "        \"max_train_samples\": 20,\n",
      "        \"metric_type\": \"seqeval\",\n",
      "        \"model_max_length\": 512,\n",
      "        \"model_name_or_path\": \"severinsimmler/xlm-roberta-longformer-base-16384\",\n",
      "        \"task_type\": \"text-generation\",\n",
      "        \"training_model\": \"BERT\",\n",
      "        \"wandb_project\": \"rjxai-cls-zh-v1-test\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"example-training-v1-2023-06-19-08-22-41-336\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-249450752701/example-training-v1-2023-06-19-08-22-41-336/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"auto_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"auto_train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"clone_repo\":\"rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-0522\",\"dataset_name\":\"rjx/ai-and-human-0522\",\"index_output\":\"labels\",\"max_eval_samples\":4,\"max_test_samples\":4,\"max_train_samples\":20,\"metric_type\":\"seqeval\",\"model_max_length\":512,\"model_name_or_path\":\"severinsimmler/xlm-roberta-longformer-base-16384\",\"task_type\":\"text-generation\",\"training_model\":\"BERT\",\"wandb_project\":\"rjxai-cls-zh-v1-test\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=auto_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=auto_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-249450752701/example-training-v1-2023-06-19-08-22-41-336/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"clone_repo\":\"rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-0522\",\"dataset_name\":\"rjx/ai-and-human-0522\",\"index_output\":\"labels\",\"max_eval_samples\":4,\"max_test_samples\":4,\"max_train_samples\":20,\"metric_type\":\"seqeval\",\"model_max_length\":512,\"model_name_or_path\":\"severinsimmler/xlm-roberta-longformer-base-16384\",\"task_type\":\"text-generation\",\"training_model\":\"BERT\",\"wandb_project\":\"rjxai-cls-zh-v1-test\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"example-training-v1-2023-06-19-08-22-41-336\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-249450752701/example-training-v1-2023-06-19-08-22-41-336/source/sourcedir.tar.gz\",\"module_name\":\"auto_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"auto_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--clone_repo\",\"rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-0522\",\"--dataset_name\",\"rjx/ai-and-human-0522\",\"--index_output\",\"labels\",\"--max_eval_samples\",\"4\",\"--max_test_samples\",\"4\",\"--max_train_samples\",\"20\",\"--metric_type\",\"seqeval\",\"--model_max_length\",\"512\",\"--model_name_or_path\",\"severinsimmler/xlm-roberta-longformer-base-16384\",\"--task_type\",\"text-generation\",\"--training_model\",\"BERT\",\"--wandb_project\",\"rjxai-cls-zh-v1-test\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_CLONE_REPO=rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-0522\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_NAME=rjx/ai-and-human-0522\u001b[0m\n",
      "\u001b[34mSM_HP_INDEX_OUTPUT=labels\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_EVAL_SAMPLES=4\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_TEST_SAMPLES=4\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_TRAIN_SAMPLES=20\u001b[0m\n",
      "\u001b[34mSM_HP_METRIC_TYPE=seqeval\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_MAX_LENGTH=512\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME_OR_PATH=severinsimmler/xlm-roberta-longformer-base-16384\u001b[0m\n",
      "\u001b[34mSM_HP_TASK_TYPE=text-generation\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_MODEL=BERT\u001b[0m\n",
      "\u001b[34mSM_HP_WANDB_PROJECT=rjxai-cls-zh-v1-test\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 -m auto_train --clone_repo rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-0522 --dataset_name rjx/ai-and-human-0522 --index_output labels --max_eval_samples 4 --max_test_samples 4 --max_train_samples 20 --metric_type seqeval --model_max_length 512 --model_name_or_path severinsimmler/xlm-roberta-longformer-base-16384 --task_type text-generation --training_model BERT --wandb_project rjxai-cls-zh-v1-test\u001b[0m\n",
      "\u001b[34m[2023-06-19 08:28:13.648: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.30.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:13,653 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:13,670 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m╭───────────────────── Traceback (most recent call last) ──────────────────────╮\u001b[0m\n",
      "\u001b[34m│ /opt/conda/lib/python3.9/site-packages/transformers/utils/import_utils.py:10 │\u001b[0m\n",
      "\u001b[34m│ 84 in _get_module                                                            │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│   1081 │                                                                     │\u001b[0m\n",
      "\u001b[34m│   1082 │   def _get_module(self, module_name: str):                          │\u001b[0m\n",
      "\u001b[34m│   1083 │   │   try:                                                          │\u001b[0m\n",
      "\u001b[34m│ ❱ 1084 │   │   │   return importlib.import_module(\".\" + module_name, self.__ │\u001b[0m\n",
      "\u001b[34m│   1085 │   │   except Exception as e:                                        │\u001b[0m\n",
      "\u001b[34m│   1086 │   │   │   raise RuntimeError(                                       │\u001b[0m\n",
      "\u001b[34m│   1087 │   │   │   │   f\"Failed to import {self.__name__}.{module_name} beca │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│ /opt/conda/lib/python3.9/importlib/__init__.py:127 in import_module          │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│   124 │   │   │   if character != '.':                                       │\u001b[0m\n",
      "\u001b[34m│   125 │   │   │   │   break                                                  │\u001b[0m\n",
      "\u001b[34m│   126 │   │   │   level += 1                                                 │\u001b[0m\n",
      "\u001b[34m│ ❱ 127 │   return _bootstrap._gcd_import(name[level:], package, level)        │\u001b[0m\n",
      "\u001b[34m│   128                                                                        │\u001b[0m\n",
      "\u001b[34m│   129                                                                        │\u001b[0m\n",
      "\u001b[34m│   130 _RELOADING = {}                                                        │\u001b[0m\n",
      "\u001b[34m│ <frozen importlib._bootstrap>:1030 in _gcd_import                            │\u001b[0m\n",
      "\u001b[34m│ <frozen importlib._bootstrap>:1007 in _find_and_load                         │\u001b[0m\n",
      "\u001b[34m│ <frozen importlib._bootstrap>:986 in _find_and_load_unlocked                 │\u001b[0m\n",
      "\u001b[34m│ <frozen importlib._bootstrap>:680 in _load_unlocked                          │\u001b[0m\n",
      "\u001b[34m│ <frozen importlib._bootstrap_external>:850 in exec_module                    │\u001b[0m\n",
      "\u001b[34m│ <frozen importlib._bootstrap>:228 in _call_with_frames_removed               │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│ /opt/conda/lib/python3.9/site-packages/transformers/training_args.py:67 in   │\u001b[0m\n",
      "\u001b[34m│ <module>                                                                     │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│     64 │   import torch.distributed as dist                                  │\u001b[0m\n",
      "\u001b[34m│     65                                                                       │\u001b[0m\n",
      "\u001b[34m│     66 if is_accelerate_available():                                         │\u001b[0m\n",
      "\u001b[34m│ ❱   67 │   from accelerate.state import AcceleratorState, PartialState       │\u001b[0m\n",
      "\u001b[34m│     68 │   from accelerate.utils import DistributedType                      │\u001b[0m\n",
      "\u001b[34m│     69                                                                       │\u001b[0m\n",
      "\u001b[34m│     70 if is_torch_tpu_available(check_device=False):                        │\u001b[0m\n",
      "\u001b[34m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[34mImportError: cannot import name 'PartialState' from 'accelerate.state' \u001b[0m\n",
      "\u001b[34m(/opt/conda/lib/python3.9/site-packages/accelerate/state.py)\u001b[0m\n",
      "\u001b[34mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\u001b[34m╭───────────────────── Traceback (most recent call last) ──────────────────────╮\u001b[0m\n",
      "\u001b[34m│ /opt/conda/lib/python3.9/runpy.py:197 in _run_module_as_main                 │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│   194 │   main_globals = sys.modules[\"__main__\"].__dict__                    │\u001b[0m\n",
      "\u001b[34m│   195 │   if alter_argv:                                                     │\u001b[0m\n",
      "\u001b[34m│   196 │   │   sys.argv[0] = mod_spec.origin                                  │\u001b[0m\n",
      "\u001b[34m│ ❱ 197 │   return _run_code(code, main_globals, None,                         │\u001b[0m\n",
      "\u001b[34m│   198 │   │   │   │   │    \"__main__\", mod_spec)                             │\u001b[0m\n",
      "\u001b[34m│   199                                                                        │\u001b[0m\n",
      "\u001b[34m│   200 def run_module(mod_name, init_globals=None,                            │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│ /opt/conda/lib/python3.9/runpy.py:87 in _run_code                            │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│    84 │   │   │   │   │      __loader__ = loader,                            │\u001b[0m\n",
      "\u001b[34m│    85 │   │   │   │   │      __package__ = pkg_name,                         │\u001b[0m\n",
      "\u001b[34m│    86 │   │   │   │   │      __spec__ = mod_spec)                            │\u001b[0m\n",
      "\u001b[34m│ ❱  87 │   exec(code, run_globals)                                            │\u001b[0m\n",
      "\u001b[34m│    88 │   return run_globals                                                 │\u001b[0m\n",
      "\u001b[34m│    89                                                                        │\u001b[0m\n",
      "\u001b[34m│    90 def _run_module_code(code, init_globals=None,                          │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│ /opt/ml/code/auto_train.py:2 in <module>                                     │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│     1 import wandb                                                           │\u001b[0m\n",
      "\u001b[34m│ ❱   2 import fengxai.config.bert_config as bert_config                       │\u001b[0m\n",
      "\u001b[34m│     3 import fengxai.config.base_config as base_config                       │\u001b[0m\n",
      "\u001b[34m│     4 import fengxai.config.llama_config as llama_config                     │\u001b[0m\n",
      "\u001b[34m│     5 import os                                                              │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│ /opt/ml/code/fengxai/config/bert_config.py:4 in <module>                     │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│     1 from transformers.trainer_utils import SchedulerType                   │\u001b[0m\n",
      "\u001b[34m│     2 from typing import Optional, List, ClassVar, Union                     │\u001b[0m\n",
      "\u001b[34m│     3 from dataclasses import dataclass, field                               │\u001b[0m\n",
      "\u001b[34m│ ❱   4 from transformers import (TrainingArguments)                           │\u001b[0m\n",
      "\u001b[34m│     5 from transformers.utils import ExplicitEnum                            │\u001b[0m\n",
      "\u001b[34m│     6 from transformers.trainer_utils import IntervalStrategy                │\u001b[0m\n",
      "\u001b[34m│     7 from fengxai.utils.log_center import create_logger                     │\u001b[0m\n",
      "\u001b[34m│ <frozen importlib._bootstrap>:1055 in _handle_fromlist                       │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│ /opt/conda/lib/python3.9/site-packages/transformers/utils/import_utils.py:10 │\u001b[0m\n",
      "\u001b[34m│ 74 in __getattr__                                                            │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│   1071 │   │   if name in self._modules:                                     │\u001b[0m\n",
      "\u001b[34m│   1072 │   │   │   value = self._get_module(name)                            │\u001b[0m\n",
      "\u001b[34m│   1073 │   │   elif name in self._class_to_module.keys():                    │\u001b[0m\n",
      "\u001b[34m│ ❱ 1074 │   │   │   module = self._get_module(self._class_to_module[name])    │\u001b[0m\n",
      "\u001b[34m│   1075 │   │   │   value = getattr(module, name)                             │\u001b[0m\n",
      "\u001b[34m│   1076 │   │   else:                                                         │\u001b[0m\n",
      "\u001b[34m│   1077 │   │   │   raise AttributeError(f\"module {self.__name__} has no attr │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│ /opt/conda/lib/python3.9/site-packages/transformers/utils/import_utils.py:10 │\u001b[0m\n",
      "\u001b[34m│ 86 in _get_module                                                            │\u001b[0m\n",
      "\u001b[34m│                                                                              │\u001b[0m\n",
      "\u001b[34m│   1083 │   │   try:                                                          │\u001b[0m\n",
      "\u001b[34m│   1084 │   │   │   return importlib.import_module(\".\" + module_name, self.__ │\u001b[0m\n",
      "\u001b[34m│   1085 │   │   except Exception as e:                                        │\u001b[0m\n",
      "\u001b[34m│ ❱ 1086 │   │   │   raise RuntimeError(                                       │\u001b[0m\n",
      "\u001b[34m│   1087 │   │   │   │   f\"Failed to import {self.__name__}.{module_name} beca │\u001b[0m\n",
      "\u001b[34m│   1088 │   │   │   │   f\" traceback):\\n{e}\"                                  │\u001b[0m\n",
      "\u001b[34m│   1089 │   │   │   ) from e                                                  │\u001b[0m\n",
      "\u001b[34m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[34mRuntimeError: Failed to import transformers.training_args because of the \u001b[0m\n",
      "\u001b[34mfollowing error (look up to see its traceback):\u001b[0m\n",
      "\u001b[34mcannot import name 'PartialState' from 'accelerate.state' \u001b[0m\n",
      "\u001b[34m(/opt/conda/lib/python3.9/site-packages/accelerate/state.py)\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:16,387 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:16,387 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:16,388 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:16,388 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"│   1085 │   │   except Exception as e:                                        │\n",
      " │   1086 │   │   │   raise RuntimeError(                                       │\n",
      " │   1087 │   │   │   │   f\"Failed to import {self.__name__}.{module_name} beca │\n",
      " │                                                                              │\n",
      " │ /opt/conda/lib/python3.9/importlib/__init__.py:127 in import_module          │\n",
      " │   124 │   │   │   if character != '.':                                       │\n",
      " │   125 │   │   │   │   break                                                  │\n",
      " │   126 │   │   │   level += 1                                                 │\n",
      " │ ❱ 127 │   return _bootstrap._gcd_import(name[level:], package, level)        │\n",
      " │   128                                                                        │\n",
      " │   129                                                                        │\n",
      " │   130 _RELOADING = {}                                                        │\n",
      " │ <frozen importlib._bootstrap>:1030 in _gcd_import                            │\n",
      " │ <frozen importlib._bootstrap>:1007 in _find_and_load                         │\n",
      " │ <frozen importlib._bootstrap>:986 in _find_and_load_unlocked                 │\n",
      " │ <frozen importlib._bootstrap>:680 in _load_unlocked                          │\n",
      " │ <frozen importlib._bootstrap_external>:850 in exec_module                    │\n",
      " │ <frozen importlib._bootstrap>:228 in _call_with_frames_removed               │\n",
      " │ /opt/conda/lib/python3.9/site-packages/transformers/training_args.py:67 in   │\n",
      " │ <module>                                                                     │\n",
      " │     64 │   import torch.distributed as dist                                  │\n",
      " │     65                                                                       │\n",
      " │     66 if is_accelerate_available():                                         │\n",
      " │ ❱   67 │   from accelerate.state import AcceleratorState, PartialState       │\n",
      " │     68 │   from accelerate.utils import DistributedType                      │\n",
      " │     69                                                                       │\n",
      " │     70 if is_torch_tpu_available(check_device=False):                        │\n",
      " ╰──────────────────────────────────────────────────────────────────────────────╯\n",
      " ImportError: cannot import name 'PartialState' from 'accelerate.state'\n",
      " (/opt/conda/lib/python3.9/site-packages/accelerate/state.py)\n",
      " \n",
      " The above exception was the direct cause of the following exception\n",
      " ╭───────────────────── Traceback (most recent call last) ──────────────────────╮\n",
      " │ /opt/conda/lib/python3.9/runpy.py:197 in _run_module_as_main                 │\n",
      " │   194 │   main_globals = sys.modules[\"__main__\"].__dict__                    │\n",
      " │   195 │   if alter_argv:                                                     │\n",
      " │   196 │   │   sys.argv[0] = mod_spec.origin                                  │\n",
      " │ ❱ 197 │   return _run_code(code, main_globals, None,                         │\n",
      " │   198 │   │   │   │   │    \"__main__\", mod_spec)                             │\n",
      " │   199                                                                        │\n",
      " │   200 def run_module(mod_name, init_globals=None,                            │\n",
      " │ /opt/conda/lib/python3.9/runpy.py:87 in _run_code                            │\n",
      " │    84 │   │   │   │   │      __loader__ = loader,                            │\n",
      " │    85 │   │   │   │   │      __package__ = pkg_name,                         │\n",
      " │    86 │   │   │   │   │      __spec__ = mod_spec)                            │\n",
      " │ ❱  87 │   exec(code, run_globals)                                            │\n",
      " │    88 │   return run_globals                                                 │\n",
      " │    89                                                                        │\n",
      " │    90 def _run_module_code(code, init_globals=None,                          │\n",
      " │ /opt/ml/code/auto_train.py:2 in <module>                                     │\n",
      " │     1 import wandb                                                           │\n",
      " │ ❱   2 import fengxai.config.bert_config as bert_config                       │\n",
      " │     3 import fengxai.config.base_config as base_config                       │\n",
      " │     4 import fengxai.config.llama_config as llama_config                     │\n",
      " │     5 import os                                                              │\n",
      " │ /opt/ml/code/fengxai/config/bert_config.py:4 in <module>                     │\n",
      " │     1 from transformers.trainer_utils import SchedulerType                   │\n",
      " │     2 from typing import Optional, List, ClassVar, Union                     │\n",
      " │     3 from dataclasses import dataclass, field                               │\n",
      " │ ❱   4 from transformers import (TrainingArguments)                           │\n",
      " │     5 from transformers.utils import ExplicitEnum                            │\n",
      " │     6 from transformers.trainer_utils import IntervalStrategy                │\n",
      " │     7 from fengxai.utils.log_center import create_logger                     │\n",
      " │ <frozen importlib._bootstrap>:1055 in _handle_fromlist                       │\n",
      " │ /opt/conda/lib/python3.9/site-packages/transformers/utils/import_utils.py:10 │\n",
      " │ 74 in __getattr__                                                            │\n",
      " │   1071 │   │   if name in self._modules:                                     │\n",
      " │   1072 │   │   │   value = self._get_module(name)                            │\n",
      " │   1073 │   │   elif name in self._class_to_module.keys():                    │\n",
      " │ ❱ 1074 │   │   │   module = self._get_module(self._class_to_module[name])    │\n",
      " │   1075 │   │   │   value = getattr(module, name)                             │\n",
      " │   1076 │   │   else:                                                         │\n",
      " │   1077 │   │   │   raise AttributeError(f\"module {self.__name__} has no attr │\n",
      " │ 86 in _get_module                                                            │\n",
      " │   1083 │   │   try:                                                          │\n",
      " │   1084 │   │   │   return importlib.import_module(\".\" + module_name, self.__ │\n",
      " │ ❱ 1086 │   │   │   raise RuntimeError(                                       │\n",
      " │   1088 │   │   │   │   f\" traceback):\\n{e}\"                                  │\n",
      " │   1089 │   │   │   ) from e                                                  │\n",
      " RuntimeError: Failed to import transformers.training_args because of the\n",
      " following error (look up to see its traceback)\n",
      " cannot import name 'PartialState' from 'accelerate.state'\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.9 -m auto_train --clone_repo rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-0522 --dataset_name rjx/ai-and-human-0522 --index_output labels --max_eval_samples 4 --max_test_samples 4 --max_train_samples 20 --metric_type seqeval --model_max_length 512 --model_name_or_path severinsimmler/xlm-roberta-longformer-base-16384 --task_type text-generation --training_model BERT --wandb_project rjxai-cls-zh-v1-test\"\u001b[0m\n",
      "\u001b[34m2023-06-19 08:28:16,388 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2023-06-19 08:28:33 Uploading - Uploading generated training model\n",
      "2023-06-19 08:28:33 Failed - Training job failed\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accel\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33merate/commands/\u001b[0m\u001b[1;33maccelerate_cli.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accel\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33merate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m916\u001b[0m in \u001b[92mlaunch_command\u001b[0m                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m913 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m914 \u001b[0m\u001b[2m│   │   │   \u001b[0mtpu_launcher(args)                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m915 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m defaults \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m defaults.compute_environment == Comp \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m916 \u001b[2m│   │   \u001b[0msagemaker_launcher(defaults, args)                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m917 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m918 \u001b[0m\u001b[2m│   │   \u001b[0msimple_launcher(args)                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m919 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accel\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33merate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m764\u001b[0m in \u001b[92msagemaker_launcher\u001b[0m                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m761 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m762 \u001b[0m\u001b[2m│   \u001b[0mhuggingface_estimator = HuggingFace(**args)                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m763 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m764 \u001b[2m│   \u001b[0mhuggingface_estimator.fit(inputs=sagemaker_inputs)                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m765 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mYou can find your model data at: \u001b[0m\u001b[33m{\u001b[0mhuggingface_estimator.mo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m766 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m767 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/workflow/\u001b[0m\u001b[1;33mpipeline_context.py\u001b[0m:\u001b[94m300\u001b[0m in \u001b[92mwrapper\u001b[0m                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m297 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m _StepArguments(retrieve_caller_name(self_instance), \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m300 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m run_func(*args, **kwargs)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m301 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m302 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m303 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m1221\u001b[0m in \u001b[92mfit\u001b[0m                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1218 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.latest_training_job = _TrainingJob.start_new(\u001b[96mself\u001b[0m, input \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1219 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.jobs.append(\u001b[96mself\u001b[0m.latest_training_job)                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1220 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m wait:                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1221 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.latest_training_job.wait(logs=logs)                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1222 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1223 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_compilation_job_name\u001b[0m(\u001b[96mself\u001b[0m):                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1224 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Placeholder docstring\"\"\"\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m2367\u001b[0m in \u001b[92mwait\u001b[0m                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2364 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogs = log_string_map[logs]                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2365 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# If logs are requested, call logs_for_jobs.\u001b[0m                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2366 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m logs != \u001b[33m\"\u001b[0m\u001b[33mNone\u001b[0m\u001b[33m\"\u001b[0m:                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2367 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.logs_for_job(\u001b[96mself\u001b[0m.job_name, wait=\u001b[94mT\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.wait_for_job(\u001b[96mself\u001b[0m.job_name)        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2370 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m4665\u001b[0m in \u001b[92mlogs_for_job\u001b[0m                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4662 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mexceptions.CapacityError: If the training job fails with \u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4663 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mexceptions.UnexpectedStatusException: If waiting and the \u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4664 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m4665 \u001b[2m│   │   \u001b[0m_logs_for_job(\u001b[96mself\u001b[0m.boto_session, job_name, wait, poll, log_ty \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4666 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4667 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mlogs_for_processing_job\u001b[0m(\u001b[96mself\u001b[0m, job_name, wait=\u001b[94mFalse\u001b[0m, poll=\u001b[94m10\u001b[0m): \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m4668 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Display logs for a given processing job, optionally tailin\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m6527\u001b[0m in \u001b[92m_logs_for_job\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6524 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlast_profiler_rule_statuses = profiler_rule_statuses  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6525 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6526 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m wait:                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m6527 \u001b[2m│   │   \u001b[0m_check_job_status(job_name, description, \u001b[33m\"\u001b[0m\u001b[33mTrainingJobStatus\u001b[0m\u001b[33m\"\u001b[0m) \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6528 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m dot:                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6529 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m()                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6530 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Customers are not billed for hardware provisioning, so bill\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m6580\u001b[0m in \u001b[92m_check_job_status\u001b[0m                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6577 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6578 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mactual_status=status,                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6579 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m6580 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m exceptions.UnexpectedStatusException(                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6581 \u001b[0m\u001b[2m│   │   │   \u001b[0mmessage=message,                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6582 \u001b[0m\u001b[2m│   │   │   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6583 \u001b[0m\u001b[2m│   │   │   \u001b[0mactual_status=status,                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mUnexpectedStatusException: \u001b[0mError for Training job \n",
      "example-training-v1-\u001b[1;36m2023\u001b[0m-\u001b[1;92m06-19-08-22-41-33\u001b[0m6: Failed. Reason: AlgorithmError: \n",
      "ExecuteUserScriptError:\n",
      "ExitCode \u001b[1;36m1\u001b[0m\n",
      "ErrorMessage \"│   \u001b[1;36m1085\u001b[0m │   │   except Exception as e:                           \n",
      "│\n",
      " │   \u001b[1;36m1086\u001b[0m │   │   │   raise \u001b[1;35mRuntimeError\u001b[0m\u001b[1m(\u001b[0m                                       \n",
      "│\n",
      " │   \u001b[1;36m1087\u001b[0m │   │   │   │   f\"Failed to import \u001b[1m{\u001b[0mself.__name__\u001b[1m}\u001b[0m.\u001b[1m{\u001b[0mmodule_name\u001b[1m}\u001b[0m beca \n",
      "│\n",
      " │                                                                              \n",
      "│\n",
      " │ \u001b[35m/opt/conda/lib/python3.9/importlib/\u001b[0m\u001b[95m__init__.py\u001b[0m:\u001b[1;36m127\u001b[0m in import_module          \n",
      "│\n",
      " │   \u001b[1;36m124\u001b[0m │   │   │   if character != \u001b[32m'.'\u001b[0m:                                       \n",
      "│\n",
      " │   \u001b[1;36m125\u001b[0m │   │   │   │   break                                                  \n",
      "│\n",
      " │   \u001b[1;36m126\u001b[0m │   │   │   level += \u001b[1;36m1\u001b[0m                                                 \n",
      "│\n",
      " │ ❱ \u001b[1;36m127\u001b[0m │   return \u001b[1;35m_bootstrap._gcd_import\u001b[0m\u001b[1m(\u001b[0mname\u001b[1m[\u001b[0mlevel:\u001b[1m]\u001b[0m, package, level\u001b[1m)\u001b[0m        \n",
      "│\n",
      " │   \u001b[1;36m128\u001b[0m                                                                        \n",
      "│\n",
      " │   \u001b[1;36m129\u001b[0m                                                                , exit \n",
      "code: \u001b[1;36m1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file fengxai/config/accelerator/sagemaker_train_gpu.yaml auto_train.py \\\n",
    "    --training_model BERT \\\n",
    "    --clone_repo rjx/rjxai-xlm-roberta-longformer-1024-and-dataset-0522 \\\n",
    "    --model_name_or_path severinsimmler/xlm-roberta-longformer-base-16384 \\\n",
    "    --dataset_name rjx/ai-and-human-0522 \\\n",
    "    --model_max_length 512 \\\n",
    "    --task_type text-generation \\\n",
    "    --metric_type seqeval \\\n",
    "    --index_output labels \\\n",
    "    --wandb_project rjxai-cls-zh-v1-test \\\n",
    "    --max_train_samples 20 \\\n",
    "    --max_eval_samples 4 \\\n",
    "    --max_test_samples 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
