{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fengxai.ml.hf_sagemaker import HfSagemaker\n",
    "\n",
    "mlFacotry=HfSagemaker(\n",
    "    # 设定 sagemaker 训练机器\n",
    "    sagemaker_config={\n",
    "        # 'instance_type': 'ml.p3dn.24xlarge',\n",
    "        # 'instance_type': 'ml.p4d.24xlarge',\n",
    "        # 'instance_type': 'ml.p3.2xlarge',\n",
    "        'instance_type': 'ml.m5.xlarge',\n",
    "        'instance_count': 1,\n",
    "    },\n",
    "    env={\n",
    "        'HF_MODEL_ID':'rjx/rjxai-lora-7b-v1'\n",
    "    }\n",
    ")\n",
    "\n",
    "mlFacotry.deploy(\n",
    "    data={\n",
    "        \"inputs\": {\n",
    "            \"question\": \"What is used for inference?\",\n",
    "            \"context\": \"My Name is Philipp and I live in Nuremberg. This model is used with sagemaker for inference.\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rlhf llama peft 本地运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file assisted_intelligence/config/accelerator/local_train.yaml auto_inference.py \\\n",
    "    --base_model /Volumes/Thunderbolt/ofengx/ai/fengx_ai_llama_chinese/rjx/rjxai-zh-llama-7b-v1 \\\n",
    "    --tokenizer_path /Volumes/Thunderbolt/ofengx/ai/fengx_ai_llama_chinese/rjx/rjxai-zh-llama-7b-v1 \\\n",
    "    --lora_model rjx/rjxai-7b-se \\\n",
    "    --use_auth_token True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rlhf llama peft sagemaker 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file assisted_intelligence/config/accelerator/sagemaker_train.yaml auto_inference.py \\\n",
    "    --base_model rjx/rjxai-zh-llama-7b-v1 \\\n",
    "    --tokenizer_path rjx/rjxai-zh-llama-7b-v1 \\\n",
    "    --lora_model rjx/rjxai-7b-se \\\n",
    "    --use_auth_token True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### falcon 7b sagemaker test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TigerResearch/tigerbot-7b-sft-4bit-128g（不可用）\n",
    "# TigerResearch/tigerbot-7b-sft\n",
    "\n",
    "!accelerate launch --config_file fengxai/config/accelerator/sagemaker_inference.yaml inference_falcon.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(not os.path.isdir('rjx/rjxai-zh-7b-se-v1.2'))\n",
    "print(not os.path.isdir('rjx/rjxai-zh-7b-se-v1'))\n",
    "\n",
    "print(os.path.isdir('rjx/rjxai-zh-7b-se-v1.2'))\n",
    "print(os.path.isdir('rjx/rjxai-zh-7b-se-v1'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
