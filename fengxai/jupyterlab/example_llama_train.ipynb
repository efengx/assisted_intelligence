{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ sagemaker tools è¿è¡Œ llama lora æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-26 17:56:04,638,638 INFO     4521711104 MainThread 51069 [fx_hf_sagemaker.py:27] åˆå§‹åŒ–ç¯å¢ƒå˜é‡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name fengx to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-26 17:56:08,633,633 INFO     4521711104 MainThread 51069 [fx_hf_sagemaker.py:39] å½“å‰ä½¿ç”¨localæœºå™¨è¿›è¡Œè¿œç¨‹è¿æ¥ï¼›ä½¿ç”¨boto3.clientè¿›è¡Œiamæƒé™è·å–\n",
      "2023-05-26 17:56:10,370,370 INFO     4521711104 MainThread 51069 [fx_hf_sagemaker.py:50] æ„å»ºestimatorç¯å¢ƒ\n",
      "2023-05-26 17:56:10,476,476 INFO     4521711104 MainThread 51069 [fx_hf_sagemaker.py:77] å¯åŠ¨estimator\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2023-05-26-09-56-10-653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-26 09:56:18 Starting - Starting the training job...\n",
      "2023-05-26 09:56:42 Starting - Preparing the instances for training......\n",
      "2023-05-26 09:57:53 Downloading - Downloading input data...\n",
      "2023-05-26 09:58:13 Training - Downloading the training image..................\n",
      "2023-05-26 10:01:44 Training - Training image download completed. Training in progress..bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2023-05-26 10:02:02,731 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2023-05-26 10:02:02,749 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-05-26 10:02:02,762 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2023-05-26 10:02:02,765 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2023-05-26 10:02:03,219 sagemaker-training-toolkit INFO     Installing module with the following command:\n",
      "/opt/conda/bin/python3.9 -m pip install . -r requirements.txt\n",
      "Processing /opt/ml/code\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torch==1.13.1 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.13.1+cu117)\n",
      "Collecting torchinfo\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.19.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (2.9.0)\n",
      "Collecting wandb\n",
      "Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.0/2.0 MB 12.8 MB/s eta 0:00:00\n",
      "Collecting deepspeed==0.9.2\n",
      "Downloading deepspeed-0.9.2.tar.gz (779 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 779.3/779.3 kB 19.1 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting absl-py\n",
      "Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 126.5/126.5 kB 27.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (1.2.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (3.6.3)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (0.12.2)\n",
      "Collecting triton\n",
      "Downloading triton-2.0.0.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.3 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 63.3/63.3 MB 28.0 MB/s eta 0:00:00\n",
      "Collecting tokenizers==0.13.3\n",
      "Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.8/7.8 MB 88.6 MB/s eta 0:00:00\n",
      "Collecting accelerate==0.19.0\n",
      "Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 219.1/219.1 kB 47.4 MB/s eta 0:00:00\n",
      "Collecting functorch==1.13.1\n",
      "Downloading functorch-1.13.1-py2.py3-none-any.whl (2.1 kB)\n",
      "Collecting xformers==0.0.16\n",
      "Downloading xformers-0.0.16-cp39-cp39-manylinux2014_x86_64.whl (50.9 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 50.9/50.9 MB 35.4 MB/s eta 0:00:00\n",
      "Collecting peft==0.2.0\n",
      "Downloading peft-0.2.0-py3-none-any.whl (40 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 40.3/40.3 kB 11.9 MB/s eta 0:00:00\n",
      "Collecting transformers==4.28.1\n",
      "Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.0/7.0 MB 86.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sentencepiece==0.1.97 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 18)) (0.1.97)\n",
      "Collecting evaluate\n",
      "Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 81.4/81.4 kB 24.7 MB/s eta 0:00:00\n",
      "Collecting gradio\n",
      "Downloading gradio-3.32.0-py3-none-any.whl (19.9 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19.9/19.9 MB 67.0 MB/s eta 0:00:00\n",
      "Collecting tensorboard\n",
      "Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.6/5.6 MB 91.2 MB/s eta 0:00:00\n",
      "Collecting torchview\n",
      "Downloading torchview-0.2.6-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 23)) (0.14.1+cu117)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 24)) (0.13.1+cu117)\n",
      "Collecting graphviz\n",
      "Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 47.0/47.0 kB 14.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-ml-py3\n",
      "Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting bitsandbytes\n",
      "Downloading bitsandbytes-0.39.0-py3-none-any.whl (92.2 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 92.2/92.2 MB 22.8 MB/s eta 0:00:00\n",
      "Collecting trl\n",
      "Downloading trl-0.4.1-py3-none-any.whl (50 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 50.9/50.9 kB 12.5 MB/s eta 0:00:00\n",
      "Collecting seqeval\n",
      "Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 43.6/43.6 kB 12.7 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch==1.13.1->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: hjson in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (1.11.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (23.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (5.9.4)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (9.0.0)\n",
      "Requirement already satisfied: pydantic<2.0.0 in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (1.10.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (4.64.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from accelerate==0.19.0->-r requirements.txt (line 13)) (5.4.1)\n",
      "Collecting pyre-extensions==0.0.23\n",
      "Downloading pyre_extensions-0.0.23-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.28.1->-r requirements.txt (line 17)) (0.12.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.28.1->-r requirements.txt (line 17)) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.28.1->-r requirements.txt (line 17)) (3.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.28.1->-r requirements.txt (line 17)) (2.28.2)\n",
      "Collecting typing-inspect\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (3.8.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (1.5.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (11.0.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (0.70.14)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (2023.1.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (0.3.6)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (0.18.0)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "Downloading sentry_sdk-1.24.0-py2.py3-none-any.whl (206 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 206.5/206.5 kB 42.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (1.4.4)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 184.3/184.3 kB 38.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (3.20.2)\n",
      "Collecting pathtools\n",
      "Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (65.6.3)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting setproctitle\n",
      "Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (8.1.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.0.7)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.9/site-packages (from triton->-r requirements.txt (line 11)) (3.24.3)\n",
      "Collecting lit\n",
      "Downloading lit-16.0.5.tar.gz (138 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 138.0/138.0 kB 34.6 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 224.5/224.5 kB 43.7 MB/s eta 0:00:00\n",
      "Collecting python-multipart\n",
      "Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 45.7/45.7 kB 12.7 MB/s eta 0:00:00\n",
      "Collecting pydub\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 50.5/50.5 kB 11.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: markupsafe in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 20)) (2.1.2)\n",
      "Requirement already satisfied: pygments>=2.12.0 in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 20)) (2.14.0)\n",
      "Collecting aiofiles\n",
      "Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting semantic-version\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 84.5/84.5 kB 21.3 MB/s eta 0:00:00\n",
      "Collecting uvicorn>=0.14.0\n",
      "Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 58.3/58.3 kB 16.8 MB/s eta 0:00:00\n",
      "Collecting fastapi\n",
      "Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 57.0/57.0 kB 15.4 MB/s eta 0:00:00\n",
      "Collecting httpx\n",
      "Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 75.4/75.4 kB 21.3 MB/s eta 0:00:00\n",
      "Collecting websockets>=10.0\n",
      "Downloading websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 129.7/129.7 kB 24.3 MB/s eta 0:00:00\n",
      "Collecting altair>=4.2.0\n",
      "Downloading altair-5.0.0-py3-none-any.whl (477 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 477.4/477.4 kB 56.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 20)) (3.1.2)\n",
      "Collecting gradio-client>=0.2.4\n",
      "Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 288.1/288.1 kB 45.5 MB/s eta 0:00:00\n",
      "Collecting orjson\n",
      "Downloading orjson-3.8.14-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 136.5/136.5 kB 27.2 MB/s eta 0:00:00\n",
      "Collecting ffmpy\n",
      "Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.6/6.6 MB 79.7 MB/s eta 0:00:00\n",
      "Collecting grpcio>=1.48.2\n",
      "Downloading grpcio-1.54.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.1/5.1 MB 89.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 21)) (2.2.3)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 21)) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "Downloading google_auth-2.19.0-py2.py3-none-any.whl (181 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 181.3/181.3 kB 31.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 21)) (3.4.1)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 20)) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 20)) (4.17.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (22.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (6.0.4)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.7/62.7 kB 17.4 MB/s eta 0:00:00\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 181.3/181.3 kB 33.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 21)) (4.7.2)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 21)) (1.26.14)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 21)) (4.13.0)\n",
      "Collecting mdurl~=0.1\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->-r requirements.txt (line 4)) (2022.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.28.1->-r requirements.txt (line 17)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.28.1->-r requirements.txt (line 17)) (3.4)\n",
      "Collecting h11>=0.8\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 58.3/58.3 kB 16.2 MB/s eta 0:00:00\n",
      "Collecting starlette<0.28.0,>=0.27.0\n",
      "Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 67.0/67.0 kB 18.1 MB/s eta 0:00:00\n",
      "Collecting httpcore<0.18.0,>=0.15.0\n",
      "Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 72.5/72.5 kB 20.3 MB/s eta 0:00:00\n",
      "Collecting sniffio\n",
      "Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting anyio<5.0,>=3.0\n",
      "Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 80.6/80.6 kB 20.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 21)) (3.13.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 20)) (0.19.3)\n",
      "Collecting uc-micro-py\n",
      "Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 21)) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 151.7/151.7 kB 29.0 MB/s eta 0:00:00\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Building wheels for collected packages: deepspeed, fengx-ai, nvidia-ml-py3, seqeval, ffmpy, lit, pathtools\n",
      "Building wheel for deepspeed (setup.py): started\n",
      "Building wheel for deepspeed (setup.py): finished with status 'done'\n",
      "Created wheel for deepspeed: filename=deepspeed-0.9.2-py3-none-any.whl size=811225 sha256=2ced57c2cb7994c997094e7272d714692cb9765ef20863bf525d0a57e954dda0\n",
      "Stored in directory: /root/.cache/pip/wheels/7a/86/f9/5b6341574584972377c6d55ff5e8fa53c956a39d63a849ffb4\n",
      "Building wheel for fengx-ai (setup.py): started\n",
      "Building wheel for fengx-ai (setup.py): finished with status 'done'\n",
      "Created wheel for fengx-ai: filename=fengx_ai-0.0.1-py3-none-any.whl size=83463 sha256=cfe5e2f1cd9d69891605d93fcbfe10f5881acd3fcb6f4cf00bfaab094f6bf3dd\n",
      "Stored in directory: /tmp/pip-ephem-wheel-cache-pk08ld22/wheels/40/03/3a/5f39818cea87b3c154b54d046a775b3da4b8ed9b642b8d50e6\n",
      "Building wheel for nvidia-ml-py3 (setup.py): started\n",
      "Building wheel for nvidia-ml-py3 (setup.py): finished with status 'done'\n",
      "Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=35f7f4f9d26528738ff37d7b37824ce4265c561952acbccb0ab2159644a7fb5a\n",
      "Stored in directory: /root/.cache/pip/wheels/f6/d8/b0/15cfd7805d39250ac29318105f09b1750683387630d68423e1\n",
      "Building wheel for seqeval (setup.py): started\n",
      "Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16164 sha256=3b52e6e9fb06113787464dbc63d83f44f09ed7b22115268b69b3a413c9bff43f\n",
      "Stored in directory: /root/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n",
      "Building wheel for ffmpy (setup.py): started\n",
      "Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=826b3498f633c1eb0498ad5fc74a3dc236d5520f41de15ec65cc70be16c657a3\n",
      "Stored in directory: /root/.cache/pip/wheels/91/e2/96/f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
      "Building wheel for lit (setup.py): started\n",
      "Building wheel for lit (setup.py): finished with status 'done'\n",
      "Created wheel for lit: filename=lit-16.0.5-py3-none-any.whl size=88174 sha256=9ff590ca07dffbe1cae11646f286e67638d7e6ff12704f3865d87b76e5535880\n",
      "Stored in directory: /root/.cache/pip/wheels/d8/3a/a1/643264c1075b22759205027b760e0b1e85d975bfb333eef328\n",
      "Building wheel for pathtools (setup.py): started\n",
      "Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=719dfd73f078d8e7cb6b792dfe68b0c98f91df1415effac29fc3f5356f978574\n",
      "Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
      "Successfully built deepspeed fengx-ai nvidia-ml-py3 seqeval ffmpy lit pathtools\n",
      "Installing collected packages: tokenizers, pydub, pathtools, nvidia-ml-py3, lit, ffmpy, bitsandbytes, websockets, uc-micro-py, torchview, torchinfo, tensorboard-data-server, sniffio, smmap, setproctitle, sentry-sdk, semantic-version, python-multipart, pyasn1-modules, orjson, oauthlib, mypy-extensions, mdurl, h11, grpcio, graphviz, fengx-ai, docker-pycreds, cachetools, aiofiles, absl-py, uvicorn, typing-inspect, triton, requests-oauthlib, markdown-it-py, linkify-it-py, huggingface-hub, google-auth, gitdb, functorch, deepspeed, anyio, accelerate, transformers, starlette, seqeval, pyre-extensions, mdit-py-plugins, httpcore, google-auth-oauthlib, GitPython, altair, xformers, wandb, tensorboard, peft, httpx, fastapi, trl, gradio-client, evaluate, gradio\n",
      "Attempting uninstall: tokenizers\n",
      "Found existing installation: tokenizers 0.13.2\n",
      "Uninstalling tokenizers-0.13.2:\n",
      "Successfully uninstalled tokenizers-0.13.2\n",
      "Attempting uninstall: huggingface-hub\n",
      "Found existing installation: huggingface-hub 0.12.0\n",
      "Uninstalling huggingface-hub-0.12.0:\n",
      "Successfully uninstalled huggingface-hub-0.12.0\n",
      "Attempting uninstall: deepspeed\n",
      "Found existing installation: deepspeed 0.6.1+06f2048\n",
      "Uninstalling deepspeed-0.6.1+06f2048:\n",
      "Successfully uninstalled deepspeed-0.6.1+06f2048\n",
      "Attempting uninstall: accelerate\n",
      "Found existing installation: accelerate 0.16.0\n",
      "Uninstalling accelerate-0.16.0:\n",
      "Successfully uninstalled accelerate-0.16.0\n",
      "Attempting uninstall: transformers\n",
      "Found existing installation: transformers 4.26.0\n",
      "Uninstalling transformers-4.26.0:\n",
      "Successfully uninstalled transformers-4.26.0\n",
      "Successfully installed GitPython-3.1.31 absl-py-1.4.0 accelerate-0.19.0 aiofiles-23.1.0 altair-5.0.0 anyio-3.6.2 bitsandbytes-0.39.0 cachetools-5.3.0 deepspeed-0.9.2 docker-pycreds-0.4.0 evaluate-0.4.0 fastapi-0.95.2 fengx-ai-0.0.1 ffmpy-0.3.0 functorch-1.13.1 gitdb-4.0.10 google-auth-2.19.0 google-auth-oauthlib-1.0.0 gradio-3.32.0 gradio-client-0.2.5 graphviz-0.20.1 grpcio-1.54.2 h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 huggingface-hub-0.14.1 linkify-it-py-2.0.2 lit-16.0.5 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 mypy-extensions-1.0.0 nvidia-ml-py3-7.352.0 oauthlib-3.2.2 orjson-3.8.14 pathtools-0.1.2 peft-0.2.0 pyasn1-modules-0.3.0 pydub-0.25.1 pyre-extensions-0.0.23 python-multipart-0.0.6 requests-oauthlib-1.3.1 semantic-version-2.10.0 sentry-sdk-1.24.0 seqeval-1.2.2 setproctitle-1.3.2 smmap-5.0.0 sniffio-1.3.0 starlette-0.27.0 tensorboard-2.13.0 tensorboard-data-server-0.7.0 tokenizers-0.13.3 torchinfo-1.8.0 torchview-0.2.6 transformers-4.28.1 triton-2.0.0.post1 trl-0.4.1 typing-inspect-0.9.0 uc-micro-py-1.0.2 uvicorn-0.22.0 wandb-0.15.3 websockets-11.0.3 xformers-0.0.16\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 23.0 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2023-05-26 10:02:56,294 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2023-05-26 10:02:56,294 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2023-05-26 10:02:56,316 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-05-26 10:02:56,349 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-05-26 10:02:56,382 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-05-26 10:02:56,395 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"clone_repo\": \"rjx/rjxai-lora-7b-v1\",\n",
      "        \"dataset_name\": \"rjx/ai-and-human-20\",\n",
      "        \"model_name_or_path\": \"rjx/rjxai-zh-llama-7b-v1\",\n",
      "        \"task_type\": \"text2text\",\n",
      "        \"training_model\": \"LLAMA\",\n",
      "        \"use_auth_token\": true\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2023-05-26-09-56-10-653\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-249450752701/huggingface-pytorch-training-2023-05-26-09-56-10-653/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"auto_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"auto_train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"clone_repo\":\"rjx/rjxai-lora-7b-v1\",\"dataset_name\":\"rjx/ai-and-human-20\",\"model_name_or_path\":\"rjx/rjxai-zh-llama-7b-v1\",\"task_type\":\"text2text\",\"training_model\":\"LLAMA\",\"use_auth_token\":true}\n",
      "SM_USER_ENTRY_POINT=auto_train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.p3.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=auto_train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-west-2-249450752701/huggingface-pytorch-training-2023-05-26-09-56-10-653/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"clone_repo\":\"rjx/rjxai-lora-7b-v1\",\"dataset_name\":\"rjx/ai-and-human-20\",\"model_name_or_path\":\"rjx/rjxai-zh-llama-7b-v1\",\"task_type\":\"text2text\",\"training_model\":\"LLAMA\",\"use_auth_token\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2023-05-26-09-56-10-653\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-249450752701/huggingface-pytorch-training-2023-05-26-09-56-10-653/source/sourcedir.tar.gz\",\"module_name\":\"auto_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"auto_train.py\"}\n",
      "SM_USER_ARGS=[\"--clone_repo\",\"rjx/rjxai-lora-7b-v1\",\"--dataset_name\",\"rjx/ai-and-human-20\",\"--model_name_or_path\",\"rjx/rjxai-zh-llama-7b-v1\",\"--task_type\",\"text2text\",\"--training_model\",\"LLAMA\",\"--use_auth_token\",\"True\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_CLONE_REPO=rjx/rjxai-lora-7b-v1\n",
      "SM_HP_DATASET_NAME=rjx/ai-and-human-20\n",
      "SM_HP_MODEL_NAME_OR_PATH=rjx/rjxai-zh-llama-7b-v1\n",
      "SM_HP_TASK_TYPE=text2text\n",
      "SM_HP_TRAINING_MODEL=LLAMA\n",
      "SM_HP_USE_AUTH_TOKEN=true\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.9 -m auto_train --clone_repo rjx/rjxai-lora-7b-v1 --dataset_name rjx/ai-and-human-20 --model_name_or_path rjx/rjxai-zh-llama-7b-v1 --task_type text2text --training_model LLAMA --use_auth_token True\n",
      "[2023-05-26 10:03:02.682: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "2023-05-26 10:03:02,688 root         INFO     Using NamedTuple = typing._NamedTuple instead.\n",
      "2023-05-26 10:03:02,710 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "wandb: Currently logged in as: fengx (feng-x). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.15.3\n",
      "wandb: Run data is saved locally in /opt/ml/code/wandb/run-20230526_100306-huggingface-pytorch-training-2023-05-26-09-56-10-653-v0baru-algo-1\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run huggingface-pytorch-training-2023-05-26-09-56-10-653-v0baru-algo-1\n",
      "wandb: â­ï¸ View project at https://wandb.ai/feng-x/uncategorized\n",
      "wandb: ğŸš€ View run at https://wandb.ai/feng-x/uncategorized/runs/huggingface-pytorch-training-2023-05-26-09-56-10-653-v0baru-algo-1\n",
      "2023-05-26 10:03:20,014,014 INFO     140340029425472 MainThread 193 [auto_train.py:33] ************ è½½å…¥LLAMAå‚æ•° *****************\n",
      "2023-05-26 10:03:20,024,024 INFO     140340029425472 MainThread 193 [auto_train.py:51] ModelArguments(model_name_or_path='rjx/rjxai-zh-llama-7b-v1', model_type='BERT', config_overrides=None, config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True, model_revision='main', use_auth_token=True, torch_dtype=None, low_cpu_mem_usage=False, hf_hub_token='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', write_hf_hub_token='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', task_type='text2text')\n",
      "2023-05-26 10:03:20,025,025 INFO     140340029425472 MainThread 193 [auto_train.py:52] DataTrainingArguments(dataset_name='rjx/ai-and-human-20', dataset_config_name=None, train_file=None, validation_file=None, max_train_samples=None, max_eval_samples=None, max_test_samples=None, streaming=False, block_size=None, overwrite_cache=False, validation_split_percentage=5, keep_linebreaks=True, index_input='text', index_output='labels')\n",
      "2023-05-26 10:03:20,025,025 INFO     140340029425472 MainThread 193 [auto_train.py:53] FxTrainingArguments(\n",
      "_n_gpu=-1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "clone_repo=rjx/rjxai-lora-7b-v1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=,\n",
      "deepspeed=None,\n",
      "disable_tqdm=None,\n",
      "do_accelerator=False,\n",
      "do_eval=True,\n",
      "do_load_dataset=True,\n",
      "do_peft=False,\n",
      "do_predict=True,\n",
      "do_save=True,\n",
      "do_train=True,\n",
      "do_visualization=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=,\n",
      "fsdp_config=None,\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=rjx/rjxai-lora-7b-v1,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=rjx/rjxai-lora-7b-v1/logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=accuracy,\n",
      "model_max_length=512,\n",
      "mp_parameters=,\n",
      "no_cuda=True,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=rjx/rjxai-lora-7b-v1,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "peft_path=None,\n",
      "per_device_eval_batch_size=2,\n",
      "per_device_train_batch_size=2,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=None,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "training_model=LLAMA,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "2023-05-26 10:03:20,026,026 INFO     140340029425472 MainThread 193 [auto_train.py:55] ************ é…ç½® logging *************\n",
      "2023-05-26 10:03:20,026,026 WARNING  140340029425472 MainThread 193 [auto_train.py:74] Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "2023-05-26 10:03:20,027,027 INFO     140340029425472 MainThread 193 [auto_train.py:78] Training/evaluation parameters FxTrainingArguments(\n",
      "_n_gpu=0,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "clone_repo=rjx/rjxai-lora-7b-v1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=,\n",
      "deepspeed=None,\n",
      "disable_tqdm=None,\n",
      "do_accelerator=False,\n",
      "do_eval=True,\n",
      "do_load_dataset=True,\n",
      "do_peft=False,\n",
      "do_predict=True,\n",
      "do_save=True,\n",
      "do_train=True,\n",
      "do_visualization=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=,\n",
      "fsdp_config=None,\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=rjx/rjxai-lora-7b-v1,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=rjx/rjxai-lora-7b-v1/logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=accuracy,\n",
      "model_max_length=512,\n",
      "mp_parameters=,\n",
      "no_cuda=True,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=rjx/rjxai-lora-7b-v1,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "peft_path=None,\n",
      "per_device_eval_batch_size=2,\n",
      "per_device_train_batch_size=2,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=None,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "training_model=LLAMA,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "2023-05-26 10:03:20,028,028 INFO     140340029425472 MainThread 193 [auto_train.py:80] ************ é‡‡ç”¨LLAMAè®­ç»ƒç±»å‹ ***********\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "python -m bitsandbytes\n",
      "and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117_nocublaslt.so\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /opt/conda/lib/python3.9/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('rjx/ai-and-human-20')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('us-west-2'), PosixPath('arn'), PosixPath('sagemaker'), PosixPath('249450752701'), PosixPath('aws'), PosixPath('training-job/huggingface-pytorch-training-2023-05-26-09-56-10-653')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/v2/credentials/proxy-e9f81410159ae2b3f874c0bd8bab20286b6b447fe05d2e0442a75dd0755e0ea4-customer')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//sagemaker-us-west-2-249450752701/huggingface-pytorch-training-2023-05-26-09-56-10-653/source/sourcedir.tar.gz'), PosixPath('s3')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('{},\"channel_input_dirs\"'), PosixPath('{},\"input_dir\"'), PosixPath('\"/opt/ml/model\",\"module_dir\"'), PosixPath('\"/opt/ml/input\",\"instance_groups\"'), PosixPath('\"ml.p3.2xlarge\",\"hosts\"'), PosixPath('false,\"is_master\"'), PosixPath('8,\"num_gpus\"'), PosixPath('\"eth0\"},\"user_entry_point\"'), PosixPath('true},\"input_config_dir\"'), PosixPath('true,\"job_name\"'), PosixPath('\"/opt/ml/output\",\"output_intermediate_dir\"'), PosixPath('{},\"current_host\"'), PosixPath('{\"additional_framework_parameters\"'), PosixPath('\"s3'), PosixPath('\"auto_train\",\"network_interface_name\"'), PosixPath('0,\"output_data_dir\"'), PosixPath('1,\"num_neurons\"'), PosixPath('\"homogeneousCluster\",\"instance_type\"'), PosixPath('\"rjx/rjxai-lora-7b-v1\",\"dataset_name\"'), PosixPath('//sagemaker-us-west-2-249450752701/huggingface-pytorch-training-2023-05-26-09-56-10-653/source/sourcedir.tar.gz\",\"module_name\"'), PosixPath('[\"algo-1\"],\"hyperparameters\"'), PosixPath('{\"hosts\"'), PosixPath('\"LLAMA\",\"use_auth_token\"'), PosixPath('\"algo-1\",\"model_dir\"'), PosixPath('20,\"master_hostname\"'), PosixPath('\"ml.p3.2xlarge\"}},\"is_hetero\"'), PosixPath('\"ml.p3.2xlarge\"}],\"network_interface_name\"'), PosixPath('\"eth0\",\"num_cpus\"'), PosixPath('{\"current_group_name\"'), PosixPath('[\"algo-1\"],\"instance_groups\"'), PosixPath('\"algo-1\",\"current_instance_type\"'), PosixPath('true,\"is_modelparallel_enabled\"'), PosixPath('\"auto_train.py\"}'), PosixPath('{\"homogeneousCluster\"'), PosixPath('[],\"framework_module\"'), PosixPath('\"algo-1\",\"current_instance_group\"'), PosixPath('{\"clone_repo\"'), PosixPath('\"ml.p3.2xlarge\",\"distribution_hosts\"'), PosixPath('[\"algo-1\"],\"instance_group_name\"'), PosixPath('\"huggingface-pytorch-training-2023-05-26-09-56-10-653\",\"log_level\"'), PosixPath('[],\"distribution_instance_groups\"'), PosixPath('\"sagemaker_pytorch_container.training'), PosixPath('[\"homogeneousCluster\"],\"instance_groups_dict\"'), PosixPath('\"rjx/ai-and-human-20\",\"model_name_or_path\"'), PosixPath('\"/opt/ml/output/data\",\"output_dir\"'), PosixPath('\"/opt/ml/output/intermediate\",\"resource_config\"'), PosixPath('main\",\"hosts\"'), PosixPath('null,\"is_smddpmprun_installed\"'), PosixPath('\"homogeneousCluster\",\"current_host\"'), PosixPath('\"text2text\",\"training_model\"'), PosixPath('[{\"hosts\"'), PosixPath('[\"algo-1\"],\"current_instance_type\"'), PosixPath('\"homogeneousCluster\",\"current_instance_group_hosts\"'), PosixPath('\"rjx/rjxai-zh-llama-7b-v1\",\"task_type\"'), PosixPath('\"/opt/ml/input/config\",\"input_data_config\"')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('\"rjx/rjxai-zh-llama-7b-v1\",\"task_type\"'), PosixPath('\"rjx/rjxai-lora-7b-v1\",\"dataset_name\"'), PosixPath('{\"clone_repo\"'), PosixPath('\"LLAMA\",\"use_auth_token\"'), PosixPath('\"text2text\",\"training_model\"'), PosixPath('true}'), PosixPath('\"rjx/ai-and-human-20\",\"model_name_or_path\"')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/opt/ml/output/intermediate')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('rjx/rjxai-lora-7b-v1')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/opt/conda/lib/python39.zip')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('[\"--clone_repo\",\"rjx/rjxai-lora-7b-v1\",\"--dataset_name\",\"rjx/ai-and-human-20\",\"--model_name_or_path\",\"rjx/rjxai-zh-llama-7b-v1\",\"--task_type\",\"text2text\",\"--training_model\",\"LLAMA\",\"--use_auth_token\",\"True\"]')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('rjx/rjxai-zh-llama-7b-v1')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('$(dirname $(which conda))/..')}\n",
      "  warn(msg)\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117_nocublaslt.so...\n",
      "2023-05-26 10:03:26,390,390 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:45] **************** è½½å…¥æ¨¡å‹ï¼šè½½å…¥åˆ†è¯å™¨/è½½å…¥æ¨¡å‹ ********************\n",
      "2023-05-26 10:03:26,391,391 INFO     140340029425472 MainThread 193 [print_utils.py:34] CPU ä¸ªæ•°: 8\n",
      "2023-05-26 10:03:26,391,391 INFO     140340029425472 MainThread 193 [print_utils.py:35] CPU memory total: 59.83776092529297 GB.\n",
      "2023-05-26 10:03:26,391,391 INFO     140340029425472 MainThread 193 [print_utils.py:36] CPU memory use: 2.0367813110351562 GB.\n",
      "2023-05-26 10:03:26,392,392 INFO     140340029425472 MainThread 193 [print_utils.py:37] CPU memory free: 39.74940872192383 GB.\n",
      "2023-05-26 10:03:26,392,392 INFO     140340029425472 MainThread 193 [print_utils.py:38] CPU memory use percent: 4.5 %\n",
      "2023-05-26 10:03:26,392,392 INFO     140340029425472 MainThread 193 [print_utils.py:17] Driver Version: b'525.85.12'\n",
      "2023-05-26 10:03:26,393,393 INFO     140340029425472 MainThread 193 [print_utils.py:21] Device 0 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-26 10:03:26,393,393 INFO     140340029425472 MainThread 193 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-26 10:03:26,393,393 INFO     140340029425472 MainThread 193 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2303466796875 GB.\n",
      "2023-05-26 10:03:26,394,394 INFO     140340029425472 MainThread 193 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7696533203125 GB.\n",
      "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/538 [00:00<?, ?B/s]\n",
      "Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 538/538 [00:00<00:00, 70.3kB/s]\n",
      "2023-05-26 10:03:26,670,670 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:56] é€šè¿‡configåŠ è½½æ¨¡å‹ï¼Œé€šè¿‡model_args.model_name_or_pathåŠ è½½å¯¹åº”æ¨¡å‹çš„æƒé‡\n",
      "Downloading (â€¦)model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]\n",
      "Downloading (â€¦)model.bin.index.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.8k/26.8k [00:00<00:00, 3.69MB/s]\n",
      "Downloading shards:   0%|          | 0/29 [00:00<?, ?it/s]\n",
      "Downloading (â€¦)l-00001-of-00029.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:   2%|â–         | 10.5M/510M [00:00<00:05, 86.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:   4%|â–         | 21.0M/510M [00:00<00:05, 93.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:   6%|â–Œ         | 31.5M/510M [00:00<00:04, 97.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:   8%|â–Š         | 41.9M/510M [00:00<00:05, 93.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  10%|â–ˆ         | 52.4M/510M [00:00<00:04, 95.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  12%|â–ˆâ–        | 62.9M/510M [00:00<00:04, 95.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  14%|â–ˆâ–        | 73.4M/510M [00:00<00:04, 95.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  16%|â–ˆâ–‹        | 83.9M/510M [00:00<00:04, 96.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  19%|â–ˆâ–Š        | 94.4M/510M [00:00<00:04, 96.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/510M [00:01<00:04, 96.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/510M [00:01<00:04, 96.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  25%|â–ˆâ–ˆâ–       | 126M/510M [00:01<00:04, 95.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  27%|â–ˆâ–ˆâ–‹       | 136M/510M [00:01<00:03, 96.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  29%|â–ˆâ–ˆâ–‰       | 147M/510M [00:01<00:03, 97.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 157M/510M [00:01<00:03, 97.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 168M/510M [00:01<00:03, 97.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  35%|â–ˆâ–ˆâ–ˆâ–      | 178M/510M [00:01<00:03, 96.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 189M/510M [00:01<00:03, 95.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 199M/510M [00:02<00:03, 89.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 210M/510M [00:02<00:03, 86.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/510M [00:02<00:03, 89.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231M/510M [00:02<00:03, 91.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 241M/510M [00:02<00:02, 92.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 252M/510M [00:02<00:02, 94.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/510M [00:02<00:02, 94.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273M/510M [00:02<00:02, 95.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 283M/510M [00:02<00:02, 95.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 294M/510M [00:03<00:02, 96.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 304M/510M [00:03<00:02, 98.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/510M [00:03<00:02, 96.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 325M/510M [00:03<00:01, 96.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 336M/510M [00:03<00:01, 96.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 346M/510M [00:03<00:01, 96.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 357M/510M [00:03<00:01, 96.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 377M/510M [00:03<00:01, 98.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 388M/510M [00:04<00:01, 95.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 398M/510M [00:04<00:01, 96.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 409M/510M [00:04<00:01, 89.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/510M [00:04<00:00, 91.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 430M/510M [00:04<00:00, 92.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 440M/510M [00:04<00:00, 94.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 451M/510M [00:04<00:00, 96.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 461M/510M [00:04<00:00, 96.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472M/510M [00:04<00:00, 97.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 482M/510M [00:05<00:00, 97.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 493M/510M [00:05<00:00, 98.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 503M/510M [00:05<00:00, 98.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00001-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 510M/510M [00:05<00:00, 95.3MB/s]\n",
      "Downloading shards:   3%|â–         | 1/29 [00:05<02:35,  5.55s/it]\n",
      "Downloading (â€¦)l-00002-of-00029.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:   2%|â–         | 10.5M/438M [00:00<00:09, 45.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:   5%|â–         | 21.0M/438M [00:00<00:07, 58.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:   7%|â–‹         | 31.5M/438M [00:00<00:06, 64.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  10%|â–‰         | 41.9M/438M [00:00<00:05, 70.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  12%|â–ˆâ–        | 52.4M/438M [00:00<00:05, 72.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  14%|â–ˆâ–        | 62.9M/438M [00:00<00:05, 73.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  17%|â–ˆâ–‹        | 73.4M/438M [00:01<00:04, 74.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  19%|â–ˆâ–‰        | 83.9M/438M [00:01<00:04, 74.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  22%|â–ˆâ–ˆâ–       | 94.4M/438M [00:01<00:04, 75.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  24%|â–ˆâ–ˆâ–       | 105M/438M [00:01<00:04, 73.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  26%|â–ˆâ–ˆâ–‹       | 115M/438M [00:01<00:05, 59.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  29%|â–ˆâ–ˆâ–Š       | 126M/438M [00:01<00:04, 63.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 136M/438M [00:02<00:04, 67.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 147M/438M [00:02<00:04, 69.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 157M/438M [00:02<00:04, 70.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 168M/438M [00:02<00:03, 68.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 178M/438M [00:02<00:03, 70.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 189M/438M [00:02<00:04, 61.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 199M/438M [00:02<00:03, 65.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 210M/438M [00:03<00:03, 67.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 220M/438M [00:03<00:03, 70.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 231M/438M [00:03<00:02, 72.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 241M/438M [00:03<00:02, 73.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 252M/438M [00:03<00:03, 62.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 262M/438M [00:03<00:02, 63.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 273M/438M [00:04<00:02, 67.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 283M/438M [00:04<00:02, 70.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 294M/438M [00:04<00:02, 71.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 304M/438M [00:04<00:01, 71.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 315M/438M [00:04<00:01, 73.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 325M/438M [00:04<00:01, 73.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 336M/438M [00:04<00:01, 71.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 346M/438M [00:05<00:01, 70.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 357M/438M [00:05<00:01, 72.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 367M/438M [00:05<00:00, 73.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 377M/438M [00:05<00:00, 74.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 388M/438M [00:05<00:00, 75.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 398M/438M [00:05<00:00, 76.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 409M/438M [00:05<00:00, 69.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 419M/438M [00:06<00:00, 59.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 430M/438M [00:06<00:00, 63.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438M/438M [00:06<00:00, 66.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00002-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438M/438M [00:06<00:00, 68.7MB/s]\n",
      "Downloading shards:   7%|â–‹         | 2/29 [00:12<02:44,  6.10s/it]\n",
      "Downloading (â€¦)l-00003-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:05, 96.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:05, 94.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:00<00:04, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:04, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  13%|â–ˆâ–        | 62.9M/495M [00:00<00:04, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:04, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:00<00:04, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:00<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [00:01<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:03, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:01<00:03, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:03, 99.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:03, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [00:01<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:01<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:01<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:02<00:03, 72.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:03, 77.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:02<00:02, 83.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:02<00:02, 88.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:02<00:02, 91.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:02<00:02, 94.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:03<00:02, 96.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:03<00:01, 99.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:03<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:03<00:01, 96.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:03<00:01, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:04<00:00, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:04<00:00, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:04<00:00, 105MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:04<00:00, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:04<00:00, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00003-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:05<00:00, 98.9MB/s]\n",
      "Downloading shards:  10%|â–ˆ         | 3/29 [00:17<02:26,  5.65s/it]\n",
      "Downloading (â€¦)l-00004-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:05, 94.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:04, 97.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:00<00:04, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:04, 99.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  13%|â–ˆâ–        | 62.9M/495M [00:00<00:04, 97.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:04, 97.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:00<00:04, 97.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:00<00:04, 97.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [00:01<00:04, 96.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:03, 96.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:01<00:03, 96.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:03, 94.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:03, 95.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [00:01<00:03, 96.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:03, 96.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:01<00:03, 92.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:01<00:03, 94.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:02<00:03, 93.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:02<00:02, 95.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:02<00:02, 93.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:02<00:02, 94.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:02, 93.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:02<00:02, 95.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:02<00:02, 96.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:02<00:02, 96.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:02<00:02, 96.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:03<00:02, 96.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:03<00:01, 97.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:03<00:01, 98.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:03<00:01, 99.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:03<00:01, 95.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:03<00:01, 92.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:03<00:01, 92.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:03<00:01, 92.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:03<00:01, 91.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:04<00:01, 92.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [00:04<00:01, 92.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:04<00:00, 93.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:04<00:00, 94.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:04<00:00, 94.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440M/495M [00:04<00:00, 95.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:04<00:00, 97.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:04<00:00, 97.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:04<00:00, 97.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:05<00:00, 97.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:05<00:00, 97.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00004-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:05<00:00, 95.7MB/s]\n",
      "Downloading shards:  14%|â–ˆâ–        | 4/29 [00:22<02:17,  5.51s/it]\n",
      "Downloading (â€¦)l-00005-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:06, 73.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:06, 75.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:   6%|â–‹         | 31.5M/495M [00:00<00:06, 76.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:00<00:05, 77.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:05, 79.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  13%|â–ˆâ–        | 62.9M/495M [00:00<00:05, 77.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:05, 73.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:01<00:05, 72.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:01<00:05, 73.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [00:01<00:05, 73.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:05, 70.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:01<00:05, 69.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:04, 72.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:04, 73.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [00:02<00:05, 60.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:02<00:05, 58.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:02<00:05, 62.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:02<00:04, 66.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:02<00:04, 68.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:02<00:03, 71.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:03<00:03, 74.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:03<00:03, 74.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:03<00:03, 73.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:03<00:04, 58.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:03<00:02, 76.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:03<00:02, 75.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:04<00:02, 73.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:04<00:02, 72.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:04<00:02, 73.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:04<00:02, 72.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:04<00:02, 72.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:04<00:02, 74.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:05<00:01, 69.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:05<00:01, 71.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:05<00:01, 73.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:05<00:01, 74.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [00:05<00:01, 75.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:05<00:01, 74.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:05<00:01, 74.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:05<00:00, 75.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440M/495M [00:06<00:00, 76.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:06<00:00, 74.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:06<00:00, 75.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:06<00:00, 75.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:06<00:00, 73.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:06<00:00, 74.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00005-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:06<00:00, 72.2MB/s]\n",
      "Downloading shards:  17%|â–ˆâ–‹        | 5/29 [00:29<02:24,  6.03s/it]\n",
      "Downloading (â€¦)l-00006-of-00029.bin:   0%|          | 0.00/505M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:   2%|â–         | 10.5M/505M [00:00<00:06, 74.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:   4%|â–         | 21.0M/505M [00:00<00:06, 76.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:   6%|â–Œ         | 31.5M/505M [00:00<00:06, 78.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:   8%|â–Š         | 41.9M/505M [00:00<00:06, 72.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  10%|â–ˆ         | 52.4M/505M [00:00<00:06, 72.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  12%|â–ˆâ–        | 62.9M/505M [00:00<00:06, 68.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  15%|â–ˆâ–        | 73.4M/505M [00:01<00:06, 71.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/505M [00:01<00:05, 72.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  19%|â–ˆâ–Š        | 94.4M/505M [00:01<00:05, 73.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/505M [00:01<00:05, 76.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/505M [00:01<00:05, 77.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  25%|â–ˆâ–ˆâ–       | 126M/505M [00:01<00:04, 77.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  27%|â–ˆâ–ˆâ–‹       | 136M/505M [00:01<00:04, 76.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  29%|â–ˆâ–ˆâ–‰       | 147M/505M [00:01<00:04, 77.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 157M/505M [00:02<00:04, 78.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 168M/505M [00:02<00:04, 78.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/505M [00:02<00:04, 78.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 189M/505M [00:02<00:04, 77.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 199M/505M [00:02<00:03, 77.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/505M [00:02<00:03, 77.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/505M [00:02<00:03, 76.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231M/505M [00:03<00:03, 76.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/505M [00:03<00:03, 75.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 252M/505M [00:03<00:03, 67.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/505M [00:03<00:03, 69.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273M/505M [00:03<00:03, 61.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 283M/505M [00:03<00:03, 65.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 294M/505M [00:04<00:03, 68.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304M/505M [00:04<00:02, 68.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/505M [00:04<00:03, 60.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 325M/505M [00:04<00:02, 66.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336M/505M [00:04<00:02, 69.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 346M/505M [00:04<00:02, 71.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 357M/505M [00:04<00:02, 73.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/505M [00:05<00:01, 70.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 377M/505M [00:05<00:01, 71.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 388M/505M [00:05<00:01, 74.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398M/505M [00:05<00:01, 75.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 409M/505M [00:05<00:01, 76.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/505M [00:05<00:01, 77.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430M/505M [00:05<00:01, 75.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 440M/505M [00:06<00:00, 76.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 451M/505M [00:06<00:00, 73.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/505M [00:06<00:00, 68.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472M/505M [00:06<00:00, 66.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 482M/505M [00:06<00:00, 69.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493M/505M [00:06<00:00, 71.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 503M/505M [00:06<00:00, 73.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00006-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 505M/505M [00:06<00:00, 72.7MB/s]\n",
      "Downloading shards:  21%|â–ˆâ–ˆ        | 6/29 [00:36<02:26,  6.39s/it]\n",
      "Downloading (â€¦)l-00007-of-00029.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:   2%|â–         | 10.5M/438M [00:00<00:04, 87.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:   5%|â–         | 21.0M/438M [00:00<00:04, 85.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:   7%|â–‹         | 31.5M/438M [00:00<00:04, 92.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  10%|â–‰         | 41.9M/438M [00:00<00:04, 93.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  12%|â–ˆâ–        | 52.4M/438M [00:00<00:04, 78.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  14%|â–ˆâ–        | 62.9M/438M [00:00<00:04, 80.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  17%|â–ˆâ–‹        | 73.4M/438M [00:00<00:04, 85.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  19%|â–ˆâ–‰        | 83.9M/438M [00:00<00:03, 89.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  22%|â–ˆâ–ˆâ–       | 94.4M/438M [00:01<00:03, 91.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  24%|â–ˆâ–ˆâ–       | 105M/438M [00:01<00:03, 93.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  26%|â–ˆâ–ˆâ–‹       | 115M/438M [00:01<00:03, 83.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  29%|â–ˆâ–ˆâ–Š       | 126M/438M [00:01<00:03, 87.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 136M/438M [00:01<00:03, 89.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 147M/438M [00:01<00:03, 91.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 157M/438M [00:01<00:03, 81.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 178M/438M [00:02<00:02, 88.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 189M/438M [00:02<00:02, 91.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 199M/438M [00:02<00:02, 93.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 210M/438M [00:02<00:02, 93.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 220M/438M [00:02<00:02, 93.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 231M/438M [00:02<00:02, 90.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 241M/438M [00:02<00:02, 85.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 252M/438M [00:02<00:02, 81.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 262M/438M [00:02<00:02, 85.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 273M/438M [00:03<00:01, 88.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 283M/438M [00:03<00:01, 89.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 294M/438M [00:03<00:01, 83.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 304M/438M [00:03<00:01, 86.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 315M/438M [00:03<00:01, 87.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 325M/438M [00:03<00:01, 87.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 336M/438M [00:03<00:01, 84.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 346M/438M [00:03<00:01, 85.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 357M/438M [00:04<00:00, 84.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 367M/438M [00:04<00:00, 88.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 377M/438M [00:04<00:00, 90.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 388M/438M [00:04<00:00, 92.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 398M/438M [00:04<00:00, 93.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 409M/438M [00:04<00:00, 86.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 419M/438M [00:04<00:00, 88.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 430M/438M [00:04<00:00, 85.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00007-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438M/438M [00:04<00:00, 87.8MB/s]\n",
      "Downloading shards:  24%|â–ˆâ–ˆâ–       | 7/29 [00:41<02:11,  5.97s/it]\n",
      "Downloading (â€¦)l-00008-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:05, 88.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:05, 91.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:   6%|â–‹         | 31.5M/495M [00:00<00:04, 97.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:00<00:04, 92.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:04, 94.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  13%|â–ˆâ–        | 62.9M/495M [00:00<00:04, 93.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:04, 95.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:00<00:04, 96.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:01<00:04, 93.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [00:01<00:04, 95.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:04, 94.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:03, 96.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:03, 93.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [00:01<00:03, 92.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:03, 93.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:01<00:03, 94.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:02<00:03, 95.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:02<00:03, 96.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:02<00:02, 96.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:02<00:02, 96.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:02<00:02, 96.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:02, 96.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:02<00:02, 95.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:02<00:02, 95.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:02<00:02, 95.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:02<00:02, 96.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:03<00:02, 97.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:03<00:01, 96.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:03<00:01, 93.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:03<00:01, 92.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:03<00:01, 89.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:03<00:01, 91.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:03<00:01, 88.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:04<00:01, 92.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:04<00:01, 86.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [00:04<00:01, 90.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:04<00:00, 92.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:04<00:00, 92.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:04<00:00, 93.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440M/495M [00:04<00:00, 94.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:04<00:00, 95.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:04<00:00, 97.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:05<00:00, 97.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:05<00:00, 97.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:05<00:00, 98.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00008-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:05<00:00, 94.3MB/s]\n",
      "Downloading shards:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:46<02:01,  5.77s/it]\n",
      "Downloading (â€¦)l-00009-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:06, 80.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:05, 90.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:   6%|â–‹         | 31.5M/495M [00:00<00:05, 92.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:00<00:04, 95.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:04, 92.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:04, 97.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:00<00:04, 98.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:00<00:04, 97.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [00:01<00:03, 97.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:03, 96.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:01<00:03, 95.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:03, 96.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:03, 94.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:03, 97.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:01<00:03, 97.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:01<00:03, 97.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:02<00:03, 97.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:02<00:02, 97.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:02<00:02, 97.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:02<00:02, 96.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:02, 97.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:02<00:02, 97.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:02<00:02, 97.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:02<00:02, 97.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:02<00:02, 97.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:03<00:02, 97.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:03<00:01, 97.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:03<00:02, 79.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:03<00:01, 99.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:03<00:01, 98.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:03<00:01, 97.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:03<00:01, 97.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:03<00:01, 96.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:04<00:01, 97.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [00:04<00:00, 97.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:04<00:00, 97.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:04<00:00, 95.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:04<00:01, 63.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:04<00:00, 96.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:04<00:00, 97.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:05<00:00, 97.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:05<00:00, 96.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00009-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:05<00:00, 95.2MB/s]\n",
      "Downloading shards:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:52<01:52,  5.63s/it]\n",
      "Downloading (â€¦)l-00010-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:05, 92.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:   6%|â–‹         | 31.5M/495M [00:00<00:04, 105MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:04, 105MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  13%|â–ˆâ–        | 62.9M/495M [00:00<00:04, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:00<00:03, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:00<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:03, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:01<00:03, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:03, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [00:01<00:03, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:03, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:01<00:03, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:01<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:02<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:02<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:02<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:02<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:02<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:02<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:03<00:01, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:03<00:00, 105MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:04<00:00, 105MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:04<00:00, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:04<00:00, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:04<00:00, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:04<00:00, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00010-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:04<00:00, 103MB/s]\n",
      "Downloading shards:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:57<01:42,  5.41s/it]\n",
      "Downloading (â€¦)l-00011-of-00029.bin:   0%|          | 0.00/505M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:   2%|â–         | 10.5M/505M [00:00<00:05, 83.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:   4%|â–         | 21.0M/505M [00:00<00:05, 90.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:   6%|â–Œ         | 31.5M/505M [00:00<00:05, 94.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:   8%|â–Š         | 41.9M/505M [00:00<00:04, 94.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  10%|â–ˆ         | 52.4M/505M [00:00<00:04, 91.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  15%|â–ˆâ–        | 73.4M/505M [00:00<00:04, 95.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/505M [00:00<00:04, 96.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  19%|â–ˆâ–Š        | 94.4M/505M [00:00<00:04, 96.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/505M [00:01<00:04, 96.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/505M [00:01<00:04, 96.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  25%|â–ˆâ–ˆâ–       | 126M/505M [00:01<00:03, 97.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  27%|â–ˆâ–ˆâ–‹       | 136M/505M [00:01<00:03, 97.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  29%|â–ˆâ–ˆâ–‰       | 147M/505M [00:01<00:03, 93.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 157M/505M [00:01<00:03, 96.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 168M/505M [00:01<00:03, 94.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/505M [00:01<00:03, 92.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 189M/505M [00:01<00:03, 95.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 199M/505M [00:02<00:03, 94.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/505M [00:02<00:03, 96.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/505M [00:02<00:02, 96.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231M/505M [00:02<00:02, 97.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/505M [00:02<00:02, 97.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 252M/505M [00:02<00:02, 97.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/505M [00:02<00:02, 95.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273M/505M [00:02<00:02, 96.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 283M/505M [00:02<00:02, 96.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 294M/505M [00:03<00:02, 96.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304M/505M [00:03<00:02, 94.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/505M [00:03<00:02, 94.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 325M/505M [00:03<00:01, 93.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336M/505M [00:03<00:01, 94.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 346M/505M [00:03<00:01, 91.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 357M/505M [00:03<00:01, 91.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/505M [00:03<00:01, 92.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 377M/505M [00:03<00:01, 94.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 388M/505M [00:04<00:01, 95.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398M/505M [00:04<00:01, 94.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 409M/505M [00:04<00:01, 94.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/505M [00:04<00:00, 93.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430M/505M [00:04<00:00, 94.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 440M/505M [00:04<00:00, 94.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 451M/505M [00:04<00:00, 95.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/505M [00:04<00:00, 93.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472M/505M [00:04<00:00, 94.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 482M/505M [00:05<00:00, 94.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493M/505M [00:05<00:00, 95.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 503M/505M [00:05<00:00, 95.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00011-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 505M/505M [00:05<00:00, 95.0MB/s]\n",
      "Downloading shards:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [01:02<01:37,  5.42s/it]\n",
      "Downloading (â€¦)l-00012-of-00029.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:   2%|â–         | 10.5M/438M [00:00<00:04, 95.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:   7%|â–‹         | 31.5M/438M [00:00<00:03, 105MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  12%|â–ˆâ–        | 52.4M/438M [00:00<00:03, 105MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  14%|â–ˆâ–        | 62.9M/438M [00:00<00:05, 67.8MB/s]#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  22%|â–ˆâ–ˆâ–       | 94.4M/438M [00:00<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  26%|â–ˆâ–ˆâ–‹       | 115M/438M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 136M/438M [00:01<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 157M/438M [00:01<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 178M/438M [00:01<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 199M/438M [00:01<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 220M/438M [00:02<00:02, 99.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 231M/438M [00:02<00:02, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 241M/438M [00:02<00:01, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 262M/438M [00:02<00:01, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 283M/438M [00:02<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 294M/438M [00:02<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 304M/438M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 315M/438M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 325M/438M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 336M/438M [00:03<00:01, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 346M/438M [00:03<00:00, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 367M/438M [00:03<00:00, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 388M/438M [00:03<00:00, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 398M/438M [00:03<00:00, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 409M/438M [00:04<00:00, 99.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 419M/438M [00:04<00:00, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 430M/438M [00:04<00:00, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00012-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438M/438M [00:04<00:00, 101MB/s]\n",
      "Downloading shards:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [01:07<01:27,  5.13s/it]\n",
      "Downloading (â€¦)l-00013-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:18, 26.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:17, 26.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:   6%|â–‹         | 31.5M/495M [00:01<00:16, 27.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:01<00:16, 26.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:01<00:16, 26.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  13%|â–ˆâ–        | 62.9M/495M [00:02<00:16, 26.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:02<00:15, 26.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:03<00:15, 26.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:03<00:14, 26.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [00:03<00:14, 27.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:04<00:13, 27.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:04<00:13, 27.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:05<00:13, 27.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:05<00:12, 27.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [00:05<00:12, 27.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:06<00:11, 28.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:06<00:11, 27.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:06<00:11, 27.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:07<00:10, 27.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:07<00:10, 27.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:08<00:10, 27.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:08<00:09, 27.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:08<00:09, 27.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:09<00:08, 27.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:09<00:08, 27.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:10<00:08, 25.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:10<00:07, 27.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:10<00:07, 25.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:11<00:07, 26.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:11<00:06, 27.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:12<00:06, 27.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:12<00:05, 27.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:12<00:05, 27.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:13<00:05, 27.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:13<00:04, 27.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:13<00:04, 27.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:14<00:03, 27.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [00:14<00:03, 27.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:15<00:03, 27.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:15<00:02, 27.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:15<00:02, 27.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440M/495M [00:16<00:01, 27.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:16<00:01, 27.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:16<00:01, 26.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:17<00:00, 26.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:17<00:00, 28.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:18<00:00, 28.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00013-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:18<00:00, 27.2MB/s]\n",
      "Downloading shards:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [01:25<02:25,  9.11s/it]\n",
      "Downloading (â€¦)l-00014-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:   2%|â–         | 10.5M/495M [00:04<03:35, 2.25MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:   4%|â–         | 21.0M/495M [00:10<03:56, 2.00MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:   6%|â–‹         | 31.5M/495M [00:15<03:59, 1.94MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:22<04:07, 1.83MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:28<04:17, 1.72MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  13%|â–ˆâ–        | 62.9M/495M [00:36<04:38, 1.55MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:44<04:36, 1.53MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:48<04:04, 1.68MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:55<04:04, 1.64MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [01:01<03:52, 1.68MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [01:07<03:42, 1.71MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [01:12<03:28, 1.77MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [01:18<03:23, 1.76MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [01:23<02:59, 1.93MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [01:28<02:53, 1.94MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [01:34<02:54, 1.87MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [01:41<02:58, 1.77MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [01:47<02:58, 1.72MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [01:54<03:02, 1.62MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [02:01<02:58, 1.60MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [02:08<02:51, 1.60MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [02:14<02:43, 1.62MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [02:18<02:18, 1.84MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [02:23<02:08, 1.89MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [02:29<02:05, 1.85MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [02:37<02:11, 1.69MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [02:44<02:10, 1.62MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [02:51<02:09, 1.55MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [02:58<02:05, 1.52MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [03:06<02:02, 1.47MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [03:14<01:57, 1.44MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [03:21<01:53, 1.41MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [03:31<01:53, 1.32MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [03:38<01:44, 1.33MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [03:45<01:32, 1.38MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [03:53<01:25, 1.38MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [04:00<01:16, 1.40MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [04:08<01:09, 1.40MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [04:15<01:01, 1.40MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [04:23<00:53, 1.40MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [04:30<00:46, 1.40MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440M/495M [04:37<00:38, 1.41MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [04:45<00:32, 1.38MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [04:52<00:23, 1.41MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [05:00<00:16, 1.41MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [05:07<00:08, 1.41MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [05:14<00:01, 1.43MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [05:16<00:00, 1.44MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00014-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [05:16<00:00, 1.56MB/s]\n",
      "Downloading shards:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [06:41<25:28, 101.92s/it]\n",
      "Downloading (â€¦)l-00015-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:08, 56.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:   6%|â–‹         | 31.5M/495M [00:00<00:04, 98.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:00<00:04, 97.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:04, 96.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  13%|â–ˆâ–        | 62.9M/495M [00:00<00:04, 95.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:04, 96.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:00<00:04, 96.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:01<00:04, 93.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [00:01<00:04, 89.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:04, 90.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:01<00:05, 63.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:05, 71.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:04, 77.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [00:01<00:04, 81.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:03, 83.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:02<00:03, 85.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:02<00:03, 86.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:02<00:03, 87.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:02<00:03, 89.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:02<00:03, 88.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:02<00:02, 90.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:02, 88.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:02<00:02, 89.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:03<00:02, 91.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:03<00:02, 91.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:03<00:02, 90.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:03<00:02, 86.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:03<00:02, 87.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:03<00:02, 89.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:03<00:01, 89.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:03<00:01, 90.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:03<00:01, 91.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:04<00:01, 93.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:04<00:01, 94.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:04<00:01, 91.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:04<00:01, 92.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [00:04<00:01, 93.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:04<00:00, 94.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:04<00:00, 95.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:04<00:00, 95.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440M/495M [00:04<00:00, 95.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:05<00:00, 95.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:05<00:00, 93.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:05<00:00, 94.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:05<00:00, 86.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:05<00:00, 87.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00015-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:05<00:00, 88.9MB/s]\n",
      "Downloading shards:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [06:47<17:01, 72.93s/it]\n",
      "Downloading (â€¦)l-00016-of-00029.bin:   0%|          | 0.00/505M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:   2%|â–         | 10.5M/505M [00:00<00:05, 82.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:   4%|â–         | 21.0M/505M [00:00<00:05, 86.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:   6%|â–Œ         | 31.5M/505M [00:00<00:05, 91.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:   8%|â–Š         | 41.9M/505M [00:00<00:05, 88.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  10%|â–ˆ         | 52.4M/505M [00:00<00:05, 87.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  12%|â–ˆâ–        | 62.9M/505M [00:00<00:05, 86.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  15%|â–ˆâ–        | 73.4M/505M [00:00<00:05, 86.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/505M [00:00<00:04, 87.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  19%|â–ˆâ–Š        | 94.4M/505M [00:01<00:04, 90.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/505M [00:01<00:04, 92.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/505M [00:01<00:04, 92.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  25%|â–ˆâ–ˆâ–       | 126M/505M [00:01<00:04, 93.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  27%|â–ˆâ–ˆâ–‹       | 136M/505M [00:01<00:03, 94.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  29%|â–ˆâ–ˆâ–‰       | 147M/505M [00:01<00:03, 94.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 157M/505M [00:01<00:03, 91.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 168M/505M [00:01<00:03, 88.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/505M [00:02<00:03, 85.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 189M/505M [00:02<00:03, 87.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 199M/505M [00:02<00:03, 85.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/505M [00:02<00:03, 82.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/505M [00:02<00:03, 83.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231M/505M [00:02<00:03, 86.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/505M [00:02<00:03, 86.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 252M/505M [00:02<00:02, 85.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/505M [00:02<00:02, 83.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273M/505M [00:03<00:02, 87.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 283M/505M [00:03<00:02, 89.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 294M/505M [00:03<00:02, 90.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304M/505M [00:03<00:02, 92.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/505M [00:03<00:02, 91.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 325M/505M [00:03<00:01, 90.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336M/505M [00:03<00:01, 91.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 346M/505M [00:03<00:01, 91.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 357M/505M [00:04<00:01, 91.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/505M [00:04<00:01, 88.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 377M/505M [00:04<00:01, 90.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 388M/505M [00:04<00:01, 91.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398M/505M [00:04<00:01, 91.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 409M/505M [00:04<00:01, 91.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/505M [00:04<00:00, 88.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430M/505M [00:04<00:00, 89.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 440M/505M [00:04<00:00, 91.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 451M/505M [00:05<00:00, 90.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/505M [00:05<00:00, 91.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472M/505M [00:05<00:00, 89.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 482M/505M [00:05<00:00, 91.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493M/505M [00:05<00:00, 91.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 503M/505M [00:05<00:00, 92.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00016-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 505M/505M [00:05<00:00, 89.4MB/s]\n",
      "Downloading shards:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [06:53<11:25, 52.71s/it]\n",
      "Downloading (â€¦)l-00017-of-00029.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:   2%|â–         | 10.5M/438M [00:00<00:04, 98.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:   7%|â–‹         | 31.5M/438M [00:00<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  10%|â–‰         | 41.9M/438M [00:00<00:04, 95.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  12%|â–ˆâ–        | 52.4M/438M [00:00<00:04, 93.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  14%|â–ˆâ–        | 62.9M/438M [00:00<00:03, 94.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  17%|â–ˆâ–‹        | 73.4M/438M [00:00<00:03, 96.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  19%|â–ˆâ–‰        | 83.9M/438M [00:00<00:03, 97.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  22%|â–ˆâ–ˆâ–       | 94.4M/438M [00:00<00:03, 98.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  24%|â–ˆâ–ˆâ–       | 105M/438M [00:01<00:03, 98.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  26%|â–ˆâ–ˆâ–‹       | 115M/438M [00:01<00:03, 99.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  29%|â–ˆâ–ˆâ–Š       | 126M/438M [00:01<00:03, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 136M/438M [00:01<00:03, 85.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 147M/438M [00:01<00:03, 89.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 157M/438M [00:01<00:03, 92.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 168M/438M [00:01<00:02, 95.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 178M/438M [00:01<00:02, 97.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 189M/438M [00:01<00:02, 94.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 210M/438M [00:02<00:02, 99.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 220M/438M [00:02<00:02, 99.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 231M/438M [00:02<00:02, 99.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 241M/438M [00:02<00:02, 92.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 252M/438M [00:02<00:01, 94.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 262M/438M [00:02<00:01, 93.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 273M/438M [00:02<00:01, 93.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 283M/438M [00:02<00:01, 95.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 294M/438M [00:03<00:01, 97.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 304M/438M [00:03<00:01, 98.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 315M/438M [00:03<00:01, 99.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 325M/438M [00:03<00:01, 99.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 336M/438M [00:03<00:01, 95.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 346M/438M [00:03<00:00, 97.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 357M/438M [00:03<00:00, 97.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 367M/438M [00:03<00:00, 98.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 377M/438M [00:03<00:00, 98.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 388M/438M [00:04<00:00, 98.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 398M/438M [00:04<00:00, 98.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 409M/438M [00:04<00:00, 98.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 419M/438M [00:04<00:00, 99.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 430M/438M [00:04<00:00, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00017-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438M/438M [00:04<00:00, 96.0MB/s]\n",
      "Downloading shards:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [06:57<07:39, 38.27s/it]\n",
      "Downloading (â€¦)l-00018-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:05, 95.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:04, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:00<00:04, 105MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:04, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  13%|â–ˆâ–        | 62.9M/495M [00:00<00:04, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:04, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:00<00:03, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:00<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:03, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:03, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:01<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:01<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:01<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:02<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:02<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:02<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:02<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:02<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:02<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:03<00:02, 64.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:03<00:01, 96.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:03<00:01, 97.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:03<00:01, 93.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:03<00:01, 95.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [00:04<00:00, 97.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:04<00:00, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:04<00:00, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440M/495M [00:04<00:00, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:04<00:00, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:04<00:00, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:04<00:00, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:04<00:00, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00018-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:04<00:00, 100MB/s]\n",
      "Downloading shards:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [07:02<05:11, 28.29s/it]\n",
      "Downloading (â€¦)l-00019-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:04, 97.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:04, 96.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:00<00:04, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:04, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:04, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:00<00:04, 99.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:01<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:01<00:02, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:02<00:02, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:02<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:02<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:02<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:02<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:02<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:03<00:01, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:03<00:01, 99.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:03<00:01, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:03<00:01, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:03<00:01, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:03<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:03<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:03<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [00:03<00:00, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:04<00:00, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:04<00:00, 99.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:04<00:00, 95.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440M/495M [00:04<00:00, 97.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:04<00:00, 98.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:04<00:00, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:04<00:00, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:04<00:00, 99.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:04<00:00, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00019-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:04<00:00, 101MB/s]\n",
      "Downloading shards:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [07:07<03:32, 21.29s/it]\n",
      "Downloading (â€¦)l-00020-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:05, 81.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:05, 83.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:   6%|â–‹         | 31.5M/495M [00:00<00:05, 81.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:00<00:05, 83.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:05, 83.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  13%|â–ˆâ–        | 62.9M/495M [00:00<00:05, 84.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:04, 85.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:00<00:04, 85.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:01<00:04, 85.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [00:01<00:04, 85.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:04, 85.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:01<00:04, 83.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:04, 83.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:04, 84.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [00:01<00:03, 85.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:03, 83.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:02<00:03, 82.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:02<00:03, 83.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:02<00:03, 84.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:02<00:03, 79.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:02<00:03, 81.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:02<00:03, 83.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:03, 83.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:03<00:02, 84.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:03<00:02, 85.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:03<00:02, 85.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:03<00:02, 85.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:03<00:02, 85.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:03<00:02, 83.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:03<00:02, 84.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:03<00:01, 85.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:03<00:01, 85.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:04<00:01, 86.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:04<00:01, 86.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:04<00:01, 86.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:04<00:01, 86.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:04<00:01, 82.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [00:04<00:01, 81.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:04<00:01, 82.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:04<00:00, 82.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:05<00:00, 83.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440M/495M [00:05<00:00, 84.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:05<00:00, 83.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:05<00:00, 84.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:05<00:00, 84.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:05<00:00, 84.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:05<00:00, 84.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00020-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:05<00:00, 84.1MB/s]\n",
      "Downloading shards:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [07:13<02:30, 16.71s/it]\n",
      "Downloading (â€¦)l-00021-of-00029.bin:   0%|          | 0.00/505M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:   2%|â–         | 10.5M/505M [00:00<00:06, 79.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:   4%|â–         | 21.0M/505M [00:00<00:05, 84.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:   6%|â–Œ         | 31.5M/505M [00:00<00:05, 86.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:   8%|â–Š         | 41.9M/505M [00:00<00:05, 87.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  10%|â–ˆ         | 52.4M/505M [00:00<00:05, 89.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  12%|â–ˆâ–        | 62.9M/505M [00:00<00:04, 90.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  15%|â–ˆâ–        | 73.4M/505M [00:00<00:04, 87.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/505M [00:00<00:04, 89.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  19%|â–ˆâ–Š        | 94.4M/505M [00:01<00:04, 86.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/505M [00:01<00:04, 87.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/505M [00:01<00:04, 84.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  25%|â–ˆâ–ˆâ–       | 126M/505M [00:01<00:04, 87.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  27%|â–ˆâ–ˆâ–‹       | 136M/505M [00:01<00:04, 88.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  29%|â–ˆâ–ˆâ–‰       | 147M/505M [00:01<00:03, 89.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 157M/505M [00:01<00:03, 89.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 168M/505M [00:01<00:03, 90.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/505M [00:02<00:03, 90.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 189M/505M [00:02<00:03, 89.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 199M/505M [00:02<00:03, 91.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/505M [00:02<00:03, 92.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/505M [00:02<00:03, 88.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231M/505M [00:02<00:03, 87.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/505M [00:02<00:03, 87.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 252M/505M [00:02<00:02, 87.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/505M [00:02<00:02, 85.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273M/505M [00:03<00:02, 86.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 283M/505M [00:03<00:02, 83.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 294M/505M [00:03<00:02, 86.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304M/505M [00:03<00:02, 82.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/505M [00:03<00:02, 83.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 325M/505M [00:03<00:02, 86.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336M/505M [00:03<00:01, 88.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 346M/505M [00:03<00:01, 85.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 357M/505M [00:04<00:01, 85.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/505M [00:04<00:01, 87.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 377M/505M [00:04<00:01, 89.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 388M/505M [00:04<00:01, 90.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398M/505M [00:04<00:01, 88.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 409M/505M [00:04<00:01, 89.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/505M [00:04<00:00, 89.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430M/505M [00:04<00:00, 91.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 440M/505M [00:05<00:00, 91.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 451M/505M [00:05<00:00, 91.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/505M [00:05<00:00, 90.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472M/505M [00:05<00:00, 91.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 482M/505M [00:05<00:00, 92.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493M/505M [00:05<00:00, 92.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 503M/505M [00:05<00:00, 93.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00021-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 505M/505M [00:05<00:00, 88.6MB/s]\n",
      "Downloading shards:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [07:19<01:47, 13.44s/it]\n",
      "Downloading (â€¦)l-00022-of-00029.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:   2%|â–         | 10.5M/438M [00:00<00:04, 87.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:   5%|â–         | 21.0M/438M [00:00<00:04, 95.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  10%|â–‰         | 41.9M/438M [00:00<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  12%|â–ˆâ–        | 52.4M/438M [00:00<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  14%|â–ˆâ–        | 62.9M/438M [00:00<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  17%|â–ˆâ–‹        | 73.4M/438M [00:00<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  19%|â–ˆâ–‰        | 83.9M/438M [00:00<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  22%|â–ˆâ–ˆâ–       | 94.4M/438M [00:00<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  24%|â–ˆâ–ˆâ–       | 105M/438M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  29%|â–ˆâ–ˆâ–Š       | 126M/438M [00:01<00:03, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 136M/438M [00:01<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 147M/438M [00:01<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 157M/438M [00:01<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 178M/438M [00:01<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 199M/438M [00:01<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 210M/438M [00:02<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 220M/438M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 241M/438M [00:02<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 252M/438M [00:02<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 262M/438M [00:02<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 273M/438M [00:02<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 283M/438M [00:02<00:01, 99.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 304M/438M [00:02<00:01, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 315M/438M [00:03<00:01, 99.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 325M/438M [00:03<00:01, 98.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 336M/438M [00:03<00:01, 98.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 346M/438M [00:03<00:00, 99.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 357M/438M [00:03<00:00, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 377M/438M [00:03<00:00, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 388M/438M [00:03<00:00, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 398M/438M [00:03<00:00, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 409M/438M [00:04<00:00, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 419M/438M [00:04<00:00, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438M/438M [00:04<00:00, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00022-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438M/438M [00:04<00:00, 102MB/s]\n",
      "Downloading shards:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [07:24<01:15, 10.73s/it]\n",
      "Downloading (â€¦)l-00023-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:06, 78.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:05, 86.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:   6%|â–‹         | 31.5M/495M [00:00<00:05, 92.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:00<00:04, 92.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:04, 91.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  13%|â–ˆâ–        | 62.9M/495M [00:00<00:04, 92.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:04, 92.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/495M [00:00<00:04, 92.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:01<00:04, 91.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [00:01<00:04, 91.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:04, 92.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:01<00:03, 93.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:04, 88.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:04, 85.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [00:01<00:03, 88.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:03, 91.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:01<00:03, 92.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:02<00:03, 94.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:02<00:03, 91.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:02<00:03, 92.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:02<00:03, 91.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:02<00:02, 93.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:02, 91.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:02<00:02, 93.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:02<00:02, 93.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:02<00:02, 93.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:03<00:02, 94.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:03<00:02, 93.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:03<00:02, 92.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:03<00:01, 91.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:03<00:01, 91.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:03<00:01, 92.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:03<00:01, 91.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:03<00:01, 93.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:03<00:01, 94.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:04<00:01, 94.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:04<00:01, 94.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [00:04<00:01, 94.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:04<00:00, 92.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:04<00:00, 90.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:04<00:00, 88.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440M/495M [00:04<00:00, 89.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:04<00:00, 89.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:05<00:00, 92.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:05<00:00, 88.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:05<00:00, 90.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:05<00:00, 91.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00023-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:05<00:00, 91.6MB/s]\n",
      "Downloading shards:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [07:29<00:54,  9.16s/it]\n",
      "Downloading (â€¦)l-00024-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:05, 95.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:10, 46.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:04, 98.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:04, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:00<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:03, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:03, 99.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:03, 99.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:01<00:03, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:02<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:02<00:02, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:02<00:02, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:02<00:01, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:03<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:03<00:01, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:03<00:01, 99.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:03<00:01, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:04<00:00, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:04<00:00, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:04<00:00, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:04<00:00, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:04<00:00, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:04<00:00, 105MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00024-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:04<00:00, 101MB/s]\n",
      "Downloading shards:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 24/29 [07:34<00:39,  7.91s/it]\n",
      "Downloading (â€¦)l-00025-of-00029.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:   2%|â–         | 10.5M/495M [00:00<00:05, 88.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:   4%|â–         | 21.0M/495M [00:00<00:05, 93.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:   6%|â–‹         | 31.5M/495M [00:00<00:04, 94.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:   8%|â–Š         | 41.9M/495M [00:00<00:04, 94.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  11%|â–ˆ         | 52.4M/495M [00:00<00:06, 68.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  15%|â–ˆâ–        | 73.4M/495M [00:00<00:04, 98.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  19%|â–ˆâ–‰        | 94.4M/495M [00:01<00:04, 97.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/495M [00:01<00:04, 94.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/495M [00:01<00:03, 95.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  25%|â–ˆâ–ˆâ–Œ       | 126M/495M [00:01<00:03, 94.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 136M/495M [00:01<00:03, 93.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  30%|â–ˆâ–ˆâ–‰       | 147M/495M [00:01<00:03, 90.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 157M/495M [00:01<00:03, 91.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 168M/495M [00:01<00:04, 76.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/495M [00:02<00:03, 81.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189M/495M [00:02<00:03, 85.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 199M/495M [00:02<00:03, 88.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/495M [00:02<00:03, 90.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/495M [00:02<00:02, 91.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/495M [00:02<00:02, 92.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/495M [00:02<00:02, 89.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252M/495M [00:02<00:02, 91.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/495M [00:02<00:02, 86.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273M/495M [00:03<00:02, 87.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283M/495M [00:03<00:02, 90.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294M/495M [00:03<00:02, 91.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 304M/495M [00:03<00:02, 93.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/495M [00:03<00:01, 93.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325M/495M [00:03<00:01, 94.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 336M/495M [00:03<00:01, 92.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346M/495M [00:03<00:01, 93.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357M/495M [00:03<00:01, 93.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/495M [00:04<00:01, 93.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377M/495M [00:04<00:01, 94.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388M/495M [00:04<00:01, 94.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398M/495M [00:04<00:01, 93.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409M/495M [00:04<00:00, 87.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/495M [00:04<00:00, 89.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430M/495M [00:04<00:00, 91.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440M/495M [00:04<00:00, 83.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451M/495M [00:05<00:00, 86.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/495M [00:05<00:00, 87.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472M/495M [00:05<00:00, 89.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482M/495M [00:05<00:00, 89.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 493M/495M [00:05<00:00, 90.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00025-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495M/495M [00:05<00:00, 90.2MB/s]\n",
      "Downloading shards:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [07:40<00:28,  7.22s/it]\n",
      "Downloading (â€¦)l-00026-of-00029.bin:   0%|          | 0.00/505M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:   2%|â–         | 10.5M/505M [00:00<00:05, 87.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:   4%|â–         | 21.0M/505M [00:00<00:05, 83.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:   6%|â–Œ         | 31.5M/505M [00:00<00:05, 89.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:   8%|â–Š         | 41.9M/505M [00:00<00:05, 91.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  10%|â–ˆ         | 52.4M/505M [00:00<00:05, 90.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  12%|â–ˆâ–        | 62.9M/505M [00:00<00:04, 91.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  15%|â–ˆâ–        | 73.4M/505M [00:00<00:04, 93.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  17%|â–ˆâ–‹        | 83.9M/505M [00:00<00:04, 91.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  19%|â–ˆâ–Š        | 94.4M/505M [00:01<00:04, 88.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  21%|â–ˆâ–ˆ        | 105M/505M [00:01<00:04, 89.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 115M/505M [00:01<00:04, 91.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  25%|â–ˆâ–ˆâ–       | 126M/505M [00:01<00:04, 90.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  27%|â–ˆâ–ˆâ–‹       | 136M/505M [00:01<00:04, 91.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  29%|â–ˆâ–ˆâ–‰       | 147M/505M [00:01<00:04, 88.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 157M/505M [00:01<00:03, 89.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 168M/505M [00:01<00:03, 90.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 178M/505M [00:01<00:03, 91.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 189M/505M [00:02<00:03, 92.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 199M/505M [00:02<00:03, 92.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210M/505M [00:02<00:03, 91.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220M/505M [00:02<00:03, 88.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231M/505M [00:02<00:03, 86.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241M/505M [00:02<00:03, 84.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 252M/505M [00:02<00:03, 78.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262M/505M [00:02<00:03, 80.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273M/505M [00:03<00:02, 84.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 283M/505M [00:03<00:02, 87.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 294M/505M [00:03<00:02, 87.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304M/505M [00:03<00:02, 85.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 315M/505M [00:03<00:02, 85.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 325M/505M [00:03<00:02, 85.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336M/505M [00:03<00:01, 86.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 346M/505M [00:03<00:01, 88.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 357M/505M [00:04<00:01, 89.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367M/505M [00:04<00:01, 91.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 377M/505M [00:04<00:01, 92.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 388M/505M [00:04<00:01, 93.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398M/505M [00:04<00:01, 94.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 409M/505M [00:04<00:01, 94.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419M/505M [00:04<00:00, 94.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430M/505M [00:04<00:00, 91.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 440M/505M [00:04<00:00, 93.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 451M/505M [00:05<00:00, 94.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461M/505M [00:05<00:00, 93.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472M/505M [00:05<00:00, 93.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 482M/505M [00:05<00:00, 92.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493M/505M [00:05<00:00, 93.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 503M/505M [00:05<00:00, 94.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00026-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 505M/505M [00:05<00:00, 89.9MB/s]\n",
      "Downloading shards:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [07:46<00:20,  6.77s/it]\n",
      "Downloading (â€¦)l-00027-of-00029.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:   2%|â–         | 10.5M/438M [00:00<00:06, 64.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:   5%|â–         | 21.0M/438M [00:00<00:05, 72.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:   7%|â–‹         | 31.5M/438M [00:00<00:05, 74.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  10%|â–‰         | 41.9M/438M [00:00<00:05, 73.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  12%|â–ˆâ–        | 52.4M/438M [00:00<00:05, 74.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  14%|â–ˆâ–        | 62.9M/438M [00:00<00:05, 73.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  17%|â–ˆâ–‹        | 73.4M/438M [00:01<00:04, 73.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  19%|â–ˆâ–‰        | 83.9M/438M [00:01<00:04, 74.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  22%|â–ˆâ–ˆâ–       | 94.4M/438M [00:01<00:04, 72.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  24%|â–ˆâ–ˆâ–       | 105M/438M [00:01<00:04, 72.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  26%|â–ˆâ–ˆâ–‹       | 115M/438M [00:01<00:04, 72.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  29%|â–ˆâ–ˆâ–Š       | 126M/438M [00:01<00:04, 72.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 136M/438M [00:01<00:04, 71.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 147M/438M [00:02<00:04, 72.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 157M/438M [00:02<00:03, 74.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 168M/438M [00:02<00:03, 74.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 178M/438M [00:02<00:03, 74.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 189M/438M [00:02<00:03, 71.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 199M/438M [00:02<00:03, 72.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 210M/438M [00:02<00:03, 72.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 220M/438M [00:03<00:02, 73.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 231M/438M [00:03<00:02, 73.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 241M/438M [00:03<00:03, 65.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 252M/438M [00:03<00:02, 67.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 262M/438M [00:03<00:02, 69.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 273M/438M [00:03<00:02, 70.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 283M/438M [00:03<00:02, 71.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 294M/438M [00:04<00:02, 54.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 304M/438M [00:04<00:02, 57.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 315M/438M [00:04<00:02, 59.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 325M/438M [00:04<00:01, 64.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 336M/438M [00:04<00:01, 68.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 346M/438M [00:04<00:01, 70.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 357M/438M [00:05<00:01, 56.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 367M/438M [00:05<00:01, 55.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 377M/438M [00:05<00:01, 59.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 388M/438M [00:05<00:00, 60.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 398M/438M [00:05<00:00, 61.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 409M/438M [00:06<00:00, 63.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 419M/438M [00:06<00:00, 53.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 430M/438M [00:06<00:00, 58.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438M/438M [00:06<00:00, 61.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00027-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438M/438M [00:06<00:00, 66.6MB/s]\n",
      "Downloading shards:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 27/29 [07:52<00:13,  6.75s/it]\n",
      "Downloading (â€¦)l-00028-of-00029.bin:   0%|          | 0.00/271M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:   4%|â–         | 10.5M/271M [00:00<00:02, 88.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:   8%|â–Š         | 21.0M/271M [00:00<00:02, 91.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  12%|â–ˆâ–        | 31.5M/271M [00:00<00:02, 95.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  16%|â–ˆâ–Œ        | 41.9M/271M [00:00<00:02, 96.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  19%|â–ˆâ–‰        | 52.4M/271M [00:00<00:02, 93.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  23%|â–ˆâ–ˆâ–       | 62.9M/271M [00:00<00:02, 90.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  27%|â–ˆâ–ˆâ–‹       | 73.4M/271M [00:00<00:02, 82.1MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  31%|â–ˆâ–ˆâ–ˆ       | 83.9M/271M [00:00<00:02, 82.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  35%|â–ˆâ–ˆâ–ˆâ–      | 94.4M/271M [00:01<00:02, 86.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 105M/271M [00:01<00:01, 88.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 115M/271M [00:01<00:01, 79.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 126M/271M [00:01<00:01, 82.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 136M/271M [00:01<00:01, 84.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 147M/271M [00:01<00:01, 88.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 157M/271M [00:01<00:01, 90.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 168M/271M [00:01<00:01, 91.4MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 178M/271M [00:02<00:00, 92.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 189M/271M [00:02<00:00, 94.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 199M/271M [00:02<00:00, 93.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 210M/271M [00:02<00:00, 94.0MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 220M/271M [00:02<00:00, 93.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 231M/271M [00:02<00:00, 92.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 241M/271M [00:02<00:00, 93.7MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 252M/271M [00:02<00:00, 92.2MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 262M/271M [00:02<00:00, 92.5MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00028-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 271M/271M [00:03<00:00, 89.9MB/s]\n",
      "Downloading shards:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [07:55<00:05,  5.67s/it]\n",
      "Downloading (â€¦)l-00029-of-00029.bin:   0%|          | 0.00/409M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:   3%|â–         | 10.5M/409M [00:00<00:04, 94.8MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:   8%|â–Š         | 31.5M/409M [00:00<00:03, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  10%|â–ˆ         | 41.9M/409M [00:00<00:03, 104MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  13%|â–ˆâ–        | 52.4M/409M [00:00<00:03, 98.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  15%|â–ˆâ–Œ        | 62.9M/409M [00:00<00:03, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  18%|â–ˆâ–Š        | 73.4M/409M [00:00<00:03, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  20%|â–ˆâ–ˆ        | 83.9M/409M [00:00<00:03, 98.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  26%|â–ˆâ–ˆâ–Œ       | 105M/409M [00:01<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  28%|â–ˆâ–ˆâ–Š       | 115M/409M [00:01<00:04, 68.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 147M/409M [00:01<00:02, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 168M/409M [00:01<00:02, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 189M/409M [00:01<00:02, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 210M/409M [00:02<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 231M/409M [00:02<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 241M/409M [00:02<00:01, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 252M/409M [00:02<00:01, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 262M/409M [00:02<00:01, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 273M/409M [00:02<00:01, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 294M/409M [00:02<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 304M/409M [00:03<00:01, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 315M/409M [00:03<00:00, 103MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 325M/409M [00:03<00:00, 101MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 336M/409M [00:03<00:00, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 346M/409M [00:03<00:00, 98.6MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 357M/409M [00:03<00:00, 100MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 367M/409M [00:03<00:00, 99.9MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 388M/409M [00:03<00:00, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 398M/409M [00:03<00:00, 102MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 409M/409M [00:04<00:00, 99.3MB/s]\n",
      "#033[A\n",
      "Downloading (â€¦)l-00029-of-00029.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409M/409M [00:04<00:00, 99.4MB/s]\n",
      "Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [08:00<00:00,  5.24s/it]\n",
      "Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [08:00<00:00, 16.56s/it]\n",
      "Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   3%|â–         | 1/29 [00:00<00:15,  1.82it/s]\n",
      "Loading checkpoint shards:   7%|â–‹         | 2/29 [00:01<00:13,  2.00it/s]\n",
      "Loading checkpoint shards:  10%|â–ˆ         | 3/29 [00:01<00:12,  2.02it/s]\n",
      "Loading checkpoint shards:  14%|â–ˆâ–        | 4/29 [00:01<00:12,  2.04it/s]\n",
      "Loading checkpoint shards:  17%|â–ˆâ–‹        | 5/29 [00:02<00:11,  2.01it/s]\n",
      "Loading checkpoint shards:  21%|â–ˆâ–ˆ        | 6/29 [00:02<00:11,  2.02it/s]\n",
      "Loading checkpoint shards:  24%|â–ˆâ–ˆâ–       | 7/29 [00:03<00:10,  2.07it/s]\n",
      "Loading checkpoint shards:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:03<00:10,  2.04it/s]\n",
      "Loading checkpoint shards:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:04<00:10,  2.00it/s]\n",
      "Loading checkpoint shards:  34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:04<00:09,  2.01it/s]\n",
      "Loading checkpoint shards:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:05<00:08,  2.02it/s]\n",
      "Loading checkpoint shards:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:05<00:08,  2.06it/s]\n",
      "Loading checkpoint shards:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:06<00:07,  2.03it/s]\n",
      "Loading checkpoint shards:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:06<00:07,  2.01it/s]\n",
      "Loading checkpoint shards:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:07<00:06,  2.02it/s]\n",
      "Loading checkpoint shards:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:07<00:06,  2.02it/s]\n",
      "Loading checkpoint shards:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:08<00:05,  2.08it/s]\n",
      "Loading checkpoint shards:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:08<00:05,  2.06it/s]\n",
      "Loading checkpoint shards:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:09<00:04,  2.06it/s]\n",
      "Loading checkpoint shards:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:09<00:04,  2.06it/s]\n",
      "Loading checkpoint shards:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:10<00:03,  2.03it/s]\n",
      "Loading checkpoint shards:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:10<00:03,  2.07it/s]\n",
      "Loading checkpoint shards:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:11<00:02,  2.04it/s]\n",
      "Loading checkpoint shards:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 24/29 [00:11<00:02,  2.02it/s]\n",
      "Loading checkpoint shards:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:12<00:01,  2.02it/s]\n",
      "Loading checkpoint shards:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:12<00:01,  2.00it/s]\n",
      "Loading checkpoint shards:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 27/29 [00:13<00:00,  2.08it/s]\n",
      "Loading checkpoint shards:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:13<00:00,  2.32it/s]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:13<00:00,  2.35it/s]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:13<00:00,  2.07it/s]\n",
      "Downloading (â€¦)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]\n",
      "Downloading (â€¦)neration_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 137/137 [00:00<00:00, 20.1kB/s]\n",
      "2023-05-26 10:12:48,408,408 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:69] model.config: LlamaConfig {\n",
      "  \"_name_or_path\": \"rjx/rjxai-zh-llama-7b-v1\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"pad_token_id\": -1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.28.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 49953\n",
      "}\n",
      "2023-05-26 10:12:48,411,411 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:70] modelç»“æ„: LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(49953, 4096, padding_idx=49952)\n",
      "    (layers): ModuleList(\n",
      "      (0): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (1): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (2): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (3): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (4): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (5): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (6): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (7): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (8): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (9): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (10): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (11): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (12): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (13): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (14): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (15): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (16): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (17): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (18): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (19): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (20): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (21): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (22): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (23): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (24): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (25): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (26): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (27): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (28): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (29): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (30): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (31): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=49953, bias=False)\n",
      ")\n",
      "2023-05-26 10:12:48,412,412 INFO     140340029425472 MainThread 193 [print_utils.py:34] CPU ä¸ªæ•°: 8\n",
      "2023-05-26 10:12:48,412,412 INFO     140340029425472 MainThread 193 [print_utils.py:35] CPU memory total: 59.83776092529297 GB.\n",
      "2023-05-26 10:12:48,412,412 INFO     140340029425472 MainThread 193 [print_utils.py:36] CPU memory use: 27.851348876953125 GB.\n",
      "2023-05-26 10:12:48,412,412 INFO     140340029425472 MainThread 193 [print_utils.py:37] CPU memory free: 1.0767555236816406 GB.\n",
      "2023-05-26 10:12:48,413,413 INFO     140340029425472 MainThread 193 [print_utils.py:38] CPU memory use percent: 47.7 %\n",
      "2023-05-26 10:12:48,413,413 INFO     140340029425472 MainThread 193 [print_utils.py:17] Driver Version: b'525.85.12'\n",
      "2023-05-26 10:12:48,413,413 INFO     140340029425472 MainThread 193 [print_utils.py:21] Device 0 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-26 10:12:48,413,413 INFO     140340029425472 MainThread 193 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-26 10:12:48,414,414 INFO     140340029425472 MainThread 193 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2303466796875 GB.\n",
      "2023-05-26 10:12:48,414,414 INFO     140340029425472 MainThread 193 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7696533203125 GB.\n",
      "Downloading tokenizer.model:   0%|          | 0.00/758k [00:00<?, ?B/s]\n",
      "Downloading tokenizer.model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 758k/758k [00:00<00:00, 5.80MB/s]\n",
      "Downloading tokenizer.model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 758k/758k [00:00<00:00, 5.76MB/s]\n",
      "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]\n",
      "Downloading (â€¦)cial_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.0/72.0 [00:00<00:00, 30.9kB/s]\n",
      "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]\n",
      "Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [00:00<00:00, 156kB/s]\n",
      "2023-05-26 10:12:49,299,299 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:86] tokenizer config: LlamaTokenizer(name_or_path='rjx/rjxai-zh-llama-7b-v1', vocab_size=49953, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False)\n",
      "2023-05-26 10:12:49,300,300 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:89] **************** é¢„å¤„ç†æ•°æ®é›† ***************\n",
      "Using pad_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "2023-05-26 10:12:49,300,300 INFO     140340029425472 MainThread 193 [build_dataset.py:83] num_new_tokens: 1\n",
      "2023-05-26 10:12:56,732,732 INFO     140340029425472 MainThread 193 [build_dataset.py:227] LlamaTokenizer(name_or_path='rjx/rjxai-zh-llama-7b-v1', vocab_size=49953, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\n",
      "2023-05-26 10:12:56,733,733 WARNING  140340029425472 MainThread 193 [build_dataset.py:229] åŠ è½½datasest\n",
      "Downloading readme:   0%|          | 0.00/549 [00:00<?, ?B/s]\n",
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 549/549 [00:00<00:00, 673kB/s]\n",
      "Using custom data configuration rjx--ai-and-human-20-976cde27ebc81e58\n",
      "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/rjx___parquet/rjx--ai-and-human-20-976cde27ebc81e58/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/17.9k [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.9k/17.9k [00:00<00:00, 13.0MB/s]\n",
      "Downloading data files:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:00,  2.18it/s]\n",
      "Downloading data:   0%|          | 0.00/17.1k [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.1k/17.1k [00:00<00:00, 13.8MB/s]\n",
      "Downloading data files:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.25it/s]\n",
      "Downloading data:   0%|          | 0.00/23.9k [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23.9k/23.9k [00:00<00:00, 1.84MB/s]\n",
      "Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]\n",
      "Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n",
      "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 1429.71it/s]\n",
      "Generating validation split:   0%|          | 0/5 [00:00<?, ? examples/s]\n",
      "Generating test split:   0%|          | 0/5 [00:00<?, ? examples/s]\n",
      "Generating train split:   0%|          | 0/10 [00:00<?, ? examples/s]\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/rjx___parquet/rjx--ai-and-human-20-976cde27ebc81e58/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 776.68it/s]\n",
      "2023-05-26 10:12:59,503,503 INFO     140340029425472 MainThread 193 [build_dataset.py:236] åŠ è½½åŸå§‹æ•°æ®é›†ï¼šDatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 10\n",
      "    })\n",
      "})\n",
      "2023-05-26 10:12:59,503,503 WARNING  140340029425472 MainThread 193 [build_dataset.py:48] æ ¼å¼åŒ–ç›‘ç£æ•°æ®é›†...\n",
      "0%|          | 0/10 [00:00<?, ?ex/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 6773.75ex/s]\n",
      "2023-05-26 10:12:59,515,515 WARNING  140340029425472 MainThread 193 [build_dataset.py:57] Tokenizing inputs... This may take some time...\n",
      "2023-05-26 10:12:59,562,562 INFO     140340029425472 MainThread 193 [build_dataset.py:262] train_dataset: <fengx_ai.dataset.build_dataset.SupervisedDataset object at 0x7fa2c3acedc0>\n",
      "2023-05-26 10:12:59,562,562 INFO     140340029425472 MainThread 193 [build_dataset.py:263] {'input_ids': [tensor([    1,   835, 29871, 38671, 29901, 33109, 45251, 36781, 36335, 29973,\n",
      "           13, 38631, 29901,    13, 29900,    13, 29896,    13,    13,  2277,\n",
      "        29937, 29871, 34485, 29901, 30682, 32742, 32444, 43709,    13,    13,\n",
      "        32903, 32515, 31462, 33484, 30503, 34663, 32754, 33462, 31844, 30805,\n",
      "        31844, 32718, 30214, 30682, 32742, 32444, 39600, 30743, 46033, 33207,\n",
      "        37318, 35375, 30267, 31844, 30805, 40194, 32063, 32041, 38085, 30214,\n",
      "        32444, 30953, 32054, 41151, 30682, 32742, 33451, 34424, 30214, 30651,\n",
      "        32445, 33789, 34021, 30503, 32291, 30267, 35167, 32833, 33335, 30275,\n",
      "        30214, 32007, 30998, 32530, 32057, 33290, 30287, 31475, 30210, 30682,\n",
      "        32742, 32444, 43709, 30214, 32070, 32544, 32728, 35363, 30214, 32123,\n",
      "        32244, 32033, 32593, 37576, 32444, 34812, 34949, 30573, 32291, 34159,\n",
      "        33900, 30267,    13,    13, 34507, 43709, 30392, 30374, 30602, 32275,\n",
      "        30267, 32013, 32043, 40371, 38570, 32286, 36279, 30503, 35763, 32087,\n",
      "        40743, 31325, 40675, 30267, 30374, 30602, 32275, 32128, 32217, 32861,\n",
      "        31074, 30909, 32445, 31149, 32286, 32447, 30214, 35565, 43809, 32081,\n",
      "        30682, 32742, 32444, 43709, 44745, 32252, 30267, 32593, 32003, 32284,\n",
      "        32251, 39855, 32088, 30214, 30847, 33859, 32619, 34726, 30330, 32141,\n",
      "        34108, 38174, 30330, 32660, 34207, 31184, 30214, 34118, 30257, 32286,\n",
      "        30210, 46459, 30503, 35586, 30267, 33792, 30214, 32593, 34402, 30505,\n",
      "        33101, 33194, 30411, 30503, 32192, 30275, 46029, 35517, 30214, 32735,\n",
      "        33101, 32087, 30503, 41517, 30267,    13,    13, 38074, 43709, 30392,\n",
      "        32622, 32483, 30267, 32622, 32483, 32510, 34735, 37449, 30503, 35586,\n",
      "        38344, 30214, 32376, 32832, 36612, 32286, 36279, 30503, 32087, 40743,\n",
      "        30267, 32622, 32483, 32128, 32217, 32861, 31074, 30909, 32445, 31149,\n",
      "        32286, 32447, 30503, 32291, 30214, 35565, 43809, 32081, 30682, 32742,\n",
      "        32444, 43709, 44745, 32252, 30267, 32593, 32003, 32284, 32251, 39855,\n",
      "        32088, 30214, 30847, 33859, 32619, 34726, 30330, 34016, 31530, 30330,\n",
      "        32597, 43158, 31184, 30214, 34118, 30257, 32286, 30210, 46459, 30503,\n",
      "        35586, 30267, 33792, 30214, 32593, 34402, 30505, 33101, 30210, 39951,\n",
      "        30275, 37263, 41574, 30214, 46029, 33101, 30210, 35517, 30503, 38644,\n",
      "        30267,    13,    13, 44823, 43709, 30392, 31824, 32741, 30333, 36543,\n",
      "        30267, 31824, 32741, 30333, 36543, 32510, 34735, 37449, 30503, 35586,\n",
      "        38344, 30214, 32376, 32832, 36612, 32286, 36279, 30503, 32087, 40743,\n",
      "        30267, 31824, 32741, 30333, 36543, 32128, 32217, 32861, 31074, 30909,\n",
      "        32445, 31149, 32286, 32447, 30503, 32291, 30214, 35565, 43809, 32081,\n",
      "        30682, 32742, 32444, 43709, 44745, 32252, 30267, 32593, 32003, 32284,\n",
      "        32251, 39855, 32088, 30214, 30847, 33859, 32619, 34726, 30330, 34016,\n",
      "        37260, 30330, 43927, 31184, 30214, 34118, 30257, 32286, 30210, 46459,\n",
      "        30503, 35586, 30267, 33792, 30214, 32593, 34402, 30505, 33101, 33194,\n",
      "        30411, 30503, 32192, 30275, 46029, 35517, 30214, 32735, 33101, 32087,\n",
      "        30503, 41517, 30267,    13,    13, 33121, 30502, 43709, 30392, 41746,\n",
      "        33813, 30267, 41746, 33813, 32510, 34735, 37449, 30503, 35586, 38344,\n",
      "        30214, 32376, 32832, 36612, 32286, 36279, 30503, 32087, 40743, 30267,\n",
      "        41746, 33813, 32128, 32217, 32861, 31074, 30909, 32445, 31149, 32286,\n",
      "        32447, 30503, 32291, 30214, 35565, 43809, 32081, 30682, 32742, 32444,\n",
      "        43709, 44745, 32252, 30267, 32593, 32003, 32284, 32251, 39855, 32088,\n",
      "        30214, 30847, 45254, 30330, 32660, 34207, 30330, 30581, 40959, 31184,\n",
      "        30214, 34118, 30257, 32286, 30210, 46459, 30503, 35586, 30267, 33792,\n",
      "        30214, 32593, 34402, 30505, 33101, 33194, 43041, 33589, 34758, 30503,\n",
      "        44973, 30214, 46029, 33101, 30210, 35517, 30503, 37800, 30267,    13,\n",
      "           13, 34225, 30502, 43709, 30392, 38916, 34050, 30923, 31814, 30267,\n",
      "        38916, 34050])], 'labels': [tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100])]}\n",
      "2023-05-26 10:12:59,566,566 INFO     140340029425472 MainThread 193 [build_dataset.py:265] éªŒè¯tokenizedåçš„å½¢çŠ¶æ˜¯å¦ä¸€è‡´\n",
      "[2023-05-26 10:12:59.684: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "INFO:root:Using NamedTuple = typing._NamedTuple instead.\n",
      "[2023-05-26 10:12:59.723 algo-1:193 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-05-26 10:12:59.750 algo-1:193 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2023-05-26 10:12:59.751 algo-1:193 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2023-05-26 10:12:59.751 algo-1:193 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2023-05-26 10:12:59.752 algo-1:193 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[2023-05-26 10:12:59.752 algo-1:193 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "2023-05-26 10:12:59,754,754 INFO     140340029425472 MainThread 193 [build_dataset.py:274] {'input_ids': tensor([[    1,   835, 29871,  ..., 49953, 49953, 49953],\n",
      "        [    1,   835, 29871,  ..., 42714, 38081, 32036]]), 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]]), 'attention_mask': tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True]])}\n",
      "2023-05-26 10:12:59,755,755 INFO     140340029425472 MainThread 193 [build_dataset.py:275] {'input_ids': torch.Size([2, 512]), 'labels': torch.Size([2, 512]), 'attention_mask': torch.Size([2, 512])}\n",
      "2023-05-26 10:12:59,755,755 INFO     140340029425472 MainThread 193 [build_dataset.py:276] <class 'dict'>\n",
      "2023-05-26 10:12:59,755,755 INFO     140340029425472 MainThread 193 [build_dataset.py:277] æ ¡éªŒinput_ids\n",
      "2023-05-26 10:12:59,756,756 INFO     140340029425472 MainThread 193 [build_dataset.py:279] å°† ids è½¬æ¢æˆ tokens æ–‡æœ¬ï¼šids_to_tokens = ['<s>', 'â–###', 'â–', 'æŒ‡ç¤º', ':', 'ä¸‹é¢', 'è¿™ç¯‡æ–‡ç« ', 'æ˜¯è°', 'å†™çš„', '?', '<0x0A>', 'é€‰é¡¹', ':', '<0x0A>', '0', '<0x0A>', '1', '<0x0A>', '<0x0A>', '##', '#', 'â–', 'è¾“å…¥', ':', 'ç”µè§†å‰§', 'ä¸­çš„', 'å‰§æƒ…', 'è½¬æŠ˜', 'åœ¨', 'è§‚ä¼—', 'ä¸­', 'ä¸€ç›´', 'å¤‡å—', 'å…³æ³¨', 'ï¼Œ', 'å¹¶ä¸”', 'å®ƒä»¬', 'å¯ä»¥', 'ä½¿', 'æ•´ä¸ª', 'å‰§é›†', 'å˜å¾—æ›´', 'åŠ ', 'ç²¾å½©', 'å’Œ', 'æœ‰è¶£', 'ã€‚', 'ä¸‹é¢', 'æ˜¯æœ‰', 'å…³', 'ç”µè§†å‰§', 'å‰§æƒ…', 'è½¬æŠ˜', 'çš„ä¸€äº›', 'æƒŠäºº', 'äº‹å®', 'ã€‚', 'â–', 'â–ç¬¬ä¸€', 'ä¸ª', 'æƒŠäºº', 'çš„äº‹', 'å®', 'æ˜¯', 'ï¼š', 'è®¸å¤š', 'ç”µè§†èŠ‚ç›®', 'åœ¨', 'åˆ¶ä½œ', 'è¿‡ç¨‹ä¸­', 'æ ¹æœ¬æ²¡æœ‰', 'è®¡åˆ’', 'å¥½', 'å‰§æƒ…', 'è½¬æŠ˜', 'ã€‚', 'ç›¸å', 'ï¼Œ', 'ä»–ä»¬', 'ä¼š', 'æ ¹æ®', 'åé¦ˆ', 'å’Œ', 'ååº”', 'æ¥', 'è°ƒæ•´', 'æ•…äº‹', 'æƒ…èŠ‚', 'ï¼Œ', 'è¿™', 'å¯èƒ½ä¼š', 'å¯¼è‡´', 'æ„å¤–', 'çš„', 'å‰§æƒ…', 'è½¬æŠ˜', 'ã€‚', 'â–', 'â–ç¬¬äºŒ', 'ä¸ª', 'æƒŠäºº', 'çš„äº‹', 'å®', 'æ˜¯', 'ï¼š', 'æœ‰äº›', 'ç”µè§†èŠ‚ç›®', 'ä¼š', 'é€šè¿‡', 'å‘', 'æƒ…èŠ‚', 'æ·»åŠ ', 'æ„å¤–', 'çš„', 'è¦ç´ ', 'æ¥', 'åˆ¶é€ ', 'å‰§æƒ…', 'è½¬æŠ˜', 'ã€‚', 'ä¾‹å¦‚', 'ï¼Œ', 'å‰§é›†', 'å¯èƒ½ä¼š', 'åŠ å…¥', 'æ–°', 'è§’è‰²', 'ã€', 'çŠ¯ç½ª', 'æƒ…èŠ‚', 'æˆ–', 'â€œ', 'å‘ç”Ÿåœ¨', 'å…ˆ', 'å‰', 'æœª', 'çœ‹åˆ°çš„', 'åœ°æ–¹', 'â€', 'çš„äº‹', 'ä»¶', 'ï¼Œ', 'ä»¥', 'ä½¿', 'æƒ…èŠ‚', 'æ›´åŠ ', 'å¤æ‚', 'å’Œ', 'æ·±å…¥', 'ã€‚', 'â–', 'â–ç¬¬ä¸‰', 'ä¸ª', 'æƒŠäºº', 'çš„äº‹', 'å®', 'æ˜¯', 'ï¼š', 'æœ‰äº›', 'ç”µè§†èŠ‚ç›®', 'ä¼š', 'åˆ¶é€ ', 'è™šå‡', 'çš„', 'å‰§æƒ…', 'è½¬æŠ˜', 'ï¼Œ', 'ä»¥', 'å¼•èµ·', 'è§‚ä¼—', 'çš„', 'æ³¨æ„åŠ›', 'ã€‚', 'è¿™æ ·åš', 'çš„ä¸€ä¸ª', 'ä¾‹å­', 'æ˜¯', 'ï¼Œ', 'ä¸€ä¸ª', 'èŠ‚ç›®', 'å¯èƒ½ä¼š', 'å‘', 'è§‚ä¼—', 'å±•ç¤º', 'ä¸€ä¸ª', 'è§’è‰²', 'æ­»äº¡', 'çš„', 'åœºæ™¯', 'ï¼Œ', 'ä½†åœ¨', 'æ¥ä¸‹æ¥', 'çš„', 'æƒ…èŠ‚', 'ä¸­', 'æ­ç¤º', 'ä»–ä»¬', 'å®é™…ä¸Š', 'è¿˜', 'æ´»ç€', 'ã€‚', 'â–', 'â–ç¬¬', 'å››ä¸ª', 'æƒŠäºº', 'çš„äº‹', 'å®', 'æ˜¯', 'ï¼š', 'æœ‰äº›', 'ç”µè§†èŠ‚ç›®', 'ä¼šä½¿', 'ç”¨', 'æ‚¬ç–‘', 'å’Œ', 'è°œ', 'å›¢', 'æ¥', 'åˆ¶é€ ', 'å‰§æƒ…', 'è½¬æŠ˜', 'ã€‚', 'ä»–ä»¬', 'å¯èƒ½ä¼š', 'åœ¨', 'èŠ‚ç›®', 'ä¸­', 'éšè—', 'çº¿ç´¢', 'å’Œ', 'æš—ç¤º', 'ï¼Œ', 'ä»¥ä¾¿', 'åœ¨', 'åç»­', 'æƒ…èŠ‚', 'ä¸­', 'æ…¢æ…¢', 'æ­ç¤º', 'å‰§æƒ…', 'è½¬æŠ˜', 'ã€‚', 'è¿™', 'ä½¿å¾—', 'è§‚ä¼—', 'å‚ä¸', 'å…¶ä¸­', 'ï¼Œ', 'åŠªåŠ›', 'æ‰¾åˆ°', 'ç­”æ¡ˆ', 'ã€‚', 'â–', 'â–ç¬¬', 'äº”ä¸ª', 'æƒŠäºº', 'çš„äº‹', 'å®', 'æ˜¯', 'ï¼š', 'æœ‰äº›', 'ç”µè§†èŠ‚ç›®', 'åœ¨', 'å‰§æƒ…', 'è½¬æŠ˜', 'æ–¹é¢', 'é‡‡ç”¨', 'é', 'çº¿æ€§', 'å™äº‹', 'æ–¹å¼', 'ã€‚', 'ä¹Ÿå°±æ˜¯è¯´', 'ï¼Œ', 'ä»–ä»¬', 'ä¼š', 'é€šè¿‡', 'åœ¨', 'èŠ‚ç›®', 'ä¸­', 'è·³', 'è¿‡', 'å’Œ', 'é‡å¤', 'æƒ…èŠ‚', 'ï¼Œ', '<0x0A>', '<0x0A>', '##', '#', 'â–', 'å›ç­”', ':0', '</s>', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "2023-05-26 10:12:59,757,757 INFO     140340029425472 MainThread 193 [build_dataset.py:281] å°†tokensè½¬æ¢æˆidsï¼štokens_to_ids = [1, 835, 29871, 38671, 29901, 33109, 45251, 36781, 36335, 29973, 13, 38631, 29901, 13, 29900, 13, 29896, 13, 13, 2277, 29937, 29871, 34485, 29901, 33371, 32204, 34357, 45205, 30505, 33140, 30275, 32217, 40457, 32173, 30214, 32454, 33392, 32003, 30785, 32606, 42497, 44844, 30666, 34048, 30503, 38658, 30267, 33109, 36883, 31057, 33371, 34357, 45205, 36410, 39225, 34317, 30267, 29871, 38996, 30502, 39225, 33647, 31195, 30392, 30383, 32832, 45867, 30505, 32665, 33152, 45131, 32282, 31076, 34357, 45205, 30267, 36349, 30214, 32023, 30437, 32237, 40177, 30503, 32823, 30805, 32601, 32617, 36017, 30214, 30810, 34299, 32468, 34540, 30210, 34357, 45205, 30267, 29871, 35999, 30502, 39225, 33647, 31195, 30392, 30383, 32460, 45867, 30437, 32039, 31331, 36017, 34631, 34540, 30210, 39098, 30805, 33265, 34357, 45205, 30267, 33725, 30214, 42497, 34299, 32725, 30374, 33115, 30330, 34413, 36017, 31391, 30015, 37645, 31244, 30658, 31295, 38718, 32544, 30024, 33647, 30631, 30214, 30651, 30785, 36017, 32744, 34396, 30503, 34084, 30267, 29871, 37513, 30502, 39225, 33647, 31195, 30392, 30383, 32460, 45867, 30437, 33265, 41557, 30210, 34357, 45205, 30214, 30651, 33227, 33140, 30210, 41022, 30267, 39626, 33207, 38657, 30392, 30214, 32001, 32858, 34299, 31331, 33140, 34494, 32001, 33115, 33564, 30210, 35470, 30214, 35098, 35482, 30210, 36017, 30275, 44819, 32023, 34003, 31994, 39814, 30267, 29871, 35317, 34575, 39225, 33647, 31195, 30392, 30383, 32460, 45867, 40159, 30406, 44414, 30503, 38715, 32344, 30805, 33265, 34357, 45205, 30267, 32023, 34299, 30505, 32858, 30275, 38310, 40496, 30503, 39186, 30214, 38652, 30505, 38501, 36017, 30275, 33998, 44819, 34357, 45205, 30267, 30810, 33529, 33140, 32587, 32099, 30214, 32664, 33059, 32940, 30267, 29871, 35317, 37472, 39225, 33647, 31195, 30392, 30383, 32460, 45867, 30505, 34357, 45205, 32132, 32487, 31838, 42410, 45509, 32290, 30267, 36850, 30214, 32023, 30437, 32039, 30505, 32858, 30275, 32907, 31138, 30503, 36102, 36017, 30214, 13, 13, 2277, 29937, 29871, 32465, 37012, 2, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953, 49953]\n",
      "2023-05-26 10:12:59,757,757 WARNING  140340029425472 MainThread 193 [build_dataset.py:48] æ ¼å¼åŒ–ç›‘ç£æ•°æ®é›†...\n",
      "0%|          | 0/5 [00:00<?, ?ex/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 3995.34ex/s]\n",
      "2023-05-26 10:12:59,767,767 WARNING  140340029425472 MainThread 193 [build_dataset.py:57] Tokenizing inputs... This may take some time...\n",
      "2023-05-26 10:12:59,807,807 INFO     140340029425472 MainThread 193 [build_dataset.py:296] eval_dataset: <fengx_ai.dataset.build_dataset.SupervisedDataset object at 0x7fa250860d60>\n",
      "2023-05-26 10:12:59,807,807 INFO     140340029425472 MainThread 193 [print_utils.py:34] CPU ä¸ªæ•°: 8\n",
      "2023-05-26 10:12:59,807,807 INFO     140340029425472 MainThread 193 [print_utils.py:35] CPU memory total: 59.83776092529297 GB.\n",
      "2023-05-26 10:12:59,808,808 INFO     140340029425472 MainThread 193 [print_utils.py:36] CPU memory use: 27.86309051513672 GB.\n",
      "2023-05-26 10:12:59,808,808 INFO     140340029425472 MainThread 193 [print_utils.py:37] CPU memory free: 1.9480514526367188 GB.\n",
      "2023-05-26 10:12:59,808,808 INFO     140340029425472 MainThread 193 [print_utils.py:38] CPU memory use percent: 47.7 %\n",
      "2023-05-26 10:12:59,808,808 INFO     140340029425472 MainThread 193 [print_utils.py:17] Driver Version: b'525.85.12'\n",
      "2023-05-26 10:12:59,809,809 INFO     140340029425472 MainThread 193 [print_utils.py:21] Device 0 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-26 10:12:59,809,809 INFO     140340029425472 MainThread 193 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-26 10:12:59,809,809 INFO     140340029425472 MainThread 193 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2303466796875 GB.\n",
      "2023-05-26 10:12:59,809,809 INFO     140340029425472 MainThread 193 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7696533203125 GB.\n",
      "2023-05-26 10:12:59,810,810 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:127] Init new peft model\n",
      "2023-05-26 10:14:54,390,390 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:153] model + peftç»“æ„: PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(49954, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (1): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (2): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (3): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (4): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (5): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (6): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (7): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (8): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (9): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (10): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (11): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (12): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (13): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (14): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (15): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (16): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (17): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (18): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (19): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (20): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (21): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (22): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (23): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (24): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Drop\n",
      "out(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (25): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (26): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (27): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (28): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (29): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (30): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "          (31): LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear(\n",
      "                in_features=4096, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear(\n",
      "                in_features=11008, out_features=4096, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=11008, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear(\n",
      "                in_features=4096, out_features=11008, bias=False\n",
      "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
      "                (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                (lora_B): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=49954, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2023-05-26 10:14:54,392,392 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:154] éªŒè¯å“ªäº›æ¨¡å—åœ¨lora\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.embed_tokens.weight'\n",
      "Arguments: (torch.Size([49954, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.0.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.1.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.2.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.3.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.4.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.5.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.6.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.7.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.8.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.9.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.10.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.11.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.12.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.13.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.14.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.15.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.16.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.17.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.18.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.19.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.20.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.21.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.22.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.23.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.24.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.25.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.26.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.27.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.28.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.29.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.30.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.self_attn.o_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.self_attn.o_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.mlp.gate_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.mlp.gate_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.mlp.down_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 11008]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.mlp.down_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([4096, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.mlp.up_proj.lora_A.weight'\n",
      "Arguments: (torch.Size([8, 4096]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.model.layers.31.mlp.up_proj.lora_B.weight'\n",
      "Arguments: (torch.Size([11008, 8]),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/opt/ml/code/auto_train.py\", line 90, in main\n",
      "    rjxai_train(\n",
      "  File \"/opt/ml/code/fengx_ai/train/rjxai_training_factory.py\", line 157, in rjxai_train\n",
      "    logger.info(name, param.shape)\n",
      "Message: 'base_model.model.lm_head.weight'\n",
      "Arguments: (torch.Size([49954, 4096]),)\n",
      "2023-05-26 10:14:55,635,635 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:158] ************** æ¨¡å‹å¯è®­ç»ƒå‚æ•°é‡ ********************\n",
      "trainable params: 429211648 || all params: 6905483264 || trainable%: 6.215519342977586\n",
      "2023-05-26 10:14:55,640,640 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:165] ************** åŠ è½½è®­ç»ƒç¯å¢ƒ **************\n",
      "2023-05-26 10:14:55,641,641 INFO     140340029425472 MainThread 193 [print_utils.py:34] CPU ä¸ªæ•°: 8\n",
      "2023-05-26 10:14:55,641,641 INFO     140340029425472 MainThread 193 [print_utils.py:35] CPU memory total: 59.83776092529297 GB.\n",
      "2023-05-26 10:14:55,641,641 INFO     140340029425472 MainThread 193 [print_utils.py:36] CPU memory use: 27.929359436035156 GB.\n",
      "2023-05-26 10:14:55,642,642 INFO     140340029425472 MainThread 193 [print_utils.py:37] CPU memory free: 1.8689918518066406 GB.\n",
      "2023-05-26 10:14:55,642,642 INFO     140340029425472 MainThread 193 [print_utils.py:38] CPU memory use percent: 47.8 %\n",
      "2023-05-26 10:14:55,642,642 INFO     140340029425472 MainThread 193 [print_utils.py:17] Driver Version: b'525.85.12'\n",
      "2023-05-26 10:14:55,642,642 INFO     140340029425472 MainThread 193 [print_utils.py:21] Device 0 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-26 10:14:55,643,643 INFO     140340029425472 MainThread 193 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-26 10:14:55,643,643 INFO     140340029425472 MainThread 193 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2303466796875 GB.\n",
      "2023-05-26 10:14:55,643,643 INFO     140340029425472 MainThread 193 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7696533203125 GB.\n",
      "2023-05-26 10:14:55,656,656 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:176] *************** å¼€å§‹è®­ç»ƒ ****************\n",
      "2023-05-26 10:14:55,657,657 INFO     140340029425472 MainThread 193 [print_utils.py:34] CPU ä¸ªæ•°: 8\n",
      "2023-05-26 10:14:55,657,657 INFO     140340029425472 MainThread 193 [print_utils.py:35] CPU memory total: 59.83776092529297 GB.\n",
      "2023-05-26 10:14:55,657,657 INFO     140340029425472 MainThread 193 [print_utils.py:36] CPU memory use: 27.92977523803711 GB.\n",
      "2023-05-26 10:14:55,657,657 INFO     140340029425472 MainThread 193 [print_utils.py:37] CPU memory free: 1.8685760498046875 GB.\n",
      "2023-05-26 10:14:55,657,657 INFO     140340029425472 MainThread 193 [print_utils.py:38] CPU memory use percent: 47.8 %\n",
      "2023-05-26 10:14:55,658,658 INFO     140340029425472 MainThread 193 [print_utils.py:17] Driver Version: b'525.85.12'\n",
      "2023-05-26 10:14:55,658,658 INFO     140340029425472 MainThread 193 [print_utils.py:21] Device 0 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-26 10:14:55,658,658 INFO     140340029425472 MainThread 193 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-26 10:14:55,658,658 INFO     140340029425472 MainThread 193 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2303466796875 GB.\n",
      "2023-05-26 10:14:55,659,659 INFO     140340029425472 MainThread 193 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7696533203125 GB.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "#015  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "20%|â–ˆâ–ˆ        | 1/5 [03:23<13:35, 203.90s/it]\n",
      "40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [06:36<09:51, 197.14s/it]\n",
      "60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [08:43<05:30, 165.30s/it]\n",
      "80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [11:55<02:55, 175.77s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [15:08<00:00, 181.84s/it]\n",
      "{'train_runtime': 908.1791, 'train_samples_per_second': 0.011, 'train_steps_per_second': 0.006, 'train_loss': 15.193890380859376, 'epoch': 1.0}\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [15:08<00:00, 181.84s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [15:08<00:00, 181.63s/it]\n",
      "2023-05-26 10:30:03,890,890 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:186] train metricsï¼š{'train_runtime': 908.1791, 'train_samples_per_second': 0.011, 'train_steps_per_second': 0.006, 'train_loss': 15.193890380859376, 'epoch': 1.0}\n",
      "***** train metrics *****\n",
      "epoch                    =        1.0\n",
      "train_loss               =    15.1939\n",
      "train_runtime            = 0:15:08.17\n",
      "train_samples            =         10\n",
      "train_samples_per_second =      0.011\n",
      "train_steps_per_second   =      0.006\n",
      "2023-05-26 10:30:03,892,892 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:193] *** Evaluate ***\n",
      "0%|          | 0/3 [00:00<?, ?it/s]\n",
      "67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [01:01<00:30, 30.71s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:32<00:00, 30.71s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:32<00:00, 30.71s/it]\n",
      "2023-05-26 10:32:36,388,388 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:199] å›°æƒ‘åº¦ä¸ºï¼šnan\n",
      "***** eval metrics *****\n",
      "epoch                   =        1.0\n",
      "eval_loss               =        nan\n",
      "eval_runtime            = 0:02:32.49\n",
      "eval_samples            =          5\n",
      "eval_samples_per_second =      0.033\n",
      "eval_steps_per_second   =       0.02\n",
      "perplexity              =        nan\n",
      "2023-05-26 10:32:36,391,391 INFO     140340029425472 MainThread 193 [rjxai_training_factory.py:206] eval metricsï¼š{'eval_loss': nan, 'eval_runtime': 152.493, 'eval_samples_per_second': 0.033, 'eval_steps_per_second': 0.02, 'epoch': 1.0, 'eval_samples': 5, 'perplexity': nan}\n",
      "2023-05-26 10:32:36,392,392 INFO     140340029425472 MainThread 193 [hub.py:20] ä¿å­˜æ¨¡å‹åˆ°ï¼šrjx/rjxai-lora-7b-v1\n",
      "2023-05-26 10:32:37,941,941 INFO     140340029425472 MainThread 193 [hub.py:33] ******* ä¸Šä¼ æ–°è®­ç»ƒçš„æ¨¡å‹åˆ° huggingface hub ********\n",
      "2023-05-26 10:32:37,941,941 INFO     140340029425472 MainThread 193 [hub.py:36] *** upload model hub ***\n",
      "/opt/conda/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:229: FutureWarning: 'list_models' currently returns a list of objects but is planned to be a generator starting from version 0.14 in order to implement pagination. Please avoid to use `list_models(...).__len__` or explicitly convert the output to a list first with `list(iter(list_models)(...))`.\n",
      "  warnings.warn(self._deprecation_msg.format(attr_name=attr_name), FutureWarning)\n",
      "2023-05-26 10:32:39,436,436 INFO     140340029425472 MainThread 193 [hub.py:74] folder_pathï¼š/opt/ml/code/fengx_ai/inference/code/LLAMA\n",
      "2023-05-26 10:32:39,437,437 INFO     140340029425472 MainThread 193 [hub.py:75] repo_idï¼šrjx/rjxai-lora-7b-v1/code\n",
      "2023-05-26 10:32:39,437,437 INFO     140340029425472 MainThread 193 [hub.py:81] è½¬ç§»æ–‡ä»¶åˆ—è¡¨ï¼š['inference.py', 'requirements.txt']\n",
      "2023-05-26 10:32:39,439,439 INFO     140340029425472 MainThread 193 [hub.py:59] folder_path:rjx/rjxai-lora-7b-v1\n",
      "2023-05-26 10:32:39,439,439 INFO     140340029425472 MainThread 193 [hub.py:61] ['logs', 'train_results.json', 'all_results.json', 'trainer_state.json', 'eval_results.json', 'pytorch_model.bin', 'tokenizer_config.json', 'special_tokens_map.json', 'added_tokens.json', 'tokenizer.model', 'training_args.bin', 'code']\n",
      "events.out.tfevents.1685096095.algo-1.193.1:   0%|          | 0.00/6.15k [00:00<?, ?B/s]\n",
      "events.out.tfevents.1685096095.algo-1.193.0:   0%|          | 0.00/4.38k [00:00<?, ?B/s]\n",
      "#033[A\n",
      "events.out.tfevents.1685097156.algo-1.193.2:   0%|          | 0.00/354 [00:00<?, ?B/s]#033[A#033[A\n",
      "pytorch_model.bin:   0%|          | 0.00/1.72G [00:00<?, ?B/s]\n",
      "#033[A#033[A#033[A\n",
      "Upload 6 LFS files:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "#033[A#033[A#033[A#033[A\n",
      "tokenizer.model:   0%|          | 0.00/758k [00:00<?, ?B/s]\n",
      "#033[A#033[A#033[A#033[A#033[A\n",
      "tokenizer.model:   1%|          | 8.19k/758k [00:00<00:28, 26.0kB/s]\n",
      "#033[A#033[A#033[A#033[A#033[A\n",
      "events.out.tfevents.1685097156.algo-1.193.2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 354/354 [00:00<00:00, 1.09kB/s]\n",
      "#033[A#033[A\n",
      "pytorch_model.bin:   0%|          | 8.19k/1.72G [00:00<18:52:55, 25.3kB/s]\n",
      "#033[A#033[A#033[A\n",
      "events.out.tfevents.1685096095.algo-1.193.0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.38k/4.38k [00:00<00:00, 12.8kB/s]\n",
      "#033[A\n",
      "events.out.tfevents.1685096095.algo-1.193.1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.15k/6.15k [00:00<00:00, 17.6kB/s]\n",
      "events.out.tfevents.1685096095.algo-1.193.0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.38k/4.38k [00:00<00:00, 9.85kB/s]\n",
      "events.out.tfevents.1685096095.algo-1.193.1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.15k/6.15k [00:00<00:00, 13.6kB/s]\n",
      "tokenizer.model:  14%|â–ˆâ–        | 106k/758k [00:00<00:02, 300kB/s]\n",
      "#033[A#033[A#033[A#033[A#033[A\n",
      "pytorch_model.bin:   0%|          | 115k/1.72G [00:00<1:30:28, 316kB/s]\n",
      "#033[A#033[A#033[A\n",
      "events.out.tfevents.1685097156.algo-1.193.2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 354/354 [00:00<00:00, 769B/s]\n",
      "tokenizer.model:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 319k/758k [00:00<00:00, 775kB/s]\n",
      "#033[A#033[A#033[A#033[A#033[A\n",
      "pytorch_model.bin:   0%|          | 336k/1.72G [00:00<35:47, 799kB/s]\n",
      "#033[A#033[A#033[A\n",
      "training_args.bin:   0%|          | 0.00/3.45k [00:00<?, ?B/s]\n",
      "pytorch_model.bin:   0%|          | 1.39M/1.72G [00:00<08:47, 3.25MB/s]\n",
      "#033[A#033[A#033[A\n",
      "Upload 6 LFS files:  17%|â–ˆâ–‹        | 1/6 [00:00<00:03,  1.40it/s]\n",
      "#033[A#033[A#033[A#033[A\n",
      "training_args.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.45k/3.45k [00:00<00:00, 41.2kB/s]\n",
      "pytorch_model.bin:   0%|          | 5.44M/1.72G [00:00<02:19, 12.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "tokenizer.model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 758k/758k [00:00<00:00, 896kB/s]\n",
      "pytorch_model.bin:   1%|          | 10.4M/1.72G [00:00<01:23, 20.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   1%|          | 15.5M/1.72G [00:01<01:03, 26.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   1%|          | 18.3M/1.72G [00:01<01:11, 23.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   1%|â–         | 23.1M/1.72G [00:01<01:01, 27.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   2%|â–         | 28.4M/1.72G [00:01<00:52, 32.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   2%|â–         | 32.0M/1.72G [00:01<01:00, 27.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   2%|â–         | 39.3M/1.72G [00:01<00:47, 35.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   3%|â–         | 43.6M/1.72G [00:01<00:47, 35.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   3%|â–         | 48.0M/1.72G [00:02<00:57, 28.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   3%|â–         | 55.2M/1.72G [00:02<00:47, 35.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   4%|â–         | 60.4M/1.72G [00:02<00:44, 37.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   4%|â–         | 64.4M/1.72G [00:02<00:51, 32.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   4%|â–         | 71.3M/1.72G [00:02<00:43, 37.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   4%|â–         | 75.3M/1.72G [00:02<00:47, 34.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   5%|â–         | 80.0M/1.72G [00:03<00:55, 29.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   5%|â–Œ         | 87.1M/1.72G [00:03<00:46, 35.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   5%|â–Œ         | 92.4M/1.72G [00:03<00:43, 37.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   6%|â–Œ         | 96.4M/1.72G [00:03<00:54, 29.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   6%|â–Œ         | 103M/1.72G [00:03<00:46, 35.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   6%|â–‹         | 108M/1.72G [00:03<00:43, 37.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   7%|â–‹         | 112M/1.72G [00:04<00:52, 30.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   7%|â–‹         | 119M/1.72G [00:04<00:44, 35.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   7%|â–‹         | 125M/1.72G [00:04<00:42, 37.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   7%|â–‹         | 129M/1.72G [00:04<00:49, 32.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   8%|â–Š         | 135M/1.72G [00:04<00:42, 37.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   8%|â–Š         | 141M/1.72G [00:04<00:40, 39.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   8%|â–Š         | 145M/1.72G [00:05<00:57, 27.4MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:   9%|â–‰         | 151M/1.72G [00:05<00:48, 32.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   9%|â–‰         | 157M/1.72G [00:05<00:44, 34.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:   9%|â–‰         | 160M/1.72G [00:05<00:56, 27.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  10%|â–‰         | 167M/1.72G [00:05<00:47, 32.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  10%|â–ˆ         | 173M/1.72G [00:05<00:42, 36.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  10%|â–ˆ         | 177M/1.72G [00:05<00:50, 30.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  11%|â–ˆ         | 183M/1.72G [00:06<00:44, 34.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  11%|â–ˆ         | 188M/1.72G [00:06<00:41, 36.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  11%|â–ˆ         | 192M/1.72G [00:06<00:49, 30.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  12%|â–ˆâ–        | 199M/1.72G [00:06<00:42, 36.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  12%|â–ˆâ–        | 204M/1.72G [00:06<00:39, 37.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  12%|â–ˆâ–        | 208M/1.72G [00:06<00:48, 31.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  13%|â–ˆâ–        | 215M/1.72G [00:07<00:41, 36.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  13%|â–ˆâ–        | 220M/1.72G [00:07<00:39, 38.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  13%|â–ˆâ–        | 224M/1.72G [00:07<00:45, 32.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  13%|â–ˆâ–        | 231M/1.72G [00:07<00:39, 37.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  14%|â–ˆâ–        | 237M/1.72G [00:07<00:37, 39.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  14%|â–ˆâ–        | 241M/1.72G [00:07<00:49, 30.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  14%|â–ˆâ–        | 247M/1.72G [00:07<00:41, 35.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  15%|â–ˆâ–        | 253M/1.72G [00:08<00:39, 37.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  15%|â–ˆâ–        | 257M/1.72G [00:08<00:46, 31.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  15%|â–ˆâ–Œ        | 263M/1.72G [00:08<00:40, 36.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  16%|â–ˆâ–Œ        | 268M/1.72G [00:08<00:38, 37.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  16%|â–ˆâ–Œ        | 272M/1.72G [00:08<00:45, 31.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  16%|â–ˆâ–‹        | 279M/1.72G [00:08<00:39, 36.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  17%|â–ˆâ–‹        | 284M/1.72G [00:08<00:37, 38.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  17%|â–ˆâ–‹        | 288M/1.72G [00:09<00:45, 31.6MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  17%|â–ˆâ–‹        | 295M/1.72G [00:09<00:38, 36.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  18%|â–ˆâ–Š        | 301M/1.72G [00:09<00:35, 39.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  18%|â–ˆâ–Š        | 306M/1.72G [00:09<00:45, 30.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  18%|â–ˆâ–Š        | 311M/1.72G [00:09<00:41, 33.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  18%|â–ˆâ–Š        | 316M/1.72G [00:09<00:38, 36.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  19%|â–ˆâ–Š        | 320M/1.72G [00:10<00:46, 29.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  19%|â–ˆâ–‰        | 327M/1.72G [00:10<00:39, 35.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  19%|â–ˆâ–‰        | 332M/1.72G [00:10<00:37, 36.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  20%|â–ˆâ–‰        | 336M/1.72G [00:10<00:42, 32.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  20%|â–ˆâ–‰        | 343M/1.72G [00:10<00:36, 37.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  20%|â–ˆâ–ˆ        | 348M/1.72G [00:10<00:35, 38.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  21%|â–ˆâ–ˆ        | 352M/1.72G [00:11<00:46, 29.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  21%|â–ˆâ–ˆ        | 359M/1.72G [00:11<00:38, 34.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  21%|â–ˆâ–ˆ        | 364M/1.72G [00:11<00:36, 37.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  21%|â–ˆâ–ˆâ–       | 368M/1.72G [00:11<00:40, 33.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  22%|â–ˆâ–ˆâ–       | 375M/1.72G [00:11<00:35, 38.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  22%|â–ˆâ–ˆâ–       | 380M/1.72G [00:11<00:33, 39.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  22%|â–ˆâ–ˆâ–       | 384M/1.72G [00:11<00:44, 30.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  23%|â–ˆâ–ˆâ–       | 391M/1.72G [00:12<00:37, 35.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  23%|â–ˆâ–ˆâ–       | 396M/1.72G [00:12<00:35, 37.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  23%|â–ˆâ–ˆâ–       | 400M/1.72G [00:12<00:42, 31.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  24%|â–ˆâ–ˆâ–       | 407M/1.72G [00:12<00:36, 36.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  24%|â–ˆâ–ˆâ–       | 412M/1.72G [00:12<00:34, 37.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  24%|â–ˆâ–ˆâ–       | 416M/1.72G [00:12<00:37, 34.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  25%|â–ˆâ–ˆâ–       | 423M/1.72G [00:12<00:33, 39.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  25%|â–ˆâ–ˆâ–       | 428M/1.72G [00:13<00:32, 40.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  25%|â–ˆâ–ˆâ–Œ       | 432M/1.72G [00:13<00:39, 32.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  26%|â–ˆâ–ˆâ–Œ       | 439M/1.72G [00:13<00:34, 36.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  26%|â–ˆâ–ˆâ–Œ       | 444M/1.72G [00:13<00:32, 39.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  26%|â–ˆâ–ˆâ–Œ       | 449M/1.72G [00:13<00:38, 33.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  27%|â–ˆâ–ˆâ–‹       | 455M/1.72G [00:13<00:33, 37.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  27%|â–ˆâ–ˆâ–‹       | 461M/1.72G [00:13<00:31, 39.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  27%|â–ˆâ–ˆâ–‹       | 465M/1.72G [00:14<00:38, 32.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  27%|â–ˆâ–ˆâ–‹       | 471M/1.72G [00:14<00:33, 36.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  28%|â–ˆâ–ˆâ–Š       | 477M/1.72G [00:14<00:32, 37.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  28%|â–ˆâ–ˆâ–Š       | 480M/1.72G [00:14<00:41, 29.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  28%|â–ˆâ–ˆâ–Š       | 487M/1.72G [00:14<00:35, 34.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  29%|â–ˆâ–ˆâ–Š       | 493M/1.72G [00:14<00:32, 37.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  29%|â–ˆâ–ˆâ–‰       | 497M/1.72G [00:15<00:40, 30.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  29%|â–ˆâ–ˆâ–‰       | 503M/1.72G [00:15<00:34, 35.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  30%|â–ˆâ–ˆâ–‰       | 509M/1.72G [00:15<00:31, 37.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  30%|â–ˆâ–ˆâ–‰       | 513M/1.72G [00:15<00:38, 31.0MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  30%|â–ˆâ–ˆâ–ˆ       | 519M/1.72G [00:15<00:34, 34.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  31%|â–ˆâ–ˆâ–ˆ       | 524M/1.72G [00:15<00:32, 36.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  31%|â–ˆâ–ˆâ–ˆ       | 528M/1.72G [00:15<00:35, 33.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  31%|â–ˆâ–ˆâ–ˆ       | 535M/1.72G [00:16<00:31, 38.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 541M/1.72G [00:16<00:29, 40.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 545M/1.72G [00:16<00:34, 33.8MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 551M/1.72G [00:16<00:31, 36.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 556M/1.72G [00:16<00:30, 38.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 560M/1.72G [00:16<00:38, 30.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 567M/1.72G [00:17<00:32, 35.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 572M/1.72G [00:17<00:30, 37.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 576M/1.72G [00:17<00:35, 32.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 583M/1.72G [00:17<00:30, 37.4MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 588M/1.72G [00:17<00:29, 38.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  34%|â–ˆâ–ˆâ–ˆâ–      | 592M/1.72G [00:17<00:37, 29.8MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  35%|â–ˆâ–ˆâ–ˆâ–      | 599M/1.72G [00:17<00:31, 35.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 604M/1.72G [00:18<00:29, 37.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 608M/1.72G [00:18<00:32, 34.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 615M/1.72G [00:18<00:28, 38.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 621M/1.72G [00:18<00:27, 40.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 625M/1.72G [00:18<00:30, 35.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 631M/1.72G [00:18<00:28, 38.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 636M/1.72G [00:18<00:26, 40.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 641M/1.72G [00:19<00:33, 32.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 647M/1.72G [00:19<00:29, 36.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 652M/1.72G [00:19<00:27, 38.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 656M/1.72G [00:19<00:33, 32.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 663M/1.72G [00:19<00:28, 36.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 668M/1.72G [00:19<00:27, 38.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 672M/1.72G [00:19<00:31, 33.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 679M/1.72G [00:20<00:27, 37.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 684M/1.72G [00:20<00:28, 36.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 688M/1.72G [00:20<00:36, 28.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 695M/1.72G [00:20<00:30, 34.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 700M/1.72G [00:20<00:28, 36.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 704M/1.72G [00:20<00:31, 31.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 711M/1.72G [00:21<00:27, 36.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 716M/1.72G [00:21<00:26, 38.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 720M/1.72G [00:21<00:31, 31.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 727M/1.72G [00:21<00:26, 36.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 732M/1.72G [00:21<00:25, 38.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 736M/1.72G [00:21<00:31, 31.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 743M/1.72G [00:21<00:26, 36.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 747M/1.72G [00:22<00:28, 34.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 752M/1.72G [00:22<00:34, 27.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 759M/1.72G [00:22<00:28, 33.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 764M/1.72G [00:22<00:26, 36.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 768M/1.72G [00:22<00:32, 28.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 775M/1.72G [00:22<00:27, 34.3MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 780M/1.72G [00:23<00:25, 36.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 784M/1.72G [00:23<00:30, 30.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 791M/1.72G [00:23<00:25, 36.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 797M/1.72G [00:23<00:24, 38.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 801M/1.72G [00:23<00:28, 32.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 807M/1.72G [00:23<00:25, 36.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 813M/1.72G [00:24<00:23, 38.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 817M/1.72G [00:24<00:27, 32.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 823M/1.72G [00:24<00:24, 36.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 828M/1.72G [00:24<00:23, 37.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 832M/1.72G [00:24<00:29, 30.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 839M/1.72G [00:24<00:24, 36.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 844M/1.72G [00:24<00:23, 37.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 848M/1.72G [00:25<00:30, 28.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 855M/1.72G [00:25<00:25, 34.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 860M/1.72G [00:25<00:24, 35.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 864M/1.72G [00:25<00:28, 30.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 871M/1.72G [00:25<00:23, 35.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 877M/1.72G [00:25<00:21, 38.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 881M/1.72G [00:26<00:24, 33.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 887M/1.72G [00:26<00:22, 36.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 892M/1.72G [00:26<00:21, 38.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 896M/1.72G [00:26<00:23, 34.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 903M/1.72G [00:26<00:20, 39.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 909M/1.72G [00:26<00:19, 41.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 914M/1.72G [00:26<00:22, 35.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 919M/1.72G [00:27<00:21, 37.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 924M/1.72G [00:27<00:20, 39.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 928M/1.72G [00:27<00:24, 32.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 935M/1.72G [00:27<00:20, 37.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 940M/1.72G [00:27<00:19, 38.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 944M/1.72G [00:27<00:24, 31.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 951M/1.72G [00:27<00:21, 35.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 956M/1.72G [00:28<00:20, 38.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 960M/1.72G [00:28<00:25, 29.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 967M/1.72G [00:28<00:21, 34.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 974M/1.72G [00:28<00:19, 38.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 978M/1.72G [00:28<00:24, 30.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 983M/1.72G [00:28<00:21, 33.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 989M/1.72G [00:29<00:20, 36.3MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 993M/1.72G [00:29<00:24, 29.6MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 999M/1.72G [00:29<00:20, 34.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.00G/1.72G [00:29<00:19, 35.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.01G/1.72G [00:29<00:22, 31.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.02G/1.72G [00:29<00:18, 37.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.02G/1.72G [00:29<00:17, 38.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1.02G/1.72G [00:30<00:20, 34.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.03G/1.72G [00:30<00:17, 39.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.04G/1.72G [00:30<00:17, 39.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.04G/1.72G [00:30<00:20, 33.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.05G/1.72G [00:30<00:17, 37.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.05G/1.72G [00:30<00:17, 39.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.06G/1.72G [00:30<00:20, 32.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.06G/1.72G [00:31<00:17, 37.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.07G/1.72G [00:31<00:16, 38.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.07G/1.72G [00:31<00:20, 30.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.08G/1.72G [00:31<00:17, 35.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.08G/1.72G [00:31<00:16, 37.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.09G/1.72G [00:31<00:20, 30.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.10G/1.72G [00:32<00:17, 35.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.10G/1.72G [00:32<00:17, 35.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.10G/1.72G [00:32<00:20, 29.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.11G/1.72G [00:32<00:17, 35.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.12G/1.72G [00:32<00:16, 37.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.12G/1.72G [00:32<00:18, 31.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.13G/1.72G [00:32<00:16, 36.5MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.13G/1.72G [00:33<00:15, 38.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.14G/1.72G [00:33<00:19, 30.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.14G/1.72G [00:33<00:16, 35.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.15G/1.72G [00:33<00:15, 37.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.15G/1.72G [00:33<00:20, 28.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.16G/1.72G [00:33<00:16, 33.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.16G/1.72G [00:34<00:15, 36.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.17G/1.72G [00:34<00:18, 28.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.18G/1.72G [00:34<00:15, 34.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.18G/1.72G [00:34<00:14, 36.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.18G/1.72G [00:34<00:17, 31.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.19G/1.72G [00:34<00:14, 36.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.20G/1.72G [00:35<00:13, 38.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.20G/1.72G [00:35<00:14, 34.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.21G/1.72G [00:35<00:13, 39.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.21G/1.72G [00:35<00:12, 40.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.22G/1.72G [00:35<00:15, 33.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.22G/1.72G [00:35<00:13, 37.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.23G/1.72G [00:35<00:12, 39.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.23G/1.72G [00:36<00:15, 32.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.24G/1.72G [00:36<00:12, 37.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.24G/1.72G [00:36<00:12, 38.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.25G/1.72G [00:36<00:14, 31.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.26G/1.72G [00:36<00:12, 36.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.26G/1.72G [00:36<00:11, 38.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.26G/1.72G [00:36<00:14, 31.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.27G/1.72G [00:37<00:12, 36.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.28G/1.72G [00:37<00:11, 37.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.28G/1.72G [00:37<00:14, 29.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.29G/1.72G [00:37<00:12, 35.4MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.29G/1.72G [00:37<00:11, 37.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.30G/1.72G [00:37<00:13, 31.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.30G/1.72G [00:38<00:11, 35.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.31G/1.72G [00:38<00:10, 38.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.31G/1.72G [00:38<00:12, 31.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.32G/1.72G [00:38<00:11, 35.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.32G/1.72G [00:38<00:10, 37.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1.33G/1.72G [00:38<00:12, 30.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.34G/1.72G [00:38<00:10, 35.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.34G/1.72G [00:39<00:10, 37.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.34G/1.72G [00:39<00:11, 31.8MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.35G/1.72G [00:39<00:10, 36.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.36G/1.72G [00:39<00:09, 38.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.36G/1.72G [00:40<00:33, 10.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.36G/1.72G [00:40<00:29, 12.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.37G/1.72G [00:41<00:21, 16.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.38G/1.72G [00:41<00:16, 20.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.38G/1.72G [00:41<00:15, 21.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.38G/1.72G [00:41<00:14, 23.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.39G/1.72G [00:41<00:11, 28.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.39G/1.72G [00:41<00:13, 24.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.40G/1.72G [00:41<00:10, 31.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.40G/1.72G [00:42<00:09, 34.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.41G/1.72G [00:42<00:10, 29.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.42G/1.72G [00:42<00:08, 35.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.42G/1.72G [00:42<00:07, 37.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.42G/1.72G [00:42<00:09, 29.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.43G/1.72G [00:42<00:08, 34.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.44G/1.72G [00:42<00:07, 36.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.44G/1.72G [00:43<00:08, 31.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.45G/1.72G [00:43<00:07, 36.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.45G/1.72G [00:43<00:06, 38.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.46G/1.72G [00:43<00:09, 28.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.46G/1.72G [00:43<00:07, 33.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.47G/1.72G [00:43<00:07, 34.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.47G/1.72G [00:44<00:08, 27.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.48G/1.72G [00:44<00:07, 33.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.49G/1.72G [00:44<00:06, 37.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.49G/1.72G [00:44<00:06, 33.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.50G/1.72G [00:44<00:06, 35.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.50G/1.72G [00:44<00:05, 37.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.50G/1.72G [00:45<00:07, 30.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.51G/1.72G [00:45<00:05, 35.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.52G/1.72G [00:45<00:05, 38.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.52G/1.72G [00:45<00:06, 30.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.53G/1.72G [00:45<00:05, 33.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.53G/1.72G [00:45<00:05, 36.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.54G/1.72G [00:46<00:05, 30.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.54G/1.72G [00:46<00:04, 35.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.55G/1.72G [00:46<00:04, 37.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.55G/1.72G [00:46<00:05, 31.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.56G/1.72G [00:46<00:04, 36.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.56G/1.72G [00:46<00:04, 38.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.57G/1.72G [00:46<00:04, 32.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.58G/1.72G [00:47<00:03, 37.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.58G/1.72G [00:47<00:03, 40.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.59G/1.72G [00:47<00:03, 34.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.59G/1.72G [00:47<00:03, 36.4MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.60G/1.72G [00:47<00:03, 38.9MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.60G/1.72G [00:48<00:07, 15.9MB/s]#033[A#033[A#033[A\n",
      "pytorch_model.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.60G/1.72G [00:48<00:06, 17.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.61G/1.72G [00:48<00:05, 18.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.61G/1.72G [00:48<00:04, 23.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.62G/1.72G [00:48<00:04, 21.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.62G/1.72G [00:49<00:03, 28.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.63G/1.72G [00:49<00:02, 32.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.63G/1.72G [00:49<00:03, 28.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.64G/1.72G [00:49<00:02, 34.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.64G/1.72G [00:49<00:01, 36.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.65G/1.72G [00:49<00:02, 31.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.66G/1.72G [00:49<00:01, 36.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.66G/1.72G [00:50<00:01, 38.0MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.66G/1.72G [00:50<00:01, 30.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.67G/1.72G [00:50<00:01, 35.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.68G/1.72G [00:50<00:01, 37.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.68G/1.72G [00:50<00:01, 30.5MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.69G/1.72G [00:50<00:00, 35.7MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.69G/1.72G [00:50<00:00, 37.6MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.70G/1.72G [00:51<00:00, 32.2MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.70G/1.72G [00:51<00:00, 37.1MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.71G/1.72G [00:51<00:00, 38.8MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.71G/1.72G [00:51<00:00, 31.3MB/s]\n",
      "#033[A#033[A#033[A\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.72G/1.72G [00:51<00:00, 33.1MB/s]\n",
      "Upload 6 LFS files:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:52<00:28, 14.06s/it]\n",
      "#033[A#033[A#033[A#033[A\n",
      "Upload 6 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:52<00:00,  8.71s/it]\n",
      "2023-05-26 10:33:37,778,778 INFO     140340029425472 MainThread 193 [hub.py:68] https://huggingface.co/rjx/rjxai-lora-7b-v1\n",
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "wandb: \\ 0.002 MB of 0.673 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 0.002 MB of 0.673 MB uploaded (0.000 MB deduped)\n",
      "wandb: / 0.673 MB of 0.673 MB uploaded (0.000 MB deduped)\n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:                   eval/runtime â–\n",
      "wandb:        eval/samples_per_second â–\n",
      "wandb:          eval/steps_per_second â–\n",
      "wandb:                    train/epoch â–â–\n",
      "wandb:              train/global_step â–â–\n",
      "wandb:               train/total_flos â–\n",
      "wandb:               train/train_loss â–\n",
      "wandb:            train/train_runtime â–\n",
      "wandb: train/train_samples_per_second â–\n",
      "wandb:   train/train_steps_per_second â–\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:                      eval/loss nan\n",
      "wandb:                   eval/runtime 152.493\n",
      "wandb:        eval/samples_per_second 0.033\n",
      "wandb:          eval/steps_per_second 0.02\n",
      "wandb:                    train/epoch 1.0\n",
      "wandb:              train/global_step 5\n",
      "wandb:               train/total_flos 191859357941760.0\n",
      "wandb:               train/train_loss 15.19389\n",
      "wandb:            train/train_runtime 908.1791\n",
      "wandb: train/train_samples_per_second 0.011\n",
      "wandb:   train/train_steps_per_second 0.006\n",
      "wandb:\n",
      "wandb: ğŸš€ View run huggingface-pytorch-training-2023-05-26-09-56-10-653-v0baru-algo-1 at: https://wandb.ai/feng-x/uncategorized/runs/huggingface-pytorch-training-2023-05-26-09-56-10-653-v0baru-algo-1\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230526_100306-huggingface-pytorch-training-2023-05-26-09-56-10-653-v0baru-algo-1/logs\n",
      "2023-05-26 10:33:44,258,258 INFO     140340029425472 MainThread 193 [util.py:54] process shutting down\n",
      "2023-05-26 10:33:46,655 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2023-05-26 10:33:46,655 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2023-05-26 10:33:46,660 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2023-05-26 10:33:58 Uploading - Uploading generated training model\n",
      "2023-05-26 10:33:58 Completed - Training job completed\n",
      "Training seconds: 2165\n",
      "Billable seconds: 2165\n"
     ]
    }
   ],
   "source": [
    "from assisted_intelligence.ml.hf_sagemaker import HfSagemaker\n",
    "\n",
    "mlFacotry=HfSagemaker(\n",
    "    # è®¾å®š sagemaker è®­ç»ƒæœºå™¨\n",
    "    sagemaker_config={\n",
    "        # 'instance_type': 'ml.p3dn.24xlarge',\n",
    "        # 'instance_type': 'ml.p4d.24xlarge',\n",
    "        'instance_type': 'ml.p3.2xlarge',\n",
    "        'instance_count': 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "mlFacotry.play(\n",
    "    config={\n",
    "        # è®­ç»ƒç±»å‹ï¼Œç›®å‰åªæœ‰ä¸¤ç§è®­ç»ƒç±»å‹ BERT LLAMA RLHF\n",
    "        'training_model': 'LLAMA',\n",
    "        'clone_repo': 'rjx/rjxai-lora-7b-v1',\n",
    "        'model_name_or_path':'rjx/rjxai-zh-llama-7b-v1',\n",
    "        'dataset_name': 'rjx/ai-and-human-20',\n",
    "        'task_type': 'text2text',\n",
    "        'use_auth_token': True,\n",
    "        # 'max_train_samples': 20,\n",
    "        # 'max_eval_samples': 2,\n",
    "        # 'max_test_samples': 2,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ sagemaker tools è¿è¡Œ llama lora æ¨¡å‹ v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-29 15:01:53,389,389 INFO     4729394688 MainThread 70147 [fx_hf_sagemaker.py:27] åˆå§‹åŒ–ç¯å¢ƒå˜é‡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name master to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-29 15:01:57,450,450 INFO     4729394688 MainThread 70147 [fx_hf_sagemaker.py:39] å½“å‰ä½¿ç”¨localæœºå™¨è¿›è¡Œè¿œç¨‹è¿æ¥ï¼›ä½¿ç”¨boto3.clientè¿›è¡Œiamæƒé™è·å–\n",
      "2023-05-29 15:01:58,965,965 INFO     4729394688 MainThread 70147 [fx_hf_sagemaker.py:50] æ„å»ºestimatorç¯å¢ƒ\n",
      "2023-05-29 15:01:59,071,071 INFO     4729394688 MainThread 70147 [fx_hf_sagemaker.py:77] å¯åŠ¨estimator\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported processor: cpu. You may need to upgrade your SDK version (pip install -U sagemaker) for newer processors. Supported processor(s): gpu.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfengx_ai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfx_hf_sagemaker\u001b[39;00m \u001b[39mimport\u001b[39;00m FxHfSagemaker\n\u001b[1;32m      3\u001b[0m fxMlFacotry\u001b[39m=\u001b[39mFxHfSagemaker(\n\u001b[1;32m      4\u001b[0m     \u001b[39m# è®¾å®š sagemaker è®­ç»ƒæœºå™¨\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     sagemaker_config\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     },\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m fxMlFacotry\u001b[39m.\u001b[39;49mplay(\n\u001b[1;32m     15\u001b[0m     config\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     16\u001b[0m         \u001b[39m# è®­ç»ƒç±»å‹ï¼Œç›®å‰åªæœ‰ä¸¤ç§è®­ç»ƒç±»å‹ BERT LLAMA RLHF\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mtraining_model\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mLLAMA\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mclone_repo\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mrjx/rjxai-lora-7b-v1\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     19\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mmodel_name_or_path\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mrjx/rjxai-zh-llama-7b-v1\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     20\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mdataset_name\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mrjx/ai-and-human-20\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     21\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mtask_type\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mtext2text\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     22\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39muse_auth_token\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     23\u001b[0m         \u001b[39m# 'max_train_samples': 20,\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m         \u001b[39m# 'max_eval_samples': 2,\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m         \u001b[39m# 'max_test_samples': 2,\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m     },\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/ai/fengx_ai/fengx_ai/ml/fx_hf_sagemaker.py:78\u001b[0m, in \u001b[0;36mFxHfSagemaker.play\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     51\u001b[0m huggingface_estimator \u001b[39m=\u001b[39m HuggingFace(\n\u001b[1;32m     52\u001b[0m \t\u001b[39m# æœ¬åœ°æºæ–‡ä»¶è·¯å¾„ï¼Œè¯¥æºæ–‡ä»¶è·¯å¾„ä¸‹æ–‡ä»¶å¤¹ä¼šè¢«å‘é€åˆ° sagemaker training job æœºå™¨ä¸Šæ‰§è¡Œã€‚\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \t\u001b[39m# åŒæ—¶ sagemaker ä¼šè‡ªåŠ¨æ‰§è¡Œè¯¥æ–‡ä»¶å¤¹ä¸­çš„ requirements.txt æ–‡ä»¶å®‰è£… python ä¾èµ–\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \tdistribution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sagemaker_distribution,\n\u001b[1;32m     75\u001b[0m )\n\u001b[1;32m     77\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39må¯åŠ¨estimator\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m huggingface_estimator\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py:284\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[39mreturn\u001b[39;00m context\n\u001b[1;32m    282\u001b[0m     \u001b[39mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m run_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/estimator.py:1192\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39m@runnable_by_pipeline\u001b[39m\n\u001b[1;32m   1128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m   1129\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1134\u001b[0m     experiment_config: Optional[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1135\u001b[0m ):\n\u001b[1;32m   1136\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train a model using the input training dataset.\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[39m    The API calls the Amazon SageMaker CreateTrainingJob API to start\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m        :class:`~sagemaker.workflow.pipeline_context.PipelineSession`\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1192\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_for_training(job_name\u001b[39m=\u001b[39;49mjob_name)\n\u001b[1;32m   1194\u001b[0m     experiment_config \u001b[39m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[1;32m   1195\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_training_job \u001b[39m=\u001b[39m _TrainingJob\u001b[39m.\u001b[39mstart_new(\u001b[39mself\u001b[39m, inputs, experiment_config)\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/estimator.py:3157\u001b[0m, in \u001b[0;36mFramework._prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m   3149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prepare_for_training\u001b[39m(\u001b[39mself\u001b[39m, job_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   3150\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Set hyperparameters needed for training. This method will also validate ``source_dir``.\u001b[39;00m\n\u001b[1;32m   3151\u001b[0m \n\u001b[1;32m   3152\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3155\u001b[0m \u001b[39m            constructor if applicable.\u001b[39;00m\n\u001b[1;32m   3156\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3157\u001b[0m     \u001b[39msuper\u001b[39;49m(Framework, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_prepare_for_training(job_name\u001b[39m=\u001b[39;49mjob_name)\n\u001b[1;32m   3159\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_and_set_debugger_configs()\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/estimator.py:766\u001b[0m, in \u001b[0;36mEstimatorBase._prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prepare_for_training\u001b[39m(\u001b[39mself\u001b[39m, job_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    759\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Set any values in the estimator that need to be set before training.\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \n\u001b[1;32m    761\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39m            constructor if applicable.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 766\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_job_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_or_create_name(job_name)\n\u001b[1;32m    768\u001b[0m     \u001b[39m# if output_path was specified we use it otherwise initialize here.\u001b[39;00m\n\u001b[1;32m    769\u001b[0m     \u001b[39m# For Local Mode with local_code=True we don't need an explicit output_path\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/estimator.py:740\u001b[0m, in \u001b[0;36mEstimatorBase._get_or_create_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39mif\u001b[39;00m name:\n\u001b[1;32m    738\u001b[0m     \u001b[39mreturn\u001b[39;00m name\n\u001b[0;32m--> 740\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_base_job_name()\n\u001b[1;32m    741\u001b[0m \u001b[39mreturn\u001b[39;00m name_from_base(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_job_name)\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/estimator.py:723\u001b[0m, in \u001b[0;36mEstimatorBase._ensure_base_job_name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set ``self.base_job_name`` if it is not set already.\"\"\"\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[39m# honor supplied base_job_name or generate it\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_job_name \u001b[39m=\u001b[39m (\n\u001b[1;32m    720\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_job_name\n\u001b[1;32m    721\u001b[0m     \u001b[39mor\u001b[39;00m get_jumpstart_base_name_if_jumpstart_model(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_uri)\n\u001b[1;32m    722\u001b[0m     \u001b[39mor\u001b[39;00m base_name_from_image(\n\u001b[0;32m--> 723\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_image_uri(), default_base_name\u001b[39m=\u001b[39mEstimatorBase\u001b[39m.\u001b[39mJOB_CLASS_NAME\n\u001b[1;32m    724\u001b[0m     )\n\u001b[1;32m    725\u001b[0m )\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/estimator.py:3329\u001b[0m, in \u001b[0;36mFramework.training_image_uri\u001b[0;34m(self, region)\u001b[0m\n\u001b[1;32m   3314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_image_uri\u001b[39m(\u001b[39mself\u001b[39m, region\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   3315\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Docker image to use for training.\u001b[39;00m\n\u001b[1;32m   3316\u001b[0m \n\u001b[1;32m   3317\u001b[0m \u001b[39m    The :meth:`~sagemaker.estimator.EstimatorBase.fit` method, which does\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3326\u001b[0m \u001b[39m        str: The URI of the Docker image.\u001b[39;00m\n\u001b[1;32m   3327\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3329\u001b[0m     \u001b[39mreturn\u001b[39;00m image_uris\u001b[39m.\u001b[39;49mget_training_image_uri(\n\u001b[1;32m   3330\u001b[0m         region\u001b[39m=\u001b[39;49mregion \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msagemaker_session\u001b[39m.\u001b[39;49mboto_region_name,\n\u001b[1;32m   3331\u001b[0m         framework\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_framework_name,\n\u001b[1;32m   3332\u001b[0m         framework_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframework_version,  \u001b[39m# pylint: disable=no-member\u001b[39;49;00m\n\u001b[1;32m   3333\u001b[0m         py_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpy_version,  \u001b[39m# pylint: disable=no-member\u001b[39;49;00m\n\u001b[1;32m   3334\u001b[0m         image_uri\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_uri,\n\u001b[1;32m   3335\u001b[0m         distribution\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdistribution\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   3336\u001b[0m         compiler_config\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcompiler_config\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   3337\u001b[0m         tensorflow_version\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtensorflow_version\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   3338\u001b[0m         pytorch_version\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpytorch_version\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   3339\u001b[0m         instance_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_instance_type(),\n\u001b[1;32m   3340\u001b[0m     )\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/image_uris.py:657\u001b[0m, in \u001b[0;36mget_training_image_uri\u001b[0;34m(region, framework, framework_version, py_version, image_uri, distribution, compiler_config, tensorflow_version, pytorch_version, instance_type)\u001b[0m\n\u001b[1;32m    654\u001b[0m     container_version \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    655\u001b[0m     base_framework_version \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m \u001b[39mreturn\u001b[39;00m retrieve(\n\u001b[1;32m    658\u001b[0m     framework,\n\u001b[1;32m    659\u001b[0m     region,\n\u001b[1;32m    660\u001b[0m     instance_type\u001b[39m=\u001b[39;49minstance_type,\n\u001b[1;32m    661\u001b[0m     version\u001b[39m=\u001b[39;49mframework_version,\n\u001b[1;32m    662\u001b[0m     py_version\u001b[39m=\u001b[39;49mpy_version,\n\u001b[1;32m    663\u001b[0m     image_scope\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    664\u001b[0m     distribution\u001b[39m=\u001b[39;49mdistribution,\n\u001b[1;32m    665\u001b[0m     base_framework_version\u001b[39m=\u001b[39;49mbase_framework_version,\n\u001b[1;32m    666\u001b[0m     container_version\u001b[39m=\u001b[39;49mcontainer_version,\n\u001b[1;32m    667\u001b[0m     training_compiler_config\u001b[39m=\u001b[39;49mcompiler_config,\n\u001b[1;32m    668\u001b[0m )\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/workflow/utilities.py:388\u001b[0m, in \u001b[0;36moverride_pipeline_parameter_var.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         logger\u001b[39m.\u001b[39mwarning(warning_msg_template, arg_name, func_name, \u001b[39mtype\u001b[39m(value))\n\u001b[1;32m    387\u001b[0m         kwargs[arg_name] \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mdefault_value\n\u001b[0;32m--> 388\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/image_uris.py:185\u001b[0m, in \u001b[0;36mretrieve\u001b[0;34m(framework, region, version, py_version, instance_type, accelerator_type, image_scope, container_version, distribution, base_framework_version, training_compiler_config, model_id, model_version, tolerate_vulnerable_model, tolerate_deprecated_model, sdk_version, inference_tool, serverless_inference_config)\u001b[0m\n\u001b[1;32m    181\u001b[0m hostname \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39m_botocore_resolver()\u001b[39m.\u001b[39mconstruct_endpoint(\u001b[39m\"\u001b[39m\u001b[39mecr\u001b[39m\u001b[39m\"\u001b[39m, region)[\u001b[39m\"\u001b[39m\u001b[39mhostname\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m repo \u001b[39m=\u001b[39m version_config[\u001b[39m\"\u001b[39m\u001b[39mrepository\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 185\u001b[0m processor \u001b[39m=\u001b[39m _processor(\n\u001b[1;32m    186\u001b[0m     instance_type,\n\u001b[1;32m    187\u001b[0m     config\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mprocessors\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mor\u001b[39;49;00m version_config\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mprocessors\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    188\u001b[0m     serverless_inference_config,\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[39m# if container version is available in .json file, utilize that\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39mif\u001b[39;00m version_config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcontainer_version\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/image_uris.py:534\u001b[0m, in \u001b[0;36m_processor\u001b[0;34m(instance_type, available_processors, serverless_inference_config)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    530\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mInvalid SageMaker instance type: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. For options, see: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    531\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mhttps://aws.amazon.com/sagemaker/pricing/instance-types\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(instance_type)\n\u001b[1;32m    532\u001b[0m         )\n\u001b[0;32m--> 534\u001b[0m _validate_arg(processor, available_processors, \u001b[39m\"\u001b[39;49m\u001b[39mprocessor\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    535\u001b[0m \u001b[39mreturn\u001b[39;00m processor\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagemaker/image_uris.py:580\u001b[0m, in \u001b[0;36m_validate_arg\u001b[0;34m(arg, available_options, arg_name)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Checks if the arg is in the available options, and raises a ``ValueError`` if not.\"\"\"\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m arg \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m available_options:\n\u001b[0;32m--> 580\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    581\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnsupported \u001b[39m\u001b[39m{arg_name}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{arg}\u001b[39;00m\u001b[39m. You may need to upgrade your SDK version \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(pip install -U sagemaker) for newer \u001b[39m\u001b[39m{arg_name}\u001b[39;00m\u001b[39ms. Supported \u001b[39m\u001b[39m{arg_name}\u001b[39;00m\u001b[39m(s): \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m{options}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(arg_name\u001b[39m=\u001b[39marg_name, arg\u001b[39m=\u001b[39marg, options\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(available_options))\n\u001b[1;32m    584\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported processor: cpu. You may need to upgrade your SDK version (pip install -U sagemaker) for newer processors. Supported processor(s): gpu."
     ]
    }
   ],
   "source": [
    "from assisted_intelligence.ml.hf_sagemaker import HfSagemaker\n",
    "\n",
    "mlFacotry=HfSagemaker(\n",
    "    # è®¾å®š sagemaker è®­ç»ƒæœºå™¨\n",
    "    sagemaker_config={\n",
    "        # 'instance_type': 'ml.p3dn.24xlarge',\n",
    "        # 'instance_type': 'ml.p4d.24xlarge',\n",
    "        # 'instance_type': 'ml.p3.2xlarge',\n",
    "        'instance_type': 'ml.m5.4xlarge',\n",
    "        'instance_count': 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "mlFacotry.play(\n",
    "    config={\n",
    "        # è®­ç»ƒç±»å‹ï¼Œç›®å‰åªæœ‰ä¸¤ç§è®­ç»ƒç±»å‹ BERT LLAMA RLHF\n",
    "        'training_model': 'LLAMA',\n",
    "        'clone_repo': 'rjx/rjxai-lora-7b-v1',\n",
    "        'model_name_or_path':'rjx/rjxai-zh-llama-7b-v1',\n",
    "        'dataset_name': 'rjx/ai-and-human-20',\n",
    "        'task_type': 'text2text',\n",
    "        'use_auth_token': True,\n",
    "        # 'max_train_samples': 20,\n",
    "        # 'max_eval_samples': 2,\n",
    "        # 'max_test_samples': 2,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ Accelerator sagemaker è¿è¡Œ llama è„šæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "Configuring Amazon SageMaker environment\n",
      "Converting Arguments to Hyperparameters\n",
      "Creating Estimator\n",
      "Using provided s3_resource\n",
      "2023-05-24 02:46:30 Starting - Starting the training job...\n",
      "2023-05-24 02:46:35 Starting - Insufficient capacity error from EC2 while launching instances, retrying!..\n",
      "2023-05-24 02:47:33 Failed - Training job failed\n",
      "..\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2mâ”‚   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m8 \u001b[2mâ”‚   \u001b[0msys.exit(main())                                                     \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accel\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33merate/commands/\u001b[0m\u001b[1;33maccelerate_cli.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                  \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                    \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m45 \u001b[2mâ”‚   \u001b[0margs.func(args)                                                     \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accel\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33merate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m916\u001b[0m in \u001b[92mlaunch_command\u001b[0m                               \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m913 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94melse\u001b[0m:                                                          \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m914 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mtpu_launcher(args)                                         \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m915 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94melif\u001b[0m defaults \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m defaults.compute_environment == Comp \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m916 \u001b[2mâ”‚   â”‚   \u001b[0msagemaker_launcher(defaults, args)                             \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m917 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94melse\u001b[0m:                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m918 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0msimple_launcher(args)                                          \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m919 \u001b[0m                                                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accel\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33merate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m764\u001b[0m in \u001b[92msagemaker_launcher\u001b[0m                           \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m761 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                   \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m762 \u001b[0m\u001b[2mâ”‚   \u001b[0mhuggingface_estimator = HuggingFace(**args)                        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m763 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                   \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m764 \u001b[2mâ”‚   \u001b[0mhuggingface_estimator.fit(inputs=sagemaker_inputs)                 \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m765 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mYou can find your model data at: \u001b[0m\u001b[33m{\u001b[0mhuggingface_estimator.mo \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m766 \u001b[0m                                                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m767 \u001b[0m                                                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33maker/workflow/\u001b[0m\u001b[1;33mpipeline_context.py\u001b[0m:\u001b[94m284\u001b[0m in \u001b[92mwrapper\u001b[0m                             \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m                                                           \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m _StepArguments(retrieve_caller_name(self_instance), \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m                                                               \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m284 \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m run_func(*args, **kwargs)                               \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m285 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                   \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m286 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                     \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m287 \u001b[0m                                                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m1198\u001b[0m in \u001b[92mfit\u001b[0m                                                \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m.latest_training_job = _TrainingJob.start_new(\u001b[96mself\u001b[0m, input \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m.jobs.append(\u001b[96mself\u001b[0m.latest_training_job)                    \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m wait:                                                      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1198 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m.latest_training_job.wait(logs=logs)                  \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1199 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                  \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1200 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_compilation_job_name\u001b[0m(\u001b[96mself\u001b[0m):                                  \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1201 \u001b[0m\u001b[2;90mâ”‚   â”‚   \u001b[0m\u001b[33m\"\"\"Placeholder docstring\"\"\"\u001b[0m                                   \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33mestimator.py\u001b[0m:\u001b[94m2344\u001b[0m in \u001b[92mwait\u001b[0m                                               \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m2341 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mlogs = log_string_map[logs]                               \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m2342 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# If logs are requested, call logs_for_jobs.\u001b[0m                  \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m2343 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m logs != \u001b[33m\"\u001b[0m\u001b[33mNone\u001b[0m\u001b[33m\"\u001b[0m:                                            \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m2344 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.logs_for_job(\u001b[96mself\u001b[0m.job_name, wait=\u001b[94mT\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m2345 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94melse\u001b[0m:                                                         \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m2346 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m.sagemaker_session.wait_for_job(\u001b[96mself\u001b[0m.job_name)        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m2347 \u001b[0m                                                                      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m4628\u001b[0m in \u001b[92mlogs_for_job\u001b[0m                                         \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m4625 \u001b[0m\u001b[2;33mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33mexceptions.CapacityError: If the training job fails with \u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m4626 \u001b[0m\u001b[2;33mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33mexceptions.UnexpectedStatusException: If waiting and the \u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m4627 \u001b[0m\u001b[2;33mâ”‚   â”‚   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m4628 \u001b[2mâ”‚   â”‚   \u001b[0m_logs_for_job(\u001b[96mself\u001b[0m.boto_session, job_name, wait, poll, log_ty \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m4629 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                  \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m4630 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mlogs_for_processing_job\u001b[0m(\u001b[96mself\u001b[0m, job_name, wait=\u001b[94mFalse\u001b[0m, poll=\u001b[94m10\u001b[0m): \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m4631 \u001b[0m\u001b[2;90mâ”‚   â”‚   \u001b[0m\u001b[33m\"\"\"Display logs for a given processing job, optionally tailin\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m6490\u001b[0m in \u001b[92m_logs_for_job\u001b[0m                                        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6487 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mlast_profiler_rule_statuses = profiler_rule_statuses  \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6488 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                  \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6489 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mif\u001b[0m wait:                                                          \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m6490 \u001b[2mâ”‚   â”‚   \u001b[0m_check_job_status(job_name, description, \u001b[33m\"\u001b[0m\u001b[33mTrainingJobStatus\u001b[0m\u001b[33m\"\u001b[0m) \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6491 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m dot:                                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6492 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[96mprint\u001b[0m()                                                   \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6493 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# Customers are not billed for hardware provisioning, so bill\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/sagem\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33maker/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m6538\u001b[0m in \u001b[92m_check_job_status\u001b[0m                                    \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6535 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mjob_type=job_type, job_name=job, status=status, reason=re \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6536 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m)                                                             \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6537 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mCapacityError\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m \u001b[96mstr\u001b[0m(reason):                            \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m6538 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mraise\u001b[0m exceptions.CapacityError(                           \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6539 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mmessage=message,                                      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6540 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],            \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m6541 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mactual_status=status,                                 \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
      "\u001b[1;91mCapacityError: \u001b[0mError for Training job \n",
      "rjxai-llama-tc-accelerate-sagemaker-\u001b[1;36m1\u001b[0m-\u001b[1;36m2023\u001b[0m-\u001b[1;92m05-24-02-45-02-81\u001b[0m6: Failed. Reason: \n",
      "CapacityError: Unable to provision requested ML compute capacity. Please retry \n",
      "using a different ML instance type.\n"
     ]
    }
   ],
   "source": [
    "# us-west-2\n",
    "# instructions tuning\n",
    "!accelerate launch --config_file assisted_intelligence/config/accelerator/sagemaker_train.yaml auto_train.py \\\n",
    "    --training_model LLAMA \\\n",
    "    --clone_repo rjx/rjxai-lora-7b-v1 \\\n",
    "    --model_name_or_path rjx/rjxai-zh-llama-7b-v1 \\\n",
    "    --dataset_name rjx/ai-and-human-0516 \\\n",
    "    --task_type text2text \\\n",
    "    --use_auth_token True \\\n",
    "    --max_train_samples 40 \\\n",
    "    --max_eval_samples 4 \\\n",
    "    --max_test_samples 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ Accelerator local è¿è¡Œ llama è„šæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "\u001b[2;36m[10:59:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m The following values were not passed to        \u001b]8;id=435763;file:///Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accelerate/commands/launch.py\u001b\\\u001b[2mlaunch.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=320834;file:///Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accelerate/commands/launch.py#890\u001b\\\u001b[2m890\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         `accelerate launch` and had defaults used      \u001b[2m             \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         instead:                                       \u001b[2m             \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m                 `--num_cpu_threads_per_process` was    \u001b[2m             \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         set to `\u001b[1;36m4\u001b[0m` to improve out-of-box performance   \u001b[2m             \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         when training on CPUs                          \u001b[2m             \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         To avoid this warning pass in values for each  \u001b[2m             \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         of the problematic parameters or run           \u001b[2m             \u001b[0m\n",
      "\u001b[2;36m           \u001b[0m         `accelerate config`.                           \u001b[2m             \u001b[0m\n",
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfengx\u001b[0m (\u001b[33mfeng-x\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/ofengx/Desktop/ai/assisted_intelligence/wandb/run-20230531_105951-tqvnp6et\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msage-pine-140\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/feng-x/uncategorized\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/feng-x/uncategorized/runs/tqvnp6et\u001b[0m\n",
      "2023-05-31 10:59:53,006,006 INFO     4705142272 MainThread 83341 [auto_train.py:26] ************ è¯»å–ç¯å¢ƒå˜é‡ *****************\n",
      "2023-05-31 10:59:53,007,007 INFO     4705142272 MainThread 83341 [auto_train.py:27] environ({'PATH': '/Users/ofengx/.asdf/plugins/python/shims:/Users/ofengx/.asdf/installs/python/3.8.13/bin:/Users/ofengx/.asdf/shims:/Users/ofengx/.local/bin:/usr/local/Cellar/john-jumbo/1.9.0_1/share/john:/Users/ofengx/.asdf/shims:/usr/local/opt/asdf/libexec/bin:/Users/ofengx/Desktop/Data/fx-pro/flutter/flutter/bin:/Users/ofengx/.yarn/bin:/Users/ofengx/.config/yarn/global/node_modules/.bin:/usr/local/bin:/usr/local/sbin:/usr/local/Cellar/gradle/4.7/bin:/usr/local/opt/coreutils/libexec/gnubin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Apple/usr/bin:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/Users/ofengx/.cargo/bin::/usr/local/opt/go/libexec/bin:/Users/ofengx/golang/bin:/Users/ofengx/Library/Android/sdk/tools:/Users/ofengx/Library/Android/sdk/platform-tools:/usr/local/Cellar/john-jumbo/1.9.0_1/share/john:/Users/ofengx/.asdf/shims:/usr/local/opt/asdf/libexec/bin:/Users/ofengx/Desktop/Data/fx-pro/flutter/flutter/bin:/Users/ofengx/.yarn/bin:/Users/ofengx/.config/yarn/global/node_modules/.bin:/usr/local/bin:/usr/local/sbin:/usr/local/Cellar/gradle/4.7/bin:/usr/local/opt/coreutils/libexec/gnubin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Apple/usr/bin:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/Users/ofengx/.cargo/bin::/usr/local/opt/go/libexec/bin:/Users/ofengx/golang/bin:/Users/ofengx/Library/Android/sdk/tools:/Users/ofengx/Library/Android/sdk/platform-tools', 'VSCODE_CRASH_REPORTER_PROCESS_TYPE': 'extensionHost', 'ANDROID_HOME': '/Users/ofengx/Library/Android/sdk', 'ASDF_DIR': '/usr/local/opt/asdf/libexec', 'SHELL': '/bin/zsh', 'VSCODE_CRASH_REPORTER_SANDBOXED_HINT': '1', 'TMPDIR': '/var/folders/v7/9xn8x9997m3c8z9g65r32l400000gn/T/', 'PROVIDE_FULLSTACK_ACTION': 'true', 'GRADLE_HOME': '/usr/local/Cellar/gradle/4.7', 'PYTHONUNBUFFERED': '1', 'MallocNanoZone': '0', 'ORIGINAL_XDG_CURRENT_DESKTOP': 'undefined', 'USER': 'ofengx', 'PYTHONIOENCODING': 'utf-8', 'COMMAND_MODE': 'unix2003', 'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.BAjsVDFtIW/Listeners', 'PUB_HOSTED_URL': 'https://pub.flutter-io.cn', '__CF_USER_TEXT_ENCODING': '0x1F5:0x19:0x34', 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'ELECTRON_RUN_AS_NODE': '1', 'LaunchInstanceID': 'A7502919-FDCF-4912-A1BC-E3081BCF4550', 'TELEMETRY_ID': 'd16b0dfd-d54e-4b77-b93e-70c5787b628d', '__CFBundleIdentifier': 'com.microsoft.VSCode', 'PWD': '/Users/ofengx/Desktop/ai/assisted_intelligence', 'THREE_SCALE_USER_TOKEN': '207c527cfc2a6b8dcf4fa43ad7a976da', 'UUID': '8faffdad-ddb8-4039-b779-73844fedd079', 'FLUTTER_STORAGE_BASE_URL': 'https://storage.flutter-io.cn', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'XPC_FLAGS': '0x0', 'XPC_SERVICE_NAME': '0', 'HOME': '/Users/ofengx', 'SHLVL': '0', 'GOLANG_EXECUTABLE': 'go', 'GOROOT': '/usr/local/opt/go/libexec', 'APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL': 'true', 'VSCODE_NLS_CONFIG': '{\"locale\":\"zh-cn\",\"osLocale\":\"zh-cn\",\"availableLanguages\":{\"*\":\"zh-cn\"},\"_languagePackId\":\"07d862891cffead1799ff1d0d31a0385.zh-cn\",\"_translationsConfigFile\":\"/Users/ofengx/Library/Application Support/Code/clp/07d862891cffead1799ff1d0d31a0385.zh-cn/tcf.json\",\"_cacheRoot\":\"/Users/ofengx/Library/Application Support/Code/clp/07d862891cffead1799ff1d0d31a0385.zh-cn\",\"_resolvedLanguagePackCoreLocation\":\"/Users/ofengx/Library/Application Support/Code/clp/07d862891cffead1799ff1d0d31a0385.zh-cn/b3e4e68a0bc097f0ae7907b217c1119af9e03435\",\"_corruptedFile\":\"/Users/ofengx/Library/Application Support/Code/clp/07d862891cffead1799ff1d0d31a0385.zh-cn/corrupted.info\",\"_languagePackSupport\":true}', 'RECOMMENDER_API_URL': 'https://gw.api.openshift.io//api/v2', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'LOGNAME': 'ofengx', 'GROOVY_HOME': '/usr/local/Cellar/groovysdk/2.4.12/libexec', 'UTM_SOURCE': 'vscode', 'VSCODE_CODE_CACHE_PATH': '/Users/ofengx/Library/Application Support/Code/CachedData/b3e4e68a0bc097f0ae7907b217c1119af9e03435', 'VSCODE_IPC_HOOK': '/Users/ofengx/Library/Application Support/Code/1.78-main.sock', 'GOPATH': '/Users/ofengx/golang', 'VSCODE_PID': '547', 'SECURITYSESSIONID': '186a3', 'VSCODE_CWD': '/', 'VSCODE_L10N_BUNDLE_LOCATION': 'file:///Users/ofengx/.vscode/extensions/ms-ceintl.vscode-language-pack-zh-hans-1.78.2023051009/translations/extensions/vscode.json-language-features.i18n.json', 'LC_CTYPE': 'UTF-8', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'OLDPWD': '/Users/ofengx/Desktop/ai/assisted_intelligence', '_': '/Users/ofengx/.asdf/installs/python/3.8.13/bin/accelerate', 'ACCELERATE_USE_CPU': 'True', 'ACCELERATE_MIXED_PRECISION': 'no', 'ACCELERATE_DYNAMO_BACKEND': 'NO', 'ACCELERATE_DYNAMO_MODE': 'default', 'ACCELERATE_DYNAMO_USE_FULLGRAPH': 'False', 'ACCELERATE_DYNAMO_USE_DYNAMIC': 'False', 'OMP_NUM_THREADS': '4', 'WANDB_API_KEY': '93523e57b94611e1a558a6541f834f17dd400be5', 'WANDB_SERVICE': '2-83341-tcp-localhost-58202'})\n",
      "2023-05-31 10:59:53,008,008 INFO     4705142272 MainThread 83341 [auto_train.py:33] ************ è½½å…¥RLHFå‚æ•° *****************\n",
      "2023-05-31 10:59:53,024,024 INFO     4705142272 MainThread 83341 [auto_train.py:51] ModelArguments(model_name_or_path='lvwerra/gpt2-imdb', model_type='BERT', config_overrides=None, config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True, model_revision='main', use_auth_token=True, torch_dtype=None, low_cpu_mem_usage=False, hf_hub_token='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', write_hf_hub_token='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', task_type=None)\n",
      "2023-05-31 10:59:53,024,024 INFO     4705142272 MainThread 83341 [auto_train.py:52] DataTrainingArguments(dataset_name='rjx/ai-and-human-20', dataset_config_name=None, train_file=None, validation_file=None, max_train_samples=40, max_eval_samples=None, max_test_samples=None, streaming=False, block_size=None, overwrite_cache=False, validation_split_percentage=5, keep_linebreaks=True, index_input='text', index_output='labels')\n",
      "2023-05-31 10:59:53,024,024 INFO     4705142272 MainThread 83341 [auto_train.py:53] RlhfTrainingArguments(\n",
      "_n_gpu=-1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "batch_size=32,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "clone_repo=rjx/trl-rlhf-test-v1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=,\n",
      "deepspeed=None,\n",
      "disable_tqdm=None,\n",
      "do_accelerator=False,\n",
      "do_eval=False,\n",
      "do_load_dataset=True,\n",
      "do_peft=False,\n",
      "do_predict=True,\n",
      "do_save=True,\n",
      "do_train=True,\n",
      "do_visualization=False,\n",
      "early_stopping=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=,\n",
      "fsdp_config=None,\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=rjx/trl-rlhf-test-v1,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1.41e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=rjx/trl-rlhf-test-v1/logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mini_batch_size=1,\n",
      "mixed_precision=None,\n",
      "model_max_length=512,\n",
      "mp_parameters=,\n",
      "no_cuda=True,\n",
      "num_train_epochs=3.0,\n",
      "optim=adafactor,\n",
      "optim_args=None,\n",
      "output_dir=ml/model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "resume_from_checkpoint=None,\n",
      "reward_baseline=0.0,\n",
      "reward_model_name=,\n",
      "run_name=None,\n",
      "save_freq=None,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=,\n",
      "skip_memory_metrics=True,\n",
      "target_kl=0.1,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "training_model=RLHF,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "2023-05-31 10:59:53,025,025 INFO     4705142272 MainThread 83341 [auto_train.py:55] ************ é…ç½® logging *************\n",
      "2023-05-31 10:59:53,029,029 WARNING  4705142272 MainThread 83341 [auto_train.py:74] Process rank: -1, device: cpu, n_gpu: 0, distributed training: True, 16-bits training: False\n",
      "2023-05-31 10:59:53,030,030 INFO     4705142272 MainThread 83341 [auto_train.py:78] Training/evaluation parameters RlhfTrainingArguments(\n",
      "_n_gpu=0,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "batch_size=32,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "clone_repo=rjx/trl-rlhf-test-v1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=,\n",
      "deepspeed=None,\n",
      "disable_tqdm=None,\n",
      "do_accelerator=False,\n",
      "do_eval=False,\n",
      "do_load_dataset=True,\n",
      "do_peft=False,\n",
      "do_predict=True,\n",
      "do_save=True,\n",
      "do_train=True,\n",
      "do_visualization=False,\n",
      "early_stopping=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=,\n",
      "fsdp_config=None,\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=rjx/trl-rlhf-test-v1,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1.41e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=rjx/trl-rlhf-test-v1/logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mini_batch_size=1,\n",
      "mixed_precision=None,\n",
      "model_max_length=512,\n",
      "mp_parameters=,\n",
      "no_cuda=True,\n",
      "num_train_epochs=3.0,\n",
      "optim=adafactor,\n",
      "optim_args=None,\n",
      "output_dir=ml/model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "resume_from_checkpoint=None,\n",
      "reward_baseline=0.0,\n",
      "reward_model_name=,\n",
      "run_name=None,\n",
      "save_freq=None,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=,\n",
      "skip_memory_metrics=True,\n",
      "target_kl=0.1,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "training_model=RLHF,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "2023-05-31 10:59:53,030,030 INFO     4705142272 MainThread 83341 [auto_train.py:80] ************ é‡‡ç”¨RLHFè®­ç»ƒç±»å‹ ***********\n",
      "2023-05-31 10:59:54,770,770 INFO     4705142272 MainThread 83341 [trl_train_rlhf_factory.py:43] æ„å»ºppoconfig\n",
      "2023-05-31 10:59:54,770,770 INFO     4705142272 MainThread 83341 [trl_train_rlhf_factory.py:58] *********** æ„å»ºtokenizer\n",
      "2023-05-31 10:59:55,742,742 INFO     4705142272 MainThread 83341 [trl_train_rlhf_factory.py:74] ********** åŠ è½½æ•°æ®é›†\n",
      "2023-05-31 10:59:55,743,743 INFO     4705142272 MainThread 83341 [trl_train_rlhf_factory.py:92] *********** åŠ è½½æ¨¡å‹\n",
      "2023-05-31 11:00:00,158,158 INFO     4705142272 MainThread 83341 [trl_train_rlhf_factory.py:97] *********** åŠ è½½å‚è€ƒæ¨¡å‹\n",
      "2023-05-31 11:00:04,382,382 INFO     4705142272 MainThread 83341 [build_dataset.py:427] GPT2TokenizerFast(name_or_path='lvwerra/gpt2-imdb', vocab_size=50257, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)\n",
      "Found cached dataset imdb (/Users/ofengx/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "2023-05-31 11:00:08,049,049 INFO     4705142272 MainThread 83341 [build_dataset.py:437] åŠ è½½æ•°æ®é›†ï¼šDataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 25000\n",
      "})\n",
      "2023-05-31 11:00:08,055,055 INFO     4705142272 MainThread 83341 [build_dataset.py:443] input_size: 5\n",
      "Map:   0%|                                        | 0/40 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
      "2023-05-31 11:00:08,270,270 INFO     4705142272 MainThread 83341 [build_dataset.py:453] Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'query'],\n",
      "    num_rows: 40\n",
      "})\n",
      "2023-05-31 11:00:08,274,274 INFO     4705142272 MainThread 83341 [build_dataset.py:454] {'text': ['I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'], 'label': tensor([0]), 'input_ids': tensor([[   40, 26399,   314,  3001,   327]]), 'query': ['I rented I AM C']}\n",
      "2023-05-31 11:00:08,275,275 INFO     4705142272 MainThread 83341 [build_model.py:185] åŠ è½½ppotrainer\n",
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "2023-05-31 11:00:10,131,131 INFO     4705142272 MainThread 83341 [build_model.py:213] output_length_sampler: 10\n",
      "1it [00:00, 205.59it/s]\n",
      "/Users/ofengx/Desktop/ai/transformers/src/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "2023-05-31 11:03:28,568,568 INFO     4705142272 MainThread 83341 [build_model.py:258] å¼€å§‹inspection\n",
      "/Users/ofengx/Desktop/ai/transformers/src/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "2023-05-31 11:03:48,205,205 INFO     4705142272 MainThread 83341 [build_model.py:294]                                  query  ... rewards (after)\n",
      "0                          :Spoilers:<  ...       -1.207318\n",
      "1                       My interest in  ...        0.955613\n",
      "2                       Oh, brother...  ...       -1.942284\n",
      "3                         This is said  ...        0.313417\n",
      "4                      Some films that  ...        0.626199\n",
      "5                       1st watched 8/  ...        0.294833\n",
      "6          It was great to see some of  ...        2.240398\n",
      "7                  I would put this at  ...       -0.256905\n",
      "8                              I think  ...        2.843237\n",
      "9   Never cast models and Playboy bunn  ...       -0.819408\n",
      "10   My girlfriend once brought around  ...       -1.514959\n",
      "11        There's tons of good-looking  ...       -0.388650\n",
      "12               I received this movie  ...        0.726939\n",
      "13                     I rented I AM C  ...       -0.307707\n",
      "14       I very much looked forward to  ...        2.086168\n",
      "15                       Really, I can  ...        0.738259\n",
      "\n",
      "[16 rows x 5 columns]\n",
      "2023-05-31 11:03:48,226,226 INFO     4705142272 MainThread 83341 [build_model.py:296] mean:\n",
      "2023-05-31 11:03:48,228,228 INFO     4705142272 MainThread 83341 [build_model.py:297] rewards (before)   -0.083097\n",
      "rewards (after)     0.274239\n",
      "dtype: float64\n",
      "2023-05-31 11:03:48,229,229 INFO     4705142272 MainThread 83341 [build_model.py:298] median:\n",
      "2023-05-31 11:03:48,232,232 INFO     4705142272 MainThread 83341 [build_model.py:299] rewards (before)   -0.724723\n",
      "rewards (after)     0.304125\n",
      "dtype: float64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             env/reward_mean â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              env/reward_std â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           objective/entropy â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                objective/kl â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           objective/kl_coef â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           ppo/learning_rate â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             ppo/loss/policy â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              ppo/loss/total â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              ppo/loss/value â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ppo/mean_non_score_reward â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             ppo/mean_scores â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  ppo/policy/advantages_mean â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         ppo/policy/approxkl â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         ppo/policy/clipfrac â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          ppo/policy/entropy â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         ppo/policy/policykl â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            ppo/returns/mean â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             ppo/returns/var â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              ppo/std_scores â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ppo/time/ppo/optimizer_step â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            ppo/val/clipfrac â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ppo/val/error â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                ppo/val/mean â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 ppo/val/var â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       ppo/val/var_explained â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ppo/val/vpred â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         time/ppo/calc_stats â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    time/ppo/compute_rewards â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       time/ppo/forward_pass â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      time/ppo/optimize_step â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              time/ppo/total â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     tokens/queries_len_mean â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      tokens/queries_len_std â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   tokens/responses_len_mean â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    tokens/responses_len_std â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             env/reward_mean -0.07791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              env/reward_std 1.50074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           objective/entropy 34.25154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                objective/kl 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           objective/kl_coef 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           ppo/learning_rate 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             ppo/loss/policy -0.09374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              ppo/loss/total 0.47191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              ppo/loss/value 5.65657\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ppo/mean_non_score_reward 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             ppo/mean_scores -0.07791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  ppo/policy/advantages_mean 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         ppo/policy/approxkl 0.54126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         ppo/policy/clipfrac 0.53619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          ppo/policy/entropy 3.71251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         ppo/policy/policykl 0.10356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            ppo/returns/mean 0.40555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             ppo/returns/var 0.167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              ppo/std_scores 1.50074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ppo/time/ppo/optimizer_step 0.55102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            ppo/val/clipfrac 0.74093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ppo/val/error 5.32057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                ppo/val/mean 2.49742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 ppo/val/var 5.28541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       ppo/val/var_explained -30.86012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ppo/val/vpred 1.52851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         time/ppo/calc_stats 0.02298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    time/ppo/compute_rewards 0.00653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       time/ppo/forward_pass 10.17977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      time/ppo/optimize_step 167.29755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              time/ppo/total 177.51982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     tokens/queries_len_mean 4.6875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      tokens/queries_len_std 1.6932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   tokens/responses_len_mean 9.9375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    tokens/responses_len_std 3.43546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33msage-pine-140\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/feng-x/uncategorized/runs/tqvnp6et\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230531_105951-tqvnp6et/logs\u001b[0m\n",
      "2023-05-31 11:03:56,530,530 INFO     4705142272 MainThread 83341 [util.py:54] process shutting down\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file assisted_intelligence/config/accelerator/local_train.yaml auto_train.py \\\n",
    "    --training_model RLHF \\\n",
    "    --clone_repo rjx/trl-rlhf-test-v1 \\\n",
    "    --model_name_or_path lvwerra/gpt2-imdb \\\n",
    "    --dataset_name rjx/ai-and-human-20 \\\n",
    "    --use_auth_token True \\\n",
    "    --max_train_samples 40"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æµ‹è¯• accelerate å¯¹åº”çš„é…ç½®æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "\n",
      "Running:  accelerate-launch --config_file=fengx_ai/config/accelerator/local_train.yaml /Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accelerate/test_utils/scripts/test_script.py\n",
      "stderr: NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "stdout: \u001b[2;36m[15:26:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m The following values were not passed to        \u001b]8;id=560056;file:///Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accelerate/commands/launch.py\u001b\\\u001b[2mlaunch.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=359665;file:///Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/accelerate/commands/launch.py#890\u001b\\\u001b[2m890\u001b[0m\u001b]8;;\u001b\\\n",
      "stdout: \u001b[2;36m           \u001b[0m         `accelerate launch` and had defaults used      \u001b[2m             \u001b[0m\n",
      "stdout: \u001b[2;36m           \u001b[0m         instead:                                       \u001b[2m             \u001b[0m\n",
      "stdout: \u001b[2;36m           \u001b[0m                 `--num_cpu_threads_per_process` was    \u001b[2m             \u001b[0m\n",
      "stdout: \u001b[2;36m           \u001b[0m         set to `\u001b[1;36m4\u001b[0m` to improve out-of-box performance   \u001b[2m             \u001b[0m\n",
      "stdout: \u001b[2;36m           \u001b[0m         when training on CPUs                          \u001b[2m             \u001b[0m\n",
      "stdout: \u001b[2;36m           \u001b[0m         To avoid this warning pass in values for each  \u001b[2m             \u001b[0m\n",
      "stdout: \u001b[2;36m           \u001b[0m         of the problematic parameters or run           \u001b[2m             \u001b[0m\n",
      "stdout: \u001b[2;36m           \u001b[0m         `accelerate config`.                           \u001b[2m             \u001b[0m\n",
      "stderr: NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "stdout: **Initialization**\n",
      "stdout: Testing, testing. 1, 2, 3.\n",
      "stdout: Distributed environment: NO\n",
      "stdout: Num processes: 1\n",
      "stdout: Process index: 0\n",
      "stdout: Local process index: 0\n",
      "stdout: Device: cpu\n",
      "stdout: \n",
      "stdout: Mixed precision type: no\n",
      "stdout: \n",
      "stdout: \n",
      "stdout: **Test process execution**\n",
      "stdout: \n",
      "stdout: **Test random number generator synchronization**\n",
      "stdout: All rng are properly synched.\n",
      "stdout: \n",
      "stdout: **DataLoader integration test**\n",
      "stdout: 0 tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]) <class 'accelerate.data_loader.DataLoaderShard'>\n",
      "stdout: Non-shuffled dataloader passing.\n",
      "stdout: Shuffled dataloader passing.\n",
      "stdout: Non-shuffled central dataloader passing.\n",
      "stdout: Shuffled central dataloader passing.\n",
      "stdout: \n",
      "stdout: **Training integration test**\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Training yielded the same results on one CPU or distributed setup with no batch split.\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Training yielded the same results on one CPU or distributes setup with batch split.\n",
      "stdout: BF16 training check.\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "Test is a success! You are ready for your distributed training!\n"
     ]
    }
   ],
   "source": [
    "!accelerate test --config_file assisted_intelligence/config/accelerator/local_train.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
