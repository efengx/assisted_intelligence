{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfengx\u001b[0m (\u001b[33mfeng-x\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/ofengx/Desktop/ai/fengx_ai/wandb/run-20230522_122616-w6gfx7ov\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfrosty-firebrand-86\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/feng-x/uncategorized\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/feng-x/uncategorized/runs/w6gfx7ov\u001b[0m\n",
      "2023-05-22 12:26:17,691,691 INFO     4644369920 MainThread 35570 [auto_train.py:35] ************ è½½å…¥BERTå‚æ•° *****************\n",
      "2023-05-22 12:26:17,700,700 INFO     4644369920 MainThread 35570 [auto_train.py:53] ModelArguments(model_name_or_path='xlm-roberta-base', model_type='BERT', config_overrides=None, config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True, model_revision='main', use_auth_token=False, torch_dtype=None, low_cpu_mem_usage=False, hf_hub_token='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', write_hf_hub_token='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', task_type='text-generation')\n",
      "2023-05-22 12:26:17,700,700 INFO     4644369920 MainThread 35570 [auto_train.py:54] DataTrainingArguments(dataset_name='rjx/ai-and-human', dataset_config_name=None, train_file=None, validation_file=None, max_train_samples=20, max_eval_samples=4, max_test_samples=4, streaming=False, block_size=None, overwrite_cache=False, validation_split_percentage=5, keep_linebreaks=True, index_input='sentence1', index_output='target')\n",
      "2023-05-22 12:26:17,701,701 INFO     4644369920 MainThread 35570 [auto_train.py:55] FxTrainingArguments(\n",
      "_n_gpu=-1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "clone_repo=rjx/rjxai-xlm-roberta-test,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=,\n",
      "deepspeed=None,\n",
      "disable_tqdm=None,\n",
      "do_accelerator=False,\n",
      "do_eval=False,\n",
      "do_load_dataset=True,\n",
      "do_peft=False,\n",
      "do_predict=True,\n",
      "do_save=True,\n",
      "do_train=True,\n",
      "do_visualization=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=,\n",
      "fsdp_config=None,\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=rjx/rjxai-xlm-roberta-test,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=rjx/rjxai-xlm-roberta-test/logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=50,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=accuracy,\n",
      "metric_type=accuracy,\n",
      "model_max_length=512,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/opt/ml/model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=None,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=100,\n",
      "save_strategy=steps,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "sharded_ddp=,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "training_model=BERT,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "2023-05-22 12:26:17,701,701 INFO     4644369920 MainThread 35570 [auto_train.py:57] ************ é…ç½® logging *************\n",
      "2023-05-22 12:26:17,726,726 WARNING  4644369920 MainThread 35570 [auto_train.py:76] Process rank: -1, device: cpu, n_gpu: 0, distributed training: True, 16-bits training: False\n",
      "2023-05-22 12:26:17,726,726 INFO     4644369920 MainThread 35570 [auto_train.py:80] Training/evaluation parameters FxTrainingArguments(\n",
      "_n_gpu=0,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "clone_repo=rjx/rjxai-xlm-roberta-test,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=,\n",
      "deepspeed=None,\n",
      "disable_tqdm=None,\n",
      "do_accelerator=False,\n",
      "do_eval=False,\n",
      "do_load_dataset=True,\n",
      "do_peft=False,\n",
      "do_predict=True,\n",
      "do_save=True,\n",
      "do_train=True,\n",
      "do_visualization=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=,\n",
      "fsdp_config=None,\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=rjx/rjxai-xlm-roberta-test,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=rjx/rjxai-xlm-roberta-test/logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=50,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=accuracy,\n",
      "metric_type=accuracy,\n",
      "model_max_length=512,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/opt/ml/model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=None,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=100,\n",
      "save_strategy=steps,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "sharded_ddp=,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "training_model=BERT,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "2023-05-22 12:26:17,727,727 INFO     4644369920 MainThread 35570 [auto_train.py:82] ************ é‡‡ç”¨BERTè®­ç»ƒç±»å‹ ***********\n",
      "2023-05-22 12:26:17,727,727 INFO     4644369920 MainThread 35570 [single_task_train_factory.py:52] ***************** è½½å…¥æ¨¡å‹: åˆ†è¯å™¨; æ¨¡å‹ *****************\n",
      "2023-05-22 12:26:17,727,727 INFO     4644369920 MainThread 35570 [print_utils.py:34] CPU ä¸ªæ•°: 8\n",
      "2023-05-22 12:26:17,727,727 INFO     4644369920 MainThread 35570 [print_utils.py:35] CPU memory total: 16.0 GB.\n",
      "2023-05-22 12:26:17,728,728 INFO     4644369920 MainThread 35570 [print_utils.py:36] CPU memory use: 7.912925720214844 GB.\n",
      "2023-05-22 12:26:17,728,728 INFO     4644369920 MainThread 35570 [print_utils.py:37] CPU memory free: 0.01885986328125 GB.\n",
      "2023-05-22 12:26:17,728,728 INFO     4644369920 MainThread 35570 [print_utils.py:38] CPU memory use percent: 65.4 %\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/pynvml.py\", line 1813, in _LoadNvmlLibrary\n",
      "    nvmlLib = CDLL(\"libnvidia-ml.so.1\")\n",
      "  File \"/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/ctypes/__init__.py\", line 373, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen(libnvidia-ml.so.1, 0x0006): tried: '/Users/ofengx/.asdf/installs/python/3.8.13/lib/libnvidia-ml.so.1' (no such file), '/Users/ofengx/.asdf/installs/python/3.8.13/lib/libnvidia-ml.so.1' (no such file), '/Users/ofengx/.asdf/installs/python/3.8.13/lib/libnvidia-ml.so.1' (no such file), '/Users/ofengx/.asdf/installs/python/3.8.13/lib/libnvidia-ml.so.1' (no such file), '/Users/ofengx/.asdf/installs/python/3.8.13/lib/libnvidia-ml.so.1' (no such file), 'libnvidia-ml.so.1' (no such file), '/usr/local/lib/libnvidia-ml.so.1' (no such file), '/usr/lib/libnvidia-ml.so.1' (no such file), '/Users/ofengx/Desktop/ai/fengx_ai/libnvidia-ml.so.1' (no such file)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"auto_train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"auto_train.py\", line 84, in main\n",
      "    single_task_train(\n",
      "  File \"/Users/ofengx/Desktop/ai/fengx_ai/fengx_ai/train/single_task_train_factory.py\", line 53, in single_task_train\n",
      "    print_source()\n",
      "  File \"/Users/ofengx/Desktop/ai/fengx_ai/fengx_ai/utils/print_utils.py\", line 42, in print_source\n",
      "    print_gpu_utilization()\n",
      "  File \"/Users/ofengx/Desktop/ai/fengx_ai/fengx_ai/utils/print_utils.py\", line 16, in print_gpu_utilization\n",
      "    nvmlInit()\n",
      "  File \"/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/pynvml.py\", line 1785, in nvmlInit\n",
      "    nvmlInitWithFlags(0)\n",
      "  File \"/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/pynvml.py\", line 1768, in nvmlInitWithFlags\n",
      "    _LoadNvmlLibrary()\n",
      "  File \"/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/pynvml.py\", line 1815, in _LoadNvmlLibrary\n",
      "    _nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)\n",
      "  File \"/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/pynvml.py\", line 848, in _nvmlCheckReturn\n",
      "    raise NVMLError(ret)\n",
      "pynvml.NVMLError_LibraryNotFound: NVML Shared Library Not Found\n",
      "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/\u001b[0m\u001b[1;33mpynvm\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[1;33ml.py\u001b[0m:\u001b[94m1813\u001b[0m in \u001b[92m_LoadNvmlLibrary\u001b[0m                                                \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1810 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0mnvmlLib = CDLL(os.path.join(os.getenv(\u001b[33m\"\u001b[0m\u001b[33mPr\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1811 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94melse\u001b[0m:                                             \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1812 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[2m# assume linux\u001b[0m                                \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1813 \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0mnvmlLib = CDLL(\u001b[33m\"\u001b[0m\u001b[33mlibnvidia-ml.so.1\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1814 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mOSError\u001b[0m \u001b[94mas\u001b[0m ose:                                \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1815 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m_nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)    \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1816 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m (nvmlLib == \u001b[94mNone\u001b[0m):                                 \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/ctypes/\u001b[0m\u001b[1;33m__init__.py\u001b[0m: \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[94m373\u001b[0m in \u001b[92m__init__\u001b[0m                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m370 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m._FuncPtr = _FuncPtr                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m371 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m                                                               \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m handle \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                             \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m373 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m._handle = _dlopen(\u001b[96mself\u001b[0m._name, mode)                   \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m374 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94melse\u001b[0m:                                                          \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m375 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m._handle = handle                                      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m376 \u001b[0m                                                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
      "\u001b[1;91mOSError: \u001b[0m\u001b[1;35mdlopen\u001b[0m\u001b[1m(\u001b[0mlibnvidia-ml.so.\u001b[1;36m1\u001b[0m, \u001b[1;36m0x0006\u001b[0m\u001b[1m)\u001b[0m: tried: \n",
      "\u001b[32m'/Users/ofengx/.asdf/installs/python/3.8.13/lib/libnvidia-ml.so.1'\u001b[0m \u001b[1m(\u001b[0mno such \n",
      "file\u001b[1m)\u001b[0m, \u001b[32m'/Users/ofengx/.asdf/installs/python/3.8.13/lib/libnvidia-ml.so.1'\u001b[0m \u001b[1m(\u001b[0mno \n",
      "such file\u001b[1m)\u001b[0m, \u001b[32m'/Users/ofengx/.asdf/installs/python/3.8.13/lib/libnvidia-ml.so.1'\u001b[0m \n",
      "\u001b[1m(\u001b[0mno such file\u001b[1m)\u001b[0m, \n",
      "\u001b[32m'/Users/ofengx/.asdf/installs/python/3.8.13/lib/libnvidia-ml.so.1'\u001b[0m \u001b[1m(\u001b[0mno such \n",
      "file\u001b[1m)\u001b[0m, \u001b[32m'/Users/ofengx/.asdf/installs/python/3.8.13/lib/libnvidia-ml.so.1'\u001b[0m \u001b[1m(\u001b[0mno \n",
      "such file\u001b[1m)\u001b[0m, \u001b[32m'libnvidia-ml.so.1'\u001b[0m \u001b[1m(\u001b[0mno such file\u001b[1m)\u001b[0m, \n",
      "\u001b[32m'/usr/local/lib/libnvidia-ml.so.1'\u001b[0m \u001b[1m(\u001b[0mno such file\u001b[1m)\u001b[0m, \u001b[32m'/usr/lib/libnvidia-ml.so.1'\u001b[0m \n",
      "\u001b[1m(\u001b[0mno such file\u001b[1m)\u001b[0m, \u001b[32m'/Users/ofengx/Desktop/ai/fengx_ai/libnvidia-ml.so.1'\u001b[0m \u001b[1m(\u001b[0mno such \n",
      "file\u001b[1m)\u001b[0m\n",
      "\n",
      "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/Desktop/ai/fengx_ai/\u001b[0m\u001b[1;33mauto_train.py\u001b[0m:\u001b[94m104\u001b[0m in \u001b[92m<module>\u001b[0m              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m101 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m)                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m102 \u001b[0m                                                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m103 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                             \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m104 \u001b[2mâ”‚   \u001b[0mmain()                                                             \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m105 \u001b[0m                                                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/Desktop/ai/fengx_ai/\u001b[0m\u001b[1;33mauto_train.py\u001b[0m:\u001b[94m84\u001b[0m in \u001b[92mmain\u001b[0m                   \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                   \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 82 \u001b[0m\u001b[2mâ”‚   \u001b[0mlogger.info(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m************ é‡‡ç”¨\u001b[0m\u001b[33m{\u001b[0mtraining_args.training_model\u001b[33m}\u001b[0m\u001b[33mè®­ç»ƒ \u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 83 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mif\u001b[0m training_args.training_model == \u001b[33m'\u001b[0m\u001b[33mBERT\u001b[0m\u001b[33m'\u001b[0m:                         \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m 84 \u001b[2mâ”‚   â”‚   \u001b[0msingle_task_train(                                             \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 85 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mmodel_args=model_args,                                     \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 86 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mdata_args=data_args,                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 87 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mtraining_args=training_args,                               \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/Desktop/ai/fengx_ai/fengx_ai/train/\u001b[0m\u001b[1;33msingle_task_train_factory.p\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m53\u001b[0m in \u001b[92msingle_task_train\u001b[0m                                                    \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[2m# )\u001b[0m                                                                \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                   \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2mâ”‚   \u001b[0mlogger.info(\u001b[33m\"\u001b[0m\u001b[33m***************** è½½å…¥æ¨¡å‹: åˆ†è¯å™¨; æ¨¡å‹ ************\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m 53 \u001b[2mâ”‚   \u001b[0mprint_source()                                                     \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 54 \u001b[0m\u001b[2mâ”‚   \u001b[0mtokenizer = AutoTokenizer.from_pretrained(                         \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mmodel_args.model_name_or_path,                                 \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0muse_auth_token=model_args.hf_hub_token \u001b[94mif\u001b[0m model_args.hf_hub_to \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/Desktop/ai/fengx_ai/fengx_ai/utils/\u001b[0m\u001b[1;33mprint_utils.py\u001b[0m:\u001b[94m42\u001b[0m in        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[92mprint_source\u001b[0m                                                                 \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m39 \u001b[0m                                                                        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m40 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mprint_source\u001b[0m():                                                     \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m41 \u001b[0m\u001b[2mâ”‚   \u001b[0mprint_cpu_utilization()                                             \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m42 \u001b[2mâ”‚   \u001b[0mprint_gpu_utilization()                                             \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m43 \u001b[0m                                                                        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/Desktop/ai/fengx_ai/fengx_ai/utils/\u001b[0m\u001b[1;33mprint_utils.py\u001b[0m:\u001b[94m16\u001b[0m in        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[92mprint_gpu_utilization\u001b[0m                                                        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m13 \u001b[0mlogger = create_logger()                                                \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m14 \u001b[0m                                                                        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m15 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mprint_gpu_utilization\u001b[0m():                                            \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m16 \u001b[2mâ”‚   \u001b[0mnvmlInit()                                                          \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2mâ”‚   \u001b[0mlogger.info(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mDriver Version: \u001b[0m\u001b[33m{\u001b[0mnvmlSystemGetDriverVersion()\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2mâ”‚   \u001b[0mdeviceCount = nvmlDeviceGetCount()                                  \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(deviceCount):                                        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/\u001b[0m\u001b[1;33mpynvm\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[1;33ml.py\u001b[0m:\u001b[94m1785\u001b[0m in \u001b[92mnvmlInit\u001b[0m                                                        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1782 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mNone\u001b[0m                                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1783 \u001b[0m                                                                      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1784 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mnvmlInit\u001b[0m():                                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1785 \u001b[2mâ”‚   \u001b[0mnvmlInitWithFlags(\u001b[94m0\u001b[0m)                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1786 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mNone\u001b[0m                                                       \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1787 \u001b[0m                                                                      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1788 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_LoadNvmlLibrary\u001b[0m():                                               \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/\u001b[0m\u001b[1;33mpynvm\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[1;33ml.py\u001b[0m:\u001b[94m1768\u001b[0m in \u001b[92mnvmlInitWithFlags\u001b[0m                                               \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1765 \u001b[0m                                                                      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1766 \u001b[0m\u001b[2m## C function wrappers ##\u001b[0m                                             \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1767 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mnvmlInitWithFlags\u001b[0m(flags):                                         \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1768 \u001b[2mâ”‚   \u001b[0m_LoadNvmlLibrary()                                                \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1769 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                  \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1770 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[2m#\u001b[0m                                                                 \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1771 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[2m# Initialize the library\u001b[0m                                          \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/\u001b[0m\u001b[1;33mpynvm\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[1;33ml.py\u001b[0m:\u001b[94m1815\u001b[0m in \u001b[92m_LoadNvmlLibrary\u001b[0m                                                \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1812 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[2m# assume linux\u001b[0m                                \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1813 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0mnvmlLib = CDLL(\u001b[33m\"\u001b[0m\u001b[33mlibnvidia-ml.so.1\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1814 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mOSError\u001b[0m \u001b[94mas\u001b[0m ose:                                \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1815 \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m_nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)    \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1816 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m (nvmlLib == \u001b[94mNone\u001b[0m):                                 \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1817 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m_nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)    \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m1818 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mfinally\u001b[0m:                                                      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/\u001b[0m\u001b[1;33mpynvm\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[1;33ml.py\u001b[0m:\u001b[94m848\u001b[0m in \u001b[92m_nvmlCheckReturn\u001b[0m                                                 \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 845 \u001b[0m                                                                      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 846 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_nvmlCheckReturn\u001b[0m(ret):                                            \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 847 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mif\u001b[0m (ret != NVML_SUCCESS):                                         \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m 848 \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mraise\u001b[0m NVMLError(ret)                                          \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 849 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mreturn\u001b[0m ret                                                        \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 850 \u001b[0m                                                                      \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 851 \u001b[0m\u001b[2m## Function access ##\u001b[0m                                                 \u001b[31mâ”‚\u001b[0m\n",
      "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
      "\u001b[1;91mNVMLError_LibraryNotFound: \u001b[0mNVML Shared Library Not Found\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "# ValkyriaLenneth/longformer_zh\n",
    "# IDEA-CCNL/Erlangshen-MegatronBert-1.3B\n",
    "# severinsimmler/xlm-roberta-longformer-base-16384\n",
    "\n",
    "!python auto_train.py\\\n",
    "     --clone_repo rjx/rjxai-xlm-roberta-test \\\n",
    "     --dataset_name rjx/ai-and-human \\\n",
    "     --index_input sentence1 \\\n",
    "     --max_eval_samples 4 \\\n",
    "     --max_test_samples 4 \\\n",
    "     --max_train_samples 20 \\\n",
    "     --model_max_length 512 \\\n",
    "     --model_name_or_path xlm-roberta-base \\\n",
    "     --task_type text-generation \\\n",
    "     --training_model BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages\n"
     ]
    }
   ],
   "source": [
    "from distutils.sysconfig import get_python_lib\n",
    "\n",
    "print(get_python_lib())\n",
    "# /Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/transformers/optimization.py:398\n",
    "# /Users/ofengx/Desktop/ai/transformers/src/transformers/optimization.py\n",
    "# /Users/ofengx/Desktop/ai/transformers/src/transformers/integrations.py:1552\n",
    "# /Users/ofengx/Desktop/ai/transformers/src/transformers/trainer.py\n",
    "# /Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/torch/nn/modules/module.py\n",
    "# /Users/ofengx/Desktop/ai/transformers/src/transformers/models/auto/auto_factory.py\n",
    "# /Users/ofengx/Desktop/ai/transformers/src/transformers/modeling_utils.py\n",
    "# /Users/ofengx/Desktop/ai/transformers/src/transformers/data/data_collator.py\n",
    "# /Users/ofengx/Desktop/ai/transformers/src/transformers/trainer.py\n",
    "# /Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/torch/nn/modules/module.py\n",
    "# /Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/peft/peft_model.py\n",
    "# /Users/ofengx/Desktop/ai/transformers/src/transformers/models/llama/modeling_llama.py\n",
    "# /Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/pynvml.py:310\n",
    "# /Users/ofengx/.asdf/installs/python/3.8.13/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Couldn't call 'get_role' to get Role ARN from role name fengx to get Role path.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2023-05-19-08-00-07-449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-19 08:00:30 Starting - Starting the training job......\n",
      "2023-05-19 08:01:16 Starting - Preparing the instances for training......\n",
      "2023-05-19 08:02:40 Downloading - Downloading input data\n",
      "2023-05-19 08:02:40 Training - Downloading the training image.....................\n",
      "2023-05-19 08:06:36 Training - Training image download completed. Training in progress...bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2023-05-19 08:06:59,126 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2023-05-19 08:06:59,163 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-05-19 08:06:59,175 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2023-05-19 08:06:59,177 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2023-05-19 08:06:59,503 sagemaker-training-toolkit INFO     Installing module with the following command:\n",
      "/opt/conda/bin/python3.9 -m pip install . -r requirements.txt\n",
      "Processing /opt/ml/code\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torch==1.13.1 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.13.1+cu117)\n",
      "Collecting torchinfo\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.19.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (2.9.0)\n",
      "Collecting wandb\n",
      "Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.0/2.0 MB 38.4 MB/s eta 0:00:00\n",
      "Collecting deepspeed==0.9.2\n",
      "Downloading deepspeed-0.9.2.tar.gz (779 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 779.3/779.3 kB 61.1 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting absl-py\n",
      "Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 126.5/126.5 kB 26.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (1.2.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (3.6.3)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (0.12.2)\n",
      "Collecting triton\n",
      "Downloading triton-2.0.0.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.3 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 63.3/63.3 MB 25.2 MB/s eta 0:00:00\n",
      "Collecting accelerate==0.19.0\n",
      "Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 219.1/219.1 kB 36.9 MB/s eta 0:00:00\n",
      "Collecting functorch==1.13.1\n",
      "Downloading functorch-1.13.1-py2.py3-none-any.whl (2.1 kB)\n",
      "Collecting xformers==0.0.16\n",
      "Downloading xformers-0.0.16-cp39-cp39-manylinux2014_x86_64.whl (50.9 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 50.9/50.9 MB 31.4 MB/s eta 0:00:00\n",
      "Collecting peft==0.2.0\n",
      "Downloading peft-0.2.0-py3-none-any.whl (40 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 40.3/40.3 kB 10.0 MB/s eta 0:00:00\n",
      "Collecting transformers==4.28.1\n",
      "Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.0/7.0 MB 78.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sentencepiece==0.1.97 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 17)) (0.1.97)\n",
      "Collecting evaluate\n",
      "Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 81.4/81.4 kB 13.4 MB/s eta 0:00:00\n",
      "Collecting gradio\n",
      "Downloading gradio-3.31.0-py3-none-any.whl (17.4 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 17.4/17.4 MB 66.2 MB/s eta 0:00:00\n",
      "Collecting tensorboard\n",
      "Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.6/5.6 MB 79.7 MB/s eta 0:00:00\n",
      "Collecting torchview\n",
      "Downloading torchview-0.2.6-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 22)) (0.14.1+cu117)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 23)) (0.13.1+cu117)\n",
      "Collecting graphviz\n",
      "Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 47.0/47.0 kB 12.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-ml-py3\n",
      "Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting bitsandbytes\n",
      "Downloading bitsandbytes-0.38.1-py3-none-any.whl (104.3 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 104.3/104.3 MB 17.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch==1.13.1->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: hjson in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (1.11.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (23.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (5.9.4)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (9.0.0)\n",
      "Requirement already satisfied: pydantic<2.0.0 in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (1.10.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from deepspeed==0.9.2->-r requirements.txt (line 6)) (4.64.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from accelerate==0.19.0->-r requirements.txt (line 12)) (5.4.1)\n",
      "Collecting pyre-extensions==0.0.23\n",
      "Downloading pyre_extensions-0.0.23-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.28.1->-r requirements.txt (line 16)) (0.13.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.28.1->-r requirements.txt (line 16)) (2.28.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.28.1->-r requirements.txt (line 16)) (0.12.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.28.1->-r requirements.txt (line 16)) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.28.1->-r requirements.txt (line 16)) (3.9.0)\n",
      "Collecting typing-inspect\n",
      "Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (11.0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (1.5.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (2023.1.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (0.3.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (3.8.4)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (0.70.14)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 4)) (0.18.0)\n",
      "Collecting pathtools\n",
      "Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (65.6.3)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (3.20.2)\n",
      "Collecting setproctitle\n",
      "Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 184.3/184.3 kB 35.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (8.1.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (1.4.4)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 205.1/205.1 kB 33.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (9.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 9)) (4.38.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.9/site-packages (from triton->-r requirements.txt (line 11)) (3.24.3)\n",
      "Collecting lit\n",
      "Downloading lit-16.0.5.tar.gz (138 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 138.0/138.0 kB 26.8 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fastapi\n",
      "Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 57.0/57.0 kB 14.5 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 224.5/224.5 kB 41.2 MB/s eta 0:00:00\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 50.5/50.5 kB 12.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: markupsafe in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 19)) (2.1.2)\n",
      "Collecting orjson\n",
      "Downloading orjson-3.8.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 137.2/137.2 kB 9.8 MB/s eta 0:00:00\n",
      "Collecting semantic-version\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting aiofiles\n",
      "Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pygments>=2.12.0 in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 19)) (2.14.0)\n",
      "Collecting ffmpy\n",
      "Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting websockets>=10.0\n",
      "Downloading websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 129.7/129.7 kB 25.6 MB/s eta 0:00:00\n",
      "Collecting httpx\n",
      "Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 75.4/75.4 kB 17.3 MB/s eta 0:00:00\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 84.5/84.5 kB 19.1 MB/s eta 0:00:00\n",
      "Collecting uvicorn>=0.14.0\n",
      "Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 58.3/58.3 kB 13.6 MB/s eta 0:00:00\n",
      "Collecting pydub\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting altair>=4.2.0\n",
      "Downloading altair-5.0.0-py3-none-any.whl (477 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 477.4/477.4 kB 58.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from gradio->-r requirements.txt (line 19)) (3.1.2)\n",
      "Collecting python-multipart\n",
      "Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 45.7/45.7 kB 11.7 MB/s eta 0:00:00\n",
      "Collecting gradio-client>=0.2.4\n",
      "Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 288.1/288.1 kB 45.5 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "Downloading google_auth-2.18.1-py2.py3-none-any.whl (178 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178.9/178.9 kB 36.0 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.6/6.6 MB 78.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 20)) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 20)) (2.2.3)\n",
      "Collecting grpcio>=1.48.2\n",
      "Downloading grpcio-1.54.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.1/5.1 MB 85.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 20)) (3.4.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 19)) (4.17.3)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 19)) (0.12.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (2.1.1)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.7/62.7 kB 15.8 MB/s eta 0:00:00\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 20)) (1.26.14)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 20)) (4.7.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 181.3/181.3 kB 35.3 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 20)) (4.13.0)\n",
      "Collecting mdurl~=0.1\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->-r requirements.txt (line 4)) (2022.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.28.1->-r requirements.txt (line 16)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.28.1->-r requirements.txt (line 16)) (2022.12.7)\n",
      "Collecting h11>=0.8\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 58.3/58.3 kB 15.4 MB/s eta 0:00:00\n",
      "Collecting starlette<0.28.0,>=0.27.0\n",
      "Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 67.0/67.0 kB 16.4 MB/s eta 0:00:00\n",
      "Collecting httpcore<0.18.0,>=0.15.0\n",
      "Downloading httpcore-0.17.1-py3-none-any.whl (70 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 70.9/70.9 kB 13.6 MB/s eta 0:00:00\n",
      "Collecting sniffio\n",
      "Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting anyio<5.0,>=3.0\n",
      "Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 80.6/80.6 kB 20.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 20)) (3.13.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 19)) (0.19.3)\n",
      "Collecting uc-micro-py\n",
      "Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 20)) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 151.7/151.7 kB 29.4 MB/s eta 0:00:00\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Building wheels for collected packages: deepspeed, fengx-ai, nvidia-ml-py3, ffmpy, lit, pathtools\n",
      "Building wheel for deepspeed (setup.py): started\n",
      "Building wheel for deepspeed (setup.py): finished with status 'done'\n",
      "Created wheel for deepspeed: filename=deepspeed-0.9.2-py3-none-any.whl size=811225 sha256=3a30fc99d8d48af7df72ac8ff89fe42e3a0eacdc85973e95b7bdd4e8780c8299\n",
      "Stored in directory: /root/.cache/pip/wheels/7a/86/f9/5b6341574584972377c6d55ff5e8fa53c956a39d63a849ffb4\n",
      "Building wheel for fengx-ai (setup.py): started\n",
      "Building wheel for fengx-ai (setup.py): finished with status 'done'\n",
      "Created wheel for fengx-ai: filename=fengx_ai-0.0.1-py3-none-any.whl size=77174 sha256=9f5073777181ecc302565f74a238ef1dddabe08b85cd148cd2b94e76d4210d7f\n",
      "Stored in directory: /tmp/pip-ephem-wheel-cache-r_o_1hiq/wheels/40/03/3a/5f39818cea87b3c154b54d046a775b3da4b8ed9b642b8d50e6\n",
      "Building wheel for nvidia-ml-py3 (setup.py): started\n",
      "Building wheel for nvidia-ml-py3 (setup.py): finished with status 'done'\n",
      "Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=d5592ee7e27447306082d423f91b183bfe78daeca12f1566f19a8431c16d9c94\n",
      "Stored in directory: /root/.cache/pip/wheels/f6/d8/b0/15cfd7805d39250ac29318105f09b1750683387630d68423e1\n",
      "Building wheel for ffmpy (setup.py): started\n",
      "Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=1a74b577d0e603749e2e4b0c2584e6eda9e66c2ed0a482c07d0a2bf92e65e31c\n",
      "Stored in directory: /root/.cache/pip/wheels/91/e2/96/f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
      "Building wheel for lit (setup.py): started\n",
      "Building wheel for lit (setup.py): finished with status 'done'\n",
      "Created wheel for lit: filename=lit-16.0.5-py3-none-any.whl size=88174 sha256=cd3ee4ae5def77e8097d92be9ce801ca8d93a75e16f2a59be8a71decb577ef68\n",
      "Stored in directory: /root/.cache/pip/wheels/d8/3a/a1/643264c1075b22759205027b760e0b1e85d975bfb333eef328\n",
      "Building wheel for pathtools (setup.py): started\n",
      "Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=89cbed29eaaf5c0ac39709f11b7dc01b236ca39065c53673628b759f901d2970\n",
      "Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
      "Successfully built deepspeed fengx-ai nvidia-ml-py3 ffmpy lit pathtools\n",
      "Installing collected packages: pydub, pathtools, nvidia-ml-py3, lit, ffmpy, bitsandbytes, websockets, uc-micro-py, torchview, torchinfo, tensorboard-data-server, sniffio, smmap, setproctitle, sentry-sdk, semantic-version, python-multipart, pyasn1-modules, orjson, oauthlib, mypy-extensions, mdurl, h11, grpcio, graphviz, fengx-ai, docker-pycreds, cachetools, aiofiles, absl-py, uvicorn, typing-inspect, triton, requests-oauthlib, markdown-it-py, linkify-it-py, huggingface-hub, google-auth, gitdb, functorch, deepspeed, anyio, accelerate, transformers, starlette, pyre-extensions, mdit-py-plugins, httpcore, google-auth-oauthlib, GitPython, altair, xformers, wandb, tensorboard, peft, httpx, fastapi, gradio-client, evaluate, gradio\n",
      "Attempting uninstall: huggingface-hub\n",
      "Found existing installation: huggingface-hub 0.12.0\n",
      "Uninstalling huggingface-hub-0.12.0:\n",
      "Successfully uninstalled huggingface-hub-0.12.0\n",
      "Attempting uninstall: deepspeed\n",
      "Found existing installation: deepspeed 0.6.1+06f2048\n",
      "Uninstalling deepspeed-0.6.1+06f2048:\n",
      "Successfully uninstalled deepspeed-0.6.1+06f2048\n",
      "Attempting uninstall: accelerate\n",
      "Found existing installation: accelerate 0.16.0\n",
      "Uninstalling accelerate-0.16.0:\n",
      "Successfully uninstalled accelerate-0.16.0\n",
      "Attempting uninstall: transformers\n",
      "Found existing installation: transformers 4.26.0\n",
      "Uninstalling transformers-4.26.0:\n",
      "Successfully uninstalled transformers-4.26.0\n",
      "Successfully installed GitPython-3.1.31 absl-py-1.4.0 accelerate-0.19.0 aiofiles-23.1.0 altair-5.0.0 anyio-3.6.2 bitsandbytes-0.38.1 cachetools-5.3.0 deepspeed-0.9.2 docker-pycreds-0.4.0 evaluate-0.4.0 fastapi-0.95.2 fengx-ai-0.0.1 ffmpy-0.3.0 functorch-1.13.1 gitdb-4.0.10 google-auth-2.18.1 google-auth-oauthlib-1.0.0 gradio-3.31.0 gradio-client-0.2.5 graphviz-0.20.1 grpcio-1.54.2 h11-0.14.0 httpcore-0.17.1 httpx-0.24.1 huggingface-hub-0.14.1 linkify-it-py-2.0.2 lit-16.0.5 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 mypy-extensions-1.0.0 nvidia-ml-py3-7.352.0 oauthlib-3.2.2 orjson-3.8.12 pathtools-0.1.2 peft-0.2.0 pyasn1-modules-0.3.0 pydub-0.25.1 pyre-extensions-0.0.23 python-multipart-0.0.6 requests-oauthlib-1.3.1 semantic-version-2.10.0 sentry-sdk-1.23.1 setproctitle-1.3.2 smmap-5.0.0 sniffio-1.3.0 starlette-0.27.0 tensorboard-2.13.0 tensorboard-data-server-0.7.0 torchinfo-1.8.0 torchview-0.2.6 transformers-4.28.1 triton-2.0.0.post1 typing-inspect-0.8.0 uc-micro-py-1.0.2 uvicorn-0.22.0 wandb-0.15.3 websockets-11.0.3 xformers-0.0.16\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 23.0 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2023-05-19 08:07:48,393 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2023-05-19 08:07:48,393 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2023-05-19 08:07:48,434 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-05-19 08:07:48,485 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-05-19 08:07:48,535 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-05-19 08:07:48,548 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.8xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"clone_repo\": \"rjx/rjxai-albert-longformer-test\",\n",
      "        \"dataset_name\": \"rjx/ai-and-human-0516\",\n",
      "        \"max_eval_samples\": 4,\n",
      "        \"max_test_samples\": 4,\n",
      "        \"max_train_samples\": 40,\n",
      "        \"model_max_length\": 1024,\n",
      "        \"model_name_or_path\": \"severinsimmler/xlm-roberta-longformer-base-16384\",\n",
      "        \"task_type\": \"text-generation\",\n",
      "        \"training_model\": \"BERT\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.8xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2023-05-19-08-00-07-449\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-249450752701/huggingface-pytorch-training-2023-05-19-08-00-07-449/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"auto_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.8xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.8xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"auto_train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"clone_repo\":\"rjx/rjxai-albert-longformer-test\",\"dataset_name\":\"rjx/ai-and-human-0516\",\"max_eval_samples\":4,\"max_test_samples\":4,\"max_train_samples\":40,\"model_max_length\":1024,\"model_name_or_path\":\"severinsimmler/xlm-roberta-longformer-base-16384\",\"task_type\":\"text-generation\",\"training_model\":\"BERT\"}\n",
      "SM_USER_ENTRY_POINT=auto_train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.p3.8xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=auto_train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=32\n",
      "SM_NUM_GPUS=4\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-west-2-249450752701/huggingface-pytorch-training-2023-05-19-08-00-07-449/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.8xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"clone_repo\":\"rjx/rjxai-albert-longformer-test\",\"dataset_name\":\"rjx/ai-and-human-0516\",\"max_eval_samples\":4,\"max_test_samples\":4,\"max_train_samples\":40,\"model_max_length\":1024,\"model_name_or_path\":\"severinsimmler/xlm-roberta-longformer-base-16384\",\"task_type\":\"text-generation\",\"training_model\":\"BERT\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2023-05-19-08-00-07-449\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-249450752701/huggingface-pytorch-training-2023-05-19-08-00-07-449/source/sourcedir.tar.gz\",\"module_name\":\"auto_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"auto_train.py\"}\n",
      "SM_USER_ARGS=[\"--clone_repo\",\"rjx/rjxai-albert-longformer-test\",\"--dataset_name\",\"rjx/ai-and-human-0516\",\"--max_eval_samples\",\"4\",\"--max_test_samples\",\"4\",\"--max_train_samples\",\"40\",\"--model_max_length\",\"1024\",\"--model_name_or_path\",\"severinsimmler/xlm-roberta-longformer-base-16384\",\"--task_type\",\"text-generation\",\"--training_model\",\"BERT\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_CLONE_REPO=rjx/rjxai-albert-longformer-test\n",
      "SM_HP_DATASET_NAME=rjx/ai-and-human-0516\n",
      "SM_HP_MAX_EVAL_SAMPLES=4\n",
      "SM_HP_MAX_TEST_SAMPLES=4\n",
      "SM_HP_MAX_TRAIN_SAMPLES=40\n",
      "SM_HP_MODEL_MAX_LENGTH=1024\n",
      "SM_HP_MODEL_NAME_OR_PATH=severinsimmler/xlm-roberta-longformer-base-16384\n",
      "SM_HP_TASK_TYPE=text-generation\n",
      "SM_HP_TRAINING_MODEL=BERT\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.9 -m auto_train --clone_repo rjx/rjxai-albert-longformer-test --dataset_name rjx/ai-and-human-0516 --max_eval_samples 4 --max_test_samples 4 --max_train_samples 40 --model_max_length 1024 --model_name_or_path severinsimmler/xlm-roberta-longformer-base-16384 --task_type text-generation --training_model BERT\n",
      "[2023-05-19 08:07:54.969: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "2023-05-19 08:07:54,975 root         INFO     Using NamedTuple = typing._NamedTuple instead.\n",
      "2023-05-19 08:07:55,002 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "python -m bitsandbytes\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117_nocublaslt.so\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /opt/conda/lib/python3.9/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('rjx/ai-and-human-0516')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('arn'), PosixPath('aws'), PosixPath('sagemaker'), PosixPath('training-job/huggingface-pytorch-training-2023-05-19-08-00-07-449'), PosixPath('249450752701'), PosixPath('us-west-2')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/v2/credentials/proxy-580e1ab400af43b5469ee2322c7e9d0e2e5159808081687608515e8b8c9781ed-customer')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('s3'), PosixPath('//sagemaker-us-west-2-249450752701/huggingface-pytorch-training-2023-05-19-08-00-07-449/source/sourcedir.tar.gz')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('4,\"num_neurons\"'), PosixPath('\"/opt/ml/output/intermediate\",\"resource_config\"'), PosixPath('{},\"current_host\"'), PosixPath('[\"homogeneousCluster\"],\"instance_groups_dict\"'), PosixPath('\"auto_train.py\"}'), PosixPath('\"eth0\"},\"user_entry_point\"'), PosixPath('{},\"input_dir\"'), PosixPath('\"ml.p3.8xlarge\"}},\"is_hetero\"'), PosixPath('[],\"distribution_instance_groups\"'), PosixPath('\"sagemaker_pytorch_container.training'), PosixPath('\"/opt/ml/output/data\",\"output_dir\"'), PosixPath('\"/opt/ml/output\",\"output_intermediate_dir\"'), PosixPath('\"rjx/rjxai-albert-longformer-test\",\"dataset_name\"'), PosixPath('\"huggingface-pytorch-training-2023-05-19-08-00-07-449\",\"log_level\"'), PosixPath('{},\"channel_input_dirs\"'), PosixPath('\"algo-1\",\"current_instance_group\"'), PosixPath('[],\"framework_module\"'), PosixPath('null,\"is_smddpmprun_installed\"'), PosixPath('1024,\"model_name_or_path\"'), PosixPath('false,\"is_master\"'), PosixPath('\"algo-1\",\"model_dir\"'), PosixPath('\"eth0\",\"num_cpus\"'), PosixPath('\"/opt/ml/model\",\"module_dir\"'), PosixPath('0,\"output_data_dir\"'), PosixPath('{\"current_group_name\"'), PosixPath('\"ml.p3.8xlarge\",\"distribution_hosts\"'), PosixPath('\"severinsimmler/xlm-roberta-longformer-base-16384\",\"task_type\"'), PosixPath('40,\"model_max_length\"'), PosixPath('\"homogeneousCluster\",\"current_host\"'), PosixPath('main\",\"hosts\"'), PosixPath('\"rjx/ai-and-human-0516\",\"max_eval_samples\"'), PosixPath('\"BERT\"},\"input_config_dir\"'), PosixPath('[\"algo-1\"],\"instance_groups\"'), PosixPath('[\"algo-1\"],\"hyperparameters\"'), PosixPath('\"/opt/ml/input/config\",\"input_data_config\"'), PosixPath('\"s3'), PosixPath('\"homogeneousCluster\",\"instance_type\"'), PosixPath('32,\"num_gpus\"'), PosixPath('\"ml.p3.8xlarge\",\"hosts\"'), PosixPath('\"/opt/ml/input\",\"instance_groups\"'), PosixPath('\"auto_train\",\"network_interface_name\"'), PosixPath('[\"algo-1\"],\"current_instance_type\"'), PosixPath('true,\"job_name\"'), PosixPath('//sagemaker-us-west-2-249450752701/huggingface-pytorch-training-2023-05-19-08-00-07-449/source/sourcedir.tar.gz\",\"module_name\"'), PosixPath('[\"algo-1\"],\"instance_group_name\"'), PosixPath('20,\"master_hostname\"'), PosixPath('\"algo-1\",\"current_instance_type\"'), PosixPath('4,\"max_train_samples\"'), PosixPath('4,\"max_test_samples\"'), PosixPath('true,\"is_modelparallel_enabled\"'), PosixPath('\"homogeneousCluster\",\"current_instance_group_hosts\"'), PosixPath('{\"clone_repo\"'), PosixPath('{\"homogeneousCluster\"'), PosixPath('\"ml.p3.8xlarge\"}],\"network_interface_name\"'), PosixPath('{\"additional_framework_parameters\"'), PosixPath('[{\"hosts\"'), PosixPath('\"text-generation\",\"training_model\"'), PosixPath('{\"hosts\"')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('\"rjx/ai-and-human-0516\",\"max_eval_samples\"'), PosixPath('4,\"max_train_samples\"'), PosixPath('4,\"max_test_samples\"'), PosixPath('1024,\"model_name_or_path\"'), PosixPath('\"BERT\"}'), PosixPath('{\"clone_repo\"'), PosixPath('\"text-generation\",\"training_model\"'), PosixPath('40,\"model_max_length\"'), PosixPath('\"severinsimmler/xlm-roberta-longformer-base-16384\",\"task_type\"'), PosixPath('\"rjx/rjxai-albert-longformer-test\",\"dataset_name\"')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/opt/ml/output/intermediate')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('rjx/rjxai-albert-longformer-test')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/opt/conda/lib/python39.zip')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('[\"--clone_repo\",\"rjx/rjxai-albert-longformer-test\",\"--dataset_name\",\"rjx/ai-and-human-0516\",\"--max_eval_samples\",\"4\",\"--max_test_samples\",\"4\",\"--max_train_samples\",\"40\",\"--model_max_length\",\"1024\",\"--model_name_or_path\",\"severinsimmler/xlm-roberta-longformer-base-16384\",\"--task_type\",\"text-generation\",\"--training_model\",\"BERT\"]')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('severinsimmler/xlm-roberta-longformer-base-16384')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('$(dirname $(which conda))/..')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117_nocublaslt.so...\n",
      "wandb: Currently logged in as: fengx (feng-x). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.15.3\n",
      "wandb: Run data is saved locally in /opt/ml/code/wandb/run-20230519_080805-huggingface-pytorch-training-2023-05-19-08-00-07-449-kh4goq-algo-1\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run huggingface-pytorch-training-2023-05-19-08-00-07-449-kh4goq-algo-1\n",
      "wandb: â­ï¸ View project at https://wandb.ai/feng-x/uncategorized\n",
      "wandb: ğŸš€ View run at https://wandb.ai/feng-x/uncategorized/runs/huggingface-pytorch-training-2023-05-19-08-00-07-449-kh4goq-algo-1\n",
      "2023-05-19 08:08:18,321,321 INFO     139756769101632 MainThread 250 [auto_train.py:32] ************ è½½å…¥å‚æ•° *****************\n",
      "2023-05-19 08:08:18,329,329 INFO     139756769101632 MainThread 250 [auto_train.py:46] ModelArguments(model_name_or_path='severinsimmler/xlm-roberta-longformer-base-16384', model_type='BERT', config_overrides=None, config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True, model_revision='main', use_auth_token=False, torch_dtype=None, low_cpu_mem_usage=False, hf_hub_token='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', write_hf_hub_token='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', task_type='text-generation')\n",
      "2023-05-19 08:08:18,330,330 INFO     139756769101632 MainThread 250 [auto_train.py:47] DataTrainingArguments(dataset_name='rjx/ai-and-human-0516', dataset_config_name=None, train_file=None, validation_file=None, max_train_samples=40, max_eval_samples=4, max_test_samples=4, streaming=False, block_size=None, overwrite_cache=False, validation_split_percentage=5, keep_linebreaks=True, index_input='text', index_output='target')\n",
      "2023-05-19 08:08:18,330,330 INFO     139756769101632 MainThread 250 [auto_train.py:48] FxTrainingArguments(\n",
      "_n_gpu=-1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "clone_repo=rjx/rjxai-albert-longformer-test,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=,\n",
      "deepspeed=None,\n",
      "disable_tqdm=None,\n",
      "do_accelerator=False,\n",
      "do_eval=False,\n",
      "do_predict=True,\n",
      "do_train=True,\n",
      "do_visualization=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=,\n",
      "fsdp_config=None,\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=rjx/rjxai-albert-longformer-test,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=rjx/rjxai-albert-longformer-test/logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=accuracy,\n",
      "model_max_length=1024,\n",
      "mp_parameters=,\n",
      "no_cuda=True,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=/opt/ml/model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=None,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=200,\n",
      "save_strategy=steps,\n",
      "save_total_limit=3,\n",
      "seed=7,\n",
      "sharded_ddp=,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "training_model=BERT,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "2023-05-19 08:08:18,331,331 INFO     139756769101632 MainThread 250 [auto_train.py:50] ************ é…ç½® logging *************\n",
      "2023-05-19 08:08:18,331,331 WARNING  139756769101632 MainThread 250 [auto_train.py:69] Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "2023-05-19 08:08:18,331,331 INFO     139756769101632 MainThread 250 [auto_train.py:73] Training/evaluation parameters FxTrainingArguments(\n",
      "_n_gpu=0,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "clone_repo=rjx/rjxai-albert-longformer-test,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=,\n",
      "deepspeed=None,\n",
      "disable_tqdm=None,\n",
      "do_accelerator=False,\n",
      "do_eval=False,\n",
      "do_predict=True,\n",
      "do_train=True,\n",
      "do_visualization=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=,\n",
      "fsdp_config=None,\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=rjx/rjxai-albert-longformer-test,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=rjx/rjxai-albert-longformer-test/logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=accuracy,\n",
      "model_max_length=1024,\n",
      "mp_parameters=,\n",
      "no_cuda=True,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=/opt/ml/model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=None,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=200,\n",
      "save_strategy=steps,\n",
      "save_total_limit=3,\n",
      "seed=7,\n",
      "sharded_ddp=,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "training_model=BERT,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "2023-05-19 08:08:18,332,332 INFO     139756769101632 MainThread 250 [auto_train.py:75] ************ é‡‡ç”¨BERTè®­ç»ƒç±»å‹ ***********\n",
      "2023-05-19 08:08:18,332,332 INFO     139756769101632 MainThread 250 [single_task_train_factory.py:118] ***************** è½½å…¥æ¨¡å‹: åˆ†è¯å™¨; æ¨¡å‹ *****************\n",
      "2023-05-19 08:08:18,332,332 INFO     139756769101632 MainThread 250 [print_utils.py:34] CPU ä¸ªæ•°: 32\n",
      "2023-05-19 08:08:18,332,332 INFO     139756769101632 MainThread 250 [print_utils.py:35] CPU memory total: 239.85776901245117 GB.\n",
      "2023-05-19 08:08:18,333,333 INFO     139756769101632 MainThread 250 [print_utils.py:36] CPU memory use: 2.360950469970703 GB.\n",
      "2023-05-19 08:08:18,333,333 INFO     139756769101632 MainThread 250 [print_utils.py:37] CPU memory free: 219.11109924316406 GB.\n",
      "2023-05-19 08:08:18,333,333 INFO     139756769101632 MainThread 250 [print_utils.py:38] CPU memory use percent: 1.8 %\n",
      "2023-05-19 08:08:18,333,333 INFO     139756769101632 MainThread 250 [print_utils.py:17] Driver Version: b'525.85.12'\n",
      "2023-05-19 08:08:18,334,334 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 0 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:18,334,334 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:18,334,334 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:18,334,334 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:18,334,334 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 1 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:18,335,335 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:18,335,335 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:18,335,335 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:18,335,335 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 2 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:18,335,335 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:18,335,335 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:18,336,336 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:18,336,336 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 3 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:18,336,336 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:18,336,336 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:18,336,336 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/420 [00:00<?, ?B/s]\n",
      "Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 420/420 [00:00<00:00, 57.3kB/s]\n",
      "Downloading tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]\n",
      "Downloading tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.1M/17.1M [00:00<00:00, 138MB/s]\n",
      "Downloading tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.1M/17.1M [00:00<00:00, 134MB/s]\n",
      "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]\n",
      "Downloading (â€¦)cial_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 50.2kB/s]\n",
      "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]\n",
      "Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 843/843 [00:00<00:00, 438kB/s]\n",
      "Downloading pytorch_model.bin:   0%|          | 0.00/1.25G [00:00<?, ?B/s]\n",
      "Downloading pytorch_model.bin:   2%|â–         | 21.0M/1.25G [00:00<00:08, 146MB/s]\n",
      "Downloading pytorch_model.bin:   4%|â–         | 52.4M/1.25G [00:00<00:05, 219MB/s]\n",
      "Downloading pytorch_model.bin:   8%|â–Š         | 94.4M/1.25G [00:00<00:04, 280MB/s]\n",
      "Downloading pytorch_model.bin:  11%|â–ˆ         | 136M/1.25G [00:00<00:03, 307MB/s]\n",
      "Downloading pytorch_model.bin:  14%|â–ˆâ–        | 178M/1.25G [00:00<00:03, 324MB/s]\n",
      "Downloading pytorch_model.bin:  18%|â–ˆâ–Š        | 220M/1.25G [00:00<00:03, 335MB/s]\n",
      "Downloading pytorch_model.bin:  21%|â–ˆâ–ˆ        | 262M/1.25G [00:00<00:02, 345MB/s]\n",
      "Downloading pytorch_model.bin:  24%|â–ˆâ–ˆâ–       | 304M/1.25G [00:00<00:02, 348MB/s]\n",
      "Downloading pytorch_model.bin:  28%|â–ˆâ–ˆâ–Š       | 346M/1.25G [00:01<00:02, 349MB/s]\n",
      "Downloading pytorch_model.bin:  31%|â–ˆâ–ˆâ–ˆ       | 388M/1.25G [00:01<00:02, 352MB/s]\n",
      "Downloading pytorch_model.bin:  35%|â–ˆâ–ˆâ–ˆâ–      | 430M/1.25G [00:01<00:02, 356MB/s]\n",
      "Downloading pytorch_model.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 472M/1.25G [00:01<00:02, 355MB/s]\n",
      "Downloading pytorch_model.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 514M/1.25G [00:01<00:02, 354MB/s]\n",
      "Downloading pytorch_model.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 556M/1.25G [00:01<00:01, 358MB/s]\n",
      "Downloading pytorch_model.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 598M/1.25G [00:01<00:01, 359MB/s]\n",
      "Downloading pytorch_model.bin:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 640M/1.25G [00:01<00:01, 357MB/s]\n",
      "Downloading pytorch_model.bin:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 682M/1.25G [00:02<00:01, 359MB/s]\n",
      "Downloading pytorch_model.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 724M/1.25G [00:02<00:01, 360MB/s]\n",
      "Downloading pytorch_model.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 765M/1.25G [00:02<00:01, 358MB/s]\n",
      "Downloading pytorch_model.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 807M/1.25G [00:02<00:01, 360MB/s]\n",
      "Downloading pytorch_model.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 849M/1.25G [00:02<00:01, 364MB/s]\n",
      "Downloading pytorch_model.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 891M/1.25G [00:02<00:00, 362MB/s]\n",
      "Downloading pytorch_model.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 933M/1.25G [00:02<00:00, 358MB/s]\n",
      "Downloading pytorch_model.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 975M/1.25G [00:02<00:00, 350MB/s]\n",
      "Downloading pytorch_model.bin:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.02G/1.25G [00:02<00:00, 342MB/s]\n",
      "Downloading pytorch_model.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.06G/1.25G [00:03<00:00, 343MB/s]\n",
      "Downloading pytorch_model.bin:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.10G/1.25G [00:03<00:00, 345MB/s]\n",
      "Downloading pytorch_model.bin:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.14G/1.25G [00:03<00:00, 347MB/s]\n",
      "Downloading pytorch_model.bin:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.18G/1.25G [00:03<00:00, 351MB/s]\n",
      "Downloading pytorch_model.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.23G/1.25G [00:03<00:00, 351MB/s]\n",
      "Downloading pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.25G/1.25G [00:03<00:00, 344MB/s]\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at severinsimmler/xlm-roberta-longformer-base-16384 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at severinsimmler/xlm-roberta-longformer-base-16384 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-05-19 08:08:27,803,803 INFO     139756769101632 MainThread 250 [single_task_train_factory.py:150] model config: LongformerConfig {\n",
      "  \"_name_or_path\": \"severinsimmler/xlm-roberta-longformer-base-16384\",\n",
      "  \"architectures\": [\n",
      "    \"LongformerModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"ai\\u5199\\u7684\",\n",
      "    \"1\": \"\\u4eba\\u7c7b\\u5199\\u7684\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"ai\\u5199\\u7684\": 0,\n",
      "    \"\\u4eba\\u7c7b\\u5199\\u7684\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 16386,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"onnx_export\": false,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.28.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "2023-05-19 08:08:27,803,803 INFO     139756769101632 MainThread 250 [single_task_train_factory.py:155] ************** é¢„å¤„ç†ï¼šæ•°æ®é›† ********************\n",
      "2023-05-19 08:08:27,803,803 INFO     139756769101632 MainThread 250 [print_utils.py:34] CPU ä¸ªæ•°: 32\n",
      "2023-05-19 08:08:27,804,804 INFO     139756769101632 MainThread 250 [print_utils.py:35] CPU memory total: 239.85776901245117 GB.\n",
      "2023-05-19 08:08:27,804,804 INFO     139756769101632 MainThread 250 [print_utils.py:36] CPU memory use: 4.185340881347656 GB.\n",
      "2023-05-19 08:08:27,804,804 INFO     139756769101632 MainThread 250 [print_utils.py:37] CPU memory free: 216.1080207824707 GB.\n",
      "2023-05-19 08:08:27,804,804 INFO     139756769101632 MainThread 250 [print_utils.py:38] CPU memory use percent: 2.6 %\n",
      "2023-05-19 08:08:27,804,804 INFO     139756769101632 MainThread 250 [print_utils.py:17] Driver Version: b'525.85.12'\n",
      "2023-05-19 08:08:27,805,805 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 0 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:27,805,805 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:27,805,805 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:27,805,805 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:27,806,806 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 1 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:27,806,806 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:27,806,806 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:27,806,806 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:27,806,806 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 2 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:27,807,807 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:27,807,807 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:27,807,807 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:27,807,807 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 3 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:27,807,807 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:27,808,808 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:27,808,808 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:27,808,808 WARNING  139756769101632 MainThread 250 [single_task_train_factory.py:56] == åŠ è½½æ•°æ®é›† ===\n",
      "Downloading readme:   0%|          | 0.00/562 [00:00<?, ?B/s]\n",
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 562/562 [00:00<00:00, 691kB/s]\n",
      "05/19/2023 08:08:28 - WARNING - datasets.builder - Using custom data configuration rjx--ai-and-human-0516-80dd0f59ba9e5093\n",
      "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/rjx___parquet/rjx--ai-and-human-0516-80dd0f59ba9e5093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/95.0M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading data:   6%|â–Œ         | 5.75M/95.0M [00:00<00:01, 57.5MB/s]\n",
      "#033[A\n",
      "Downloading data:  14%|â–ˆâ–        | 13.3M/95.0M [00:00<00:01, 67.9MB/s]\n",
      "#033[A\n",
      "Downloading data:  22%|â–ˆâ–ˆâ–       | 21.0M/95.0M [00:00<00:01, 72.0MB/s]\n",
      "#033[A\n",
      "Downloading data:  30%|â–ˆâ–ˆâ–ˆ       | 28.6M/95.0M [00:00<00:00, 73.9MB/s]\n",
      "#033[A\n",
      "Downloading data:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 36.2M/95.0M [00:00<00:00, 74.4MB/s]\n",
      "#033[A\n",
      "Downloading data:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 43.7M/95.0M [00:00<00:00, 74.6MB/s]\n",
      "#033[A\n",
      "Downloading data:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 51.3M/95.0M [00:00<00:00, 75.3MB/s]\n",
      "#033[A\n",
      "Downloading data:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59.1M/95.0M [00:00<00:00, 76.0MB/s]\n",
      "#033[A\n",
      "Downloading data:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 66.8M/95.0M [00:00<00:00, 76.4MB/s]\n",
      "#033[A\n",
      "Downloading data:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 74.6M/95.0M [00:01<00:00, 76.7MB/s]\n",
      "#033[A\n",
      "Downloading data:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 82.3M/95.0M [00:01<00:00, 77.0MB/s]\n",
      "#033[A\n",
      "Downloading data:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90.1M/95.0M [00:01<00:00, 77.2MB/s]\n",
      "#033[A\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95.0M/95.0M [00:01<00:00, 75.1MB/s]\n",
      "Downloading data files:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:03,  1.68s/it]\n",
      "Downloading data:   0%|          | 0.00/11.9M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading data:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6.02M/11.9M [00:00<00:00, 60.2MB/s]\n",
      "#033[A\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.9M/11.9M [00:00<00:00, 67.7MB/s]\n",
      "Downloading data files:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:02<00:01,  1.04s/it]\n",
      "Downloading data:   0%|          | 0.00/11.9M [00:00<?, ?B/s]\n",
      "#033[A\n",
      "Downloading data:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 5.81M/11.9M [00:00<00:00, 58.1MB/s]\n",
      "#033[A\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.9M/11.9M [00:00<00:00, 66.3MB/s]\n",
      "Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.20it/s]\n",
      "Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.05it/s]\n",
      "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 1526.13it/s]\n",
      "Generating train split:   0%|          | 0/72405 [00:00<?, ? examples/s]\n",
      "Generating train split:  28%|â–ˆâ–ˆâ–Š       | 20000/72405 [00:00<00:00, 108166.97 examples/s]\n",
      "Generating train split:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 40000/72405 [00:00<00:00, 124678.36 examples/s]\n",
      "Generating train split:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 60000/72405 [00:00<00:00, 126459.19 examples/s]\n",
      "Generating validation split:   0%|          | 0/9051 [00:00<?, ? examples/s]\n",
      "Generating test split:   0%|          | 0/9051 [00:00<?, ? examples/s]\n",
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/rjx___parquet/rjx--ai-and-human-0516-80dd0f59ba9e5093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 618.23it/s]\n",
      "2023-05-19 08:08:32,929,929 INFO     139756769101632 MainThread 250 [single_task_train_factory.py:63] DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'target'],\n",
      "        num_rows: 72405\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'target'],\n",
      "        num_rows: 9051\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'target'],\n",
      "        num_rows: 9051\n",
      "    })\n",
      "})\n",
      "0%|          | 0/40 [00:00<?, ?ex/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 15386.29ex/s]\n",
      "0%|          | 0/4 [00:00<?, ?ex/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 5314.29ex/s]\n",
      "0%|          | 0/4 [00:00<?, ?ex/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 5331.18ex/s]\n",
      "0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 29.01ba/s]\n",
      "0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 182.00ba/s]\n",
      "0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 146.96ba/s]\n",
      "2023-05-19 08:08:33,093,093 INFO     139756769101632 MainThread 250 [single_task_train_factory.py:95] DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 40\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 4\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 4\n",
      "    })\n",
      "})\n",
      "2023-05-19 08:08:33,094,094 INFO     139756769101632 MainThread 250 [single_task_train_factory.py:96] {'text': ['èƒ½ä¸Šç½‘æ›´ç²¾å½© åº·ä½³42å¯¸æ¶²æ™¶å²æœ«ç‹‚ä¿ƒ\\u3000\\u3000åº·ä½³LC42TS86Nç½‘ç»œæ¶²æ™¶ç”µè§†æ•´ä½“é‡‡ç”¨é»‘è‰²é«˜å…‰ææ–™åˆ¶æˆï¼Œæµç•…çš„æ•´ä½“çº¿æ¡ä½¿å¾—è¿™æ¬¾æ¶²æ™¶ç”µè§†æ›´åŠ çš„å¤§æ°”ã€‚è¯¥æœºè¾¹æ¡†é‡‡ç”¨æ—¶å°šçš„è¶…çª„å¼è®¾è®¡ç†å¿µï¼Œè¾¹æ¡†åšåº¦ä»…ä¸º1.99cmã€‚LOGOä½äºå±å¹•ä¸‹æ–¹æ­£ä¸­çš„ä½ç½®ä¸­è§„ä¸­çŸ©ï¼Œåœ¨LOGOä¸‹æ–¹è®¾æœ‰â€œè§¦æ§å…‰åª’â€æŒ‡ç¤ºç¯ï¼Œå¯æ ¹æ®æ¶ˆè´¹è€…çš„éœ€æ±‚éšæ—¶è°ƒèŠ‚å¼€å¯æˆ–è€…å…³é—­ï¼Œæ›´ä¸ºè¿™æ¬¾æ¶²æ™¶ç”µè§†å¢æ·»äº†æ—¶å°šäº®ä¸½çš„å…ƒç´ ã€‚\\u3000\\u3000åº·ä½³LC42TS86Nç½‘ç»œæ¶²æ™¶ç”µè§†ä¸ä»…åœ¨å¤–è§‚ä¸Šç»™äººæ„Ÿè§‰å¾ˆäº²åˆ‡ï¼Œåœ¨åŠŸèƒ½æ–¹é¢æ‰€è¡¨ç°å‡ºçš„ç‹¬åˆ°ä¹‹å¤„ï¼Œä¹Ÿéå¸¸å…·æœ‰å¸å¼•åŠ›ã€‚å…¶äº§å“æ‰€è®¾è®¡çš„å½±è§†åŠã€éŸ³ä¹å…ã€é“ç…§å§ã€ä¿¡æ¯æ¸¯ã€å¨±ä¹å‡çº§ã€èŠ‚èƒ½ç³»ç»ŸåŠŸèƒ½ï¼Œè®©æ¶ˆè´¹è€…åœ¨äº«å—å¨±ä¹ç”Ÿæ´»çš„åŒæ—¶ï¼Œè¿˜èƒ½èŠ‚çœä¸å°‘ç”µè´¹ã€‚\\xa0\\xa0\\xa0 å¦å¤–ï¼Œé€šè¿‡åº·ä½³LC42TS86Nç½‘ç»œæ¶²æ™¶ç”µè§†è¿˜èƒ½å…¨ç¨‹é«˜æ¸…è¯»å–ï¼Œè§£ç å’Œæ˜¾ç¤º1080Pé«˜æ¸…å½±åƒèµ„æºï¼Œè¿˜èƒ½é€šè¿‡ç½‘ç»œäº’è”ï¼Œè‡ªä¸»æœç´¢ã€ä¸‹è½½è‡ªå·±å–œæ¬¢çš„å½±è§†å¤§ç‰‡ï¼Œæ”¯æŒå¤šä»»åŠ¡å¹¶è¡Œå¤„ç†ï¼Œç•…äº«eæ—¶ä»£çš„ç²¾å½©ã€‚\\u3000\\u3000åœ¨è§†é¢‘æ ¼å¼å…¼å®¹æ–¹é¢ï¼Œåº·ä½³LC42TS86Nç½‘ç»œæ¶²æ™¶ç”µè§†å…¨é«˜æ¸…çš„è¯»å–ã€å­˜å‚¨ã€è§£ç ã€æ˜¾ç¤ºæ¨¡å¼ï¼ŒçœŸæ­£å®ç°å…¨ç¨‹é«˜æ¸…ï¼Œå…·æœ‰æ›´é«˜çš„è§†é¢‘å‹ç¼©æ¯”ã€æ›´é«˜çš„å›¾åƒè´¨é‡ã€æ›´ä½çš„è¯¯ç ç‡ã€æ›´å¿«çš„ä¼ è¾“ç‡ã€æ›´å¼ºçš„ç½‘ç»œé€‚åº”æ€§ã€‚è½»æ¾è¯†åˆ«è§†é¢‘ç¼–ç ï¼Œå„ç§æµåª’ä½“è®¾å¤‡è‡ªç”±æ’­æ”¾ã€‚\\u3000\\u3000ç¼–è¾‘ç‚¹è¯„ï¼šä½œä¸ºæ–°å“ç½‘ç»œç”µè§†ï¼Œåº·ä½³LC42TS86Næ¶²æ™¶ç”µè§†é™¤äº†æ‹¥æœ‰è·å–æ–°é—»ã€è‚¡ç¥¨ã€å¤©æ°”ç­‰èµ„è®¯ï¼Œäº«å—å¾…æœºä¸‹è½½å½±ç‰‡ã€åœ¨çº¿è§‚çœ‹å½±ç‰‡ç­‰åŠŸèƒ½å¤–ï¼Œå…¶é¦–åˆ›é“ç…§å§åŠŸèƒ½ï¼Œå¯ä»¥éšæ—¶éšåœ°é€šè¿‡ç½‘ç»œå®ç°è§†åƒè¿œç¨‹å…±äº«ã€ç…§ç‰‡æµè§ˆç­‰åŠŸèƒ½ï¼Œå¯ä¸äº²æœ‹å¥½å‹å…±äº«é«˜æ¸…ç”Ÿæ´»ï¼Œäº’åŠ¨æ€§å¤§å¤§å¢åŠ ã€‚ç›®å‰ï¼Œåº·ä½³LC42TS86Næ¶²æ™¶ç”µè§†çš„ä¿ƒé”€ä»·æ ¼ä»…7999å…ƒï¼Œéå¸¸å…·æœ‰å¸å¼•åŠ›ï¼Œæ„Ÿå…´è¶£çš„æœ‹å‹ä¸è¦é”™è¿‡ã€‚'], 'label': [1], 'input_ids': [[0, 6, 1580, 167704, 1955, 52479, 6, 22384, 21093, 13023, 104176, 135323, 13288, 27415, 36891, 62532, 6, 22384, 21093, 26943, 13023, 12763, 15276, 839, 10294, 135323, 39069, 41740, 33541, 67329, 1395, 2825, 14077, 6607, 2803, 4, 4695, 86308, 43, 41740, 9005, 7781, 38192, 107257, 135323, 39069, 11391, 43, 189574, 30, 4941, 5312, 14591, 97296, 33541, 117291, 43, 5230, 186239, 5392, 10736, 28609, 4, 14591, 97296, 21549, 2621, 31723, 1064, 418, 5, 5046, 3931, 30, 200203, 35292, 111482, 146015, 3302, 514, 57486, 514, 42709, 514, 145223, 4, 213, 200203, 146015, 175494, 155, 46696, 17154, 2825, 62876, 63, 76858, 36480, 4, 1403, 12568, 23497, 36288, 102537, 204992, 125510, 7363, 146417, 4, 101516, 107257, 135323, 39069, 167109, 274, 117291, 16955, 34344, 43, 54322, 30, 6, 22384, 21093, 26943, 13023, 12763, 15276, 839, 10294, 135323, 39069, 21523, 213, 192179, 575, 4766, 487, 26379, 2165, 18857, 7847, 4, 213, 8588, 7165, 1493, 192469, 43, 26871, 789, 141541, 4, 166229, 7985, 159438, 30, 2413, 5889, 1493, 10736, 43, 150833, 72293, 37, 35766, 34431, 37, 244320, 8988, 4502, 37, 5412, 9994, 37, 23942, 58486, 37, 148231, 8488, 8588, 4, 3933, 23497, 213, 16704, 23942, 2985, 62736, 4, 76530, 197056, 19392, 8312, 14479, 30, 81977, 4, 4511, 22384, 21093, 26943, 13023, 12763, 15276, 839, 10294, 135323, 39069, 76530, 130785, 167693, 23927, 5226, 4, 6006, 39453, 264, 21662, 168630, 683, 167693, 78722, 14641, 4, 76530, 4511, 10294, 30588, 16356, 4, 41774, 63449, 37, 51972, 1652, 14999, 43, 150833, 573, 5143, 4, 7499, 1288, 23906, 2672, 2003, 15635, 4, 86308, 68224, 13, 144750, 52479, 30, 6376, 23537, 92905, 26646, 17707, 7165, 4, 22384, 21093, 26943, 13023, 12763, 15276, 839, 10294, 135323, 39069, 2476, 167693, 43, 23927, 5226, 37, 165497, 37, 6006, 39453, 37, 21662, 12250, 4, 20357, 10725, 130785, 167693, 4, 7985, 162309, 23537, 226160, 2615, 37, 162309, 196409, 13723, 37, 1955, 4814, 43, 56356, 39453, 5133, 37, 155132, 43, 226881, 5133, 37, 1955, 6710, 43, 10294, 58397, 1278, 30, 85905, 126858, 23537, 30862, 39453, 4, 20456, 4695, 16477, 13494, 12422, 57987, 30, 6, 90157, 2391, 32219, 12, 7408, 126435, 10294, 39069, 4, 22384, 21093, 26943, 13023, 12763, 15276, 839, 135323, 39069, 8502, 15049, 95579, 21606, 37, 50653, 37, 70871, 844, 144343, 4, 16704, 15768, 5312, 51972, 24504, 37, 36542, 113064, 24504, 844, 8588, 1998, 4, 2413, 6342, 27638, 244320, 8988, 4502, 8588, 4, 1441, 102537, 25572, 955, 4511, 10294, 10725, 18646, 5483, 203554, 52611, 37, 20552, 181299, 844, 8588, 4, 1403, 1189, 18857, 182529, 81070, 52611, 167693, 2985, 4, 95444, 1278, 55431, 10161, 30, 4696, 4, 22384, 21093, 26943, 13023, 12763, 15276, 839, 135323, 39069, 43, 62532, 29906, 16806, 31723, 966, 65040, 2954, 4, 4528, 7985, 159438, 4, 123701, 32477, 7402, 175175, 30, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n",
      "2023-05-19 08:08:33,096,096 INFO     139756769101632 MainThread 250 [single_task_train_factory.py:97] input_ids len = 1024\n",
      "2023-05-19 08:08:33,097,097 INFO     139756769101632 MainThread 250 [single_task_train_factory.py:98] attention_mask len = 1024\n",
      "2023-05-19 08:08:33,098,098 INFO     139756769101632 MainThread 250 [single_task_train_factory.py:164] *************** 8-bit Adam é™ä½å†…å­˜æ¶ˆè€— **************\n",
      "2023-05-19 08:08:33,098,098 INFO     139756769101632 MainThread 250 [print_utils.py:34] CPU ä¸ªæ•°: 32\n",
      "2023-05-19 08:08:33,098,098 INFO     139756769101632 MainThread 250 [print_utils.py:35] CPU memory total: 239.85776901245117 GB.\n",
      "2023-05-19 08:08:33,099,099 INFO     139756769101632 MainThread 250 [print_utils.py:36] CPU memory use: 4.285392761230469 GB.\n",
      "2023-05-19 08:08:33,099,099 INFO     139756769101632 MainThread 250 [print_utils.py:37] CPU memory free: 215.72257232666016 GB.\n",
      "2023-05-19 08:08:33,099,099 INFO     139756769101632 MainThread 250 [print_utils.py:38] CPU memory use percent: 2.6 %\n",
      "2023-05-19 08:08:33,099,099 INFO     139756769101632 MainThread 250 [print_utils.py:17] Driver Version: b'525.85.12'\n",
      "2023-05-19 08:08:33,099,099 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 0 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:33,100,100 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:33,100,100 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:33,100,100 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:33,100,100 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 1 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:33,100,100 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:33,101,101 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:33,101,101 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:33,101,101 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 2 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:33,101,101 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:33,101,101 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:33,102,102 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:33,102,102 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 3 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:33,102,102 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:33,102,102 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:33,102,102 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:33,103,103 INFO     139756769101632 MainThread 250 [single_task_train_factory.py:229] ************** ä½¿ç”¨ Trainer æ„å»ºè®­ç»ƒç¯å¢ƒ, å¹¶è¿›è¡Œè®­ç»ƒ ******************\n",
      "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]\n",
      "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.20k/4.20k [00:00<00:00, 4.42MB/s]\n",
      "2023-05-19 08:08:33,701,701 INFO     139756769101632 MainThread 250 [print_utils.py:34] CPU ä¸ªæ•°: 32\n",
      "2023-05-19 08:08:33,701,701 INFO     139756769101632 MainThread 250 [print_utils.py:35] CPU memory total: 239.85776901245117 GB.\n",
      "2023-05-19 08:08:33,701,701 INFO     139756769101632 MainThread 250 [print_utils.py:36] CPU memory use: 4.277103424072266 GB.\n",
      "2023-05-19 08:08:33,701,701 INFO     139756769101632 MainThread 250 [print_utils.py:37] CPU memory free: 215.73040390014648 GB.\n",
      "2023-05-19 08:08:33,702,702 INFO     139756769101632 MainThread 250 [print_utils.py:38] CPU memory use percent: 2.6 %\n",
      "2023-05-19 08:08:33,702,702 INFO     139756769101632 MainThread 250 [print_utils.py:17] Driver Version: b'525.85.12'\n",
      "2023-05-19 08:08:33,702,702 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 0 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:33,702,702 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:33,703,703 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:33,703,703 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:33,703,703 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 1 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:33,703,703 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:33,703,703 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:33,704,704 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:33,704,704 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 2 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:33,704,704 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:33,704,704 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:33,704,704 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "2023-05-19 08:08:33,705,705 INFO     139756769101632 MainThread 250 [print_utils.py:21] Device 3 : b'Tesla V100-SXM2-16GB'\n",
      "2023-05-19 08:08:33,705,705 INFO     139756769101632 MainThread 250 [print_utils.py:23] GPU memory total(æ€»å…±): 16.0 GB.\n",
      "2023-05-19 08:08:33,705,705 INFO     139756769101632 MainThread 250 [print_utils.py:24] GPU memory occupied(å ç”¨): 0.2310791015625 GB.\n",
      "2023-05-19 08:08:33,705,705 INFO     139756769101632 MainThread 250 [print_utils.py:25] GPU memory free(å¯ç”¨): 15.7689208984375 GB.\n",
      "0%|          | 0/40 [00:00<?, ?it/s]\n",
      "[2023-05-19 08:08:33.830: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "05/19/2023 08:08:33 - INFO - root - Using NamedTuple = typing._NamedTuple instead.\n",
      "[2023-05-19 08:08:33.866 algo-1:250 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-05-19 08:08:33.892 algo-1:250 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2023-05-19 08:08:33.893 algo-1:250 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2023-05-19 08:08:33.893 algo-1:250 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2023-05-19 08:08:33.894 algo-1:250 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[2023-05-19 08:08:33.894 algo-1:250 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "2%|â–         | 1/40 [12:08<7:53:40, 728.72s/it]\n",
      "[W kineto_shim.cpp:330] Profiler is not initialized: skipping step() invocation\n",
      "5%|â–Œ         | 2/40 [24:14<7:40:33, 727.20s/it]\n",
      "[W kineto_shim.cpp:330] Profiler is not initialized: skipping step() invocation\n",
      "8%|â–Š         | 3/40 [36:20<7:27:53, 726.31s/it]\n",
      "[W kineto_shim.cpp:330] Profiler is not initialized: skipping step() invocation\n",
      "10%|â–ˆ         | 4/40 [48:25<7:15:34, 725.96s/it]\n",
      "12%|â–ˆâ–        | 5/40 [1:00:31<7:03:33, 726.10s/it]\n",
      "STAGE:2023-05-19 09:09:05 250:250 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n"
     ]
    }
   ],
   "source": [
    "from assisted_intelligence.ml.hf_sagemaker import HfSagemaker\n",
    "\n",
    "ml=HfSagemaker(\n",
    "    # è¾“å…¥è‡ªå·±çš„ sagemaker è§’è‰²\n",
    "    sagemaker_role_name=\"fx_sagemaker_20230419\",\n",
    "    # è®¾å®š sagemaker è®­ç»ƒæœºå™¨\n",
    "    sagemaker_config={\n",
    "        'instance_type': 'ml.p3.8xlarge',\n",
    "        # 'instance_type': 'ml.p3.16xlarge',\n",
    "        # 'instance_type': 'ml.p3dn.24xlarge',\n",
    "        'instance_count': 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "ml.play(\n",
    "    config={\n",
    "        # è®­ç»ƒç±»å‹ï¼Œç›®å‰åªæœ‰ä¸¤ç§è®­ç»ƒç±»å‹ BERT and LLAMA\n",
    "        'training_model': 'BERT',\n",
    "        'clone_repo': 'rjx/rjxai-albert-longformer-test',\n",
    "        'model_name_or_path':'severinsimmler/xlm-roberta-longformer-base-16384',\n",
    "        'dataset_name': 'rjx/ai-and-human-0516',\n",
    "        'model_max_length': 1024,\n",
    "        'task_type': 'text-generation',\n",
    "        'max_train_samples': 40,\n",
    "        'max_eval_samples': 4,\n",
    "        'max_test_samples': 4,\n",
    "    }, \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
