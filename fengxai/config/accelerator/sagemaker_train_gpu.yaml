base_job_name: example-training-v1
distributed_type: 'NO'
compute_environment: AMAZON_SAGEMAKER
region: us-west-2
iam_role_name: sagemaker_ap-southeast-2
ec2_instance_type: ml.g5.2xlarge
# ml.g4dn.8xlarge  1个GPU16G  费用$2.72/h             
# ml.g4dn.12xlarge 4个GPU16G  费用$4.89/h   配额?
# ml.p3.8xlarge    4个GPU16G  费用$14/h     配额4
# ml.p3.2xlarge    1个GPU16G  费用$3.825/h  配额?
# ml.g5n.xlarge    
# ml.g5.2xlarge    1个GPU24G  费用$1.624/h
# ml.g5.4xlarge    1个GPU24G  费用$1.624/h
# ml.g5.12xlarge   4个GPU24G  费用$5.672    (比ml.g4dn.12xlarge快了20分钟左右)
profile: default
num_machines: 1
mixed_precision: bf16
# image_uri: 763104351884.dkr.ecr.ap-southeast-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04
image_uri: 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:1.13.1-transformers4.26.0-gpu-py39-cu117-ubuntu20.04
# py_version: py39
# pytorch_version: 1.13.1
# transformers_version: 4.26.0
# image_uri: null
use_cpu: false
