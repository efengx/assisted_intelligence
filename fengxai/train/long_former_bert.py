import torch
import numpy as np
import evaluate
import logging
import sys
import os
# TODO: åç»­å¯ä»¥è€ƒè™‘ä½¿ç”¨ transformers ä¸­çš„æ–¹æ³•æ›¿ä»£æ‰ï¼Œå‡å°‘é¢å¤–çš„ä¾èµ–
import time
import graphviz

from transformers import (
    MegatronBertConfig, 
    MegatronBertModel,
    BertTokenizer,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    AutoModelForSequenceClassification,
    TrainerCallback,
    PreTrainedTokenizer
)
from datasets import (
    load_dataset
)
from huggingface_hub import (
    create_repo,
    HfApi,
)
from torch.utils.tensorboard import SummaryWriter
from torchview import draw_graph
from datetime import datetime
from fengxai.utils.log_center import create_logger

# logger = logging.getLogger(__name__)
logger = create_logger()

class ProfCallback(TrainerCallback):
    """
    æ¨ç†å›è°ƒ
    """
    def __init__(self, prof):
        self.prof = prof

    def on_step_end(self, args, state, control, **kwargs):
        self.prof.step()

def build_dataset(
        tokenizer: PreTrainedTokenizer,
        data_args,
        model_args,
        model_max_length: int=1024,
    ):
    """
    ä¸‹è½½å¹¶ç»„è£…æ•°æ®é›†
    """
    logger.warning("== åŠ è½½æ•°æ®é›† ===")
    raw_dataset=load_dataset(
        data_args.dataset_name, 
        use_auth_token=model_args.hf_hub_token if model_args.hf_hub_token else None,
    )
    logger.info(raw_dataset)

    raw_dataset["train"]=raw_dataset['train'].select(range(2))
    raw_dataset["validation"]=raw_dataset['validation'].select(range(2))
    raw_dataset["test"]=raw_dataset['test'].select(range(2))

    def format_dataset(example):
        if example["target"] == "äººç±»å†™çš„":
            example["label"] = 1
        elif example["target"] == "aiå†™çš„":
            example["label"] = 0
        else:
            logger.error("æ— æ•ˆçš„target")
        logger.info(example)
        return example
    format_dataset = raw_dataset.map(
        format_dataset,
        remove_columns="target"
    )
    logger.info(raw_dataset)
    logger.info(raw_dataset["train"][:1])

    def tokenizer_fun(example):
        return tokenizer(
            example["text"],
            max_length=model_max_length,
            padding="max_length",
            truncation=True,
        )
    tokenized_dataset = format_dataset.map(tokenizer_fun, batched=True)
    logger.info(tokenized_dataset)
    logger.info(tokenized_dataset["train"][:1])

    logger.info(f"input_ids len = {len(tokenized_dataset['train'][:1]['input_ids'][0])}")
    logger.info(f"attention_mask len = {len(tokenized_dataset['train'][:1]['attention_mask'][0])}")
    
    return tokenized_dataset

def long_former_bert_train(
        model_args, data_args, training_args    
    ):
    ndt=datetime.now()

    if not os.path.exists(f"{training_args.clone_repo}/logs"):
        os.makedirs(f"{training_args.clone_repo}/logs")
    logging.basicConfig(
        # æ—¥å¿—é…ç½®
        level=logging.INFO,
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler(f"{training_args.clone_repo}/logs/training-{ndt.year}{ndt.month:02d}{ndt.day}.log")
        ],
        format="%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s",
    )

    logger.info("***************** è½½å…¥æ¨¡å‹: åˆ†è¯å™¨; æ¨¡å‹ *****************")
    tokenizer = BertTokenizer.from_pretrained(
        model_args.model_name_or_path,
        use_auth_token=model_args.hf_hub_token if model_args.hf_hub_token and model_args.use_auth_token else None,
    )

    # id2labelåœ¨å¼€å§‹è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œä½¿ç”¨å’Œåˆ›å»ºé¢„æœŸ ID åˆ°å…¶æ ‡ç­¾çš„æ˜ å°„label2idï¼š
    id2label = {0: "AI write", 1: "Human write"}
    label2id = {"AI write": 0, "Human write": 1}
    """
    AutoModelForSequenceClassification ç±»åŠ è½½ DistilBertForSequenceClassification ç±»ä½œä¸ºåŸºç¡€æ¨¡å‹ã€‚ 
    ç”±äº AutoModelForSequenceClassification ä¸æ¥å—å‚æ•°â€œnum_labelsâ€ï¼Œ
    å®ƒè¢«ä¼ é€’ç»™æ¥å—å®ƒçš„åŸºç¡€ç±» DistilBertForSequenceClassificationã€‚
    
    to("cuda") è¡¨ç¤ºä½¿ç”¨ gpu åŠ è½½
    """
    # LongformerZhForMaksedLM.from_pretrained('ValkyriaLenneth/longformer_zh')
    # model = MegatronBertModel.from_pretrained(
    #     model_args.model_name_or_path,
    #     # å¿…é¡»çš„ï¼Œä½œç”¨ï¼šæ›¿æ¢æ‰åŸæ¥çš„æ¨¡å‹çš„åˆ†ç±»å¤´éƒ¨ï¼Œæ ¹æ®è®­ç»ƒçš„æ•°æ®é›†é‡æ–°ç”Ÿæˆæ–°çš„äºŒåˆ†ç±»å¤´éƒ¨
    #     num_labels=2,
    #     id2label=id2label,
    #     label2id=label2id
    # )

    model=AutoModelForSequenceClassification.from_pretrained(
        model_args.model_name_or_path,
        # å¿…é¡»çš„ï¼Œä½œç”¨ï¼šæ›¿æ¢æ‰åŸæ¥çš„æ¨¡å‹çš„åˆ†ç±»å¤´éƒ¨ï¼Œæ ¹æ®è®­ç»ƒçš„æ•°æ®é›†é‡æ–°ç”Ÿæˆæ–°çš„äºŒåˆ†ç±»å¤´éƒ¨
        num_labels=2,
        id2label=id2label,
        label2id=label2id,
        use_auth_token=model_args.hf_hub_token if model_args.hf_hub_token and model_args.use_auth_token else None,
    )
    logger.info(f"model config: {model.config}")

    logger.info("************** é¢„å¤„ç†ï¼šæ•°æ®é›† ********************")
    datasets = build_dataset(
        tokenizer=tokenizer,
        data_args=data_args,
        model_args=model_args,
        model_max_length=training_args.model_max_length
    )

    logger.info("************** æ„å»ºè®­ç»ƒç¯å¢ƒ, å¹¶è¿›è¡Œè®­ç»ƒ *****************************")
    """
    æˆ‘ä»¬æƒ³åœ¨è®­ç»ƒæœŸé—´è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚ Trainer é€šè¿‡æä¾› compute_metrics æ¥æ”¯æŒè®­ç»ƒæœŸé—´çš„è¯„ä¼°ã€‚
    è¯„ä¼°æ‘˜è¦ä»»åŠ¡æœ€å¸¸ç”¨çš„æŒ‡æ ‡æ˜¯ rogue_scoreï¼Œæ˜¯é¢å‘å¬å›çš„ Understudy for Gisting Evaluation çš„ç¼©å†™ï¼‰ã€‚ 
    è¯¥æŒ‡æ ‡çš„è¡Œä¸ºä¸æ ‡å‡†å‡†ç¡®åº¦ä¸åŒï¼šå®ƒå°†ç”Ÿæˆçš„æ‘˜è¦ä¸ä¸€ç»„å‚è€ƒæ‘˜è¦è¿›è¡Œæ¯”è¾ƒ
    """
    # Metric
    metric=evaluate.load("accuracy")
    # å°†åœ¨æ•´ä¸ªé¢„æµ‹/æ ‡ç­¾æ•°ç»„çš„æ¯ä¸ªè¯„ä¼°é˜¶æ®µç»“æŸæ—¶è°ƒç”¨çš„å‡½æ•°ï¼Œä»¥ç”ŸæˆæŒ‡æ ‡ã€‚
    def compute_metrics(eval_pred):
        # é¢„æµ‹å’Œæ ‡ç­¾è¢«åˆ†ç»„åœ¨ä¸€ä¸ªåä¸º EvalPrediction çš„å‘½åå…ƒç»„ä¸­
        logits, labels = eval_pred
        # è·å–é¢„æµ‹åˆ†æ•°æœ€é«˜çš„ç´¢å¼•ï¼ˆå³é¢„æµ‹æ ‡ç­¾ï¼‰
        predictions = np.argmax(logits, axis=1)
        # å°†é¢„æµ‹æ ‡ç­¾ä¸å‚è€ƒæ ‡ç­¾è¿›è¡Œæ¯”è¾ƒ
        results = metric.compute(predictions=predictions, references=labels)
        # ç»“æœï¼šä¸€ä¸ªåŒ…å«å­—ç¬¦ä¸²é”®ï¼ˆæŒ‡æ ‡åç§°ï¼‰å’Œæµ®ç‚¹æ•°çš„å­—å…¸
        # å€¼ï¼ˆå³æŒ‡æ ‡å€¼ï¼‰
        return results

    # Create Trainer instance
    # åˆ›å»º Trainer å®ä¾‹
    trainer=Trainer(
        model=model,
        args=training_args,
        train_dataset=datasets["train"],
        eval_dataset=datasets["validation"],
        tokenizer=tokenizer,
        compute_metrics=compute_metrics
    )

    # åˆå§‹åŒ–æ—¶é—´ï¼Œç”¨äºè®¡ç®—è®­ç»ƒæ‰€ç”¨æ—¶é—´
    start = time.perf_counter()
    # å¼€å¯pytorch profileç”¨äºç›‘æ§æ¨¡å‹æ€§èƒ½ï¼Œé€šè¿‡ tensorboard è¿›è¡ŒæŸ¥çœ‹
    with torch.profiler.profile(
        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA], 
        schedule=torch.profiler.schedule(skip_first=3, wait=1, warmup=1, active=2, repeat=2),
        # æ–‡ä»¶ä¿å­˜è·¯å¾„ï¼Œé€šè¿‡ tensorboard è¿›è¡ŒæŸ¥çœ‹
        on_trace_ready=torch.profiler.tensorboard_trace_handler(f"{training_args.clone_repo}/logs/resnet"),
        profile_memory=True,
        with_stack=True,
        record_shapes=True
    ) as prof:
        trainer.add_callback(ProfCallback(prof=prof))
        trainer.train()

    # å¼€å§‹è®­ç»ƒ
    # trainer.train()
    # å¾ˆå¥½ï¼Œæˆ‘ä»¬å·²ç»è®­ç»ƒäº†æˆ‘ä»¬çš„æ¨¡å‹ã€‚ ğŸ‰è®©æˆ‘ä»¬åœ¨æµ‹è¯•é›†ä¸Šå†æ¬¡è¯„ä¼°æœ€ä½³æ¨¡å‹ã€‚
    trainer.evaluate()

    # ä¿å­˜æˆ‘ä»¬çš„åˆ†è¯å™¨å¹¶åˆ›å»ºæ¨¡å‹å¡
    logger.info(training_args.clone_repo)
    tokenizer.save_pretrained(training_args.clone_repo)
    # å­˜åœ¨è¶…å‚æ•°æ ¼å¼é—®é¢˜ AttributeError: 'str' object has no attribute 'value' 
    # for hyperparameters["lr_scheduler_type"] = trainer.args.lr_scheduler_type.value
    # trainer.create_model_card()
    # ä¿å­˜æ¨¡å‹
    trainer.save_model(training_args.clone_repo)
    num=model.num_parameters()
    logger.info(num)


    logger.info("********* è¯»å–æ¨¡å‹ç»“æ„å¹¶ä¿å­˜ ****************")
    # æ˜¾ç¤ºæ¨¡å‹
    encoding_input=tokenizer(
        datasets["test"][0]["text"],
        return_tensors="pt"
    )
    # è®¾ç½®æ¨¡å‹çš„ä¿å­˜æ ¼å¼ä¸ºpng
    graphviz.set_jupyter_format('png')
    # ç”Ÿæˆæ¨¡å‹ç»“æ„
    model_graph=draw_graph(
        model, 
        input_data=encoding_input, 
        save_graph=True
    )
    visual_graph=model_graph.visual_graph
    logger.info(visual_graph)
    visual_graph.render(filename=f"{training_args.clone_repo}/logs/model_png")

    logger.info(datasets["test"][0]["text"])
    logger.info(encoding_input)
    logger.info(encoding_input.input_ids.numpy())
    logger.info(encoding_input.input_ids.numpy().shape)
    logger.info(encoding_input.input_ids.numpy().ndim)
    # å°† encoding_input è½¬æ¢å›æ–‡æœ¬
    tokens=tokenizer.convert_ids_to_tokens(encoding_input.input_ids.numpy()[0])
    logger.info(tokens)
    # å°†æ–‡æœ¬è½¬æ¢æˆids
    ids=tokenizer.convert_tokens_to_ids(tokens)
    logger.info(ids)

    # è¯¥ä»£ç çš„æœ¬æ¥ç›®çš„æ˜¯è·å–æ¨¡å‹ç»“æ„ï¼Œä½†æ˜¯ç›®å‰æ— æ³•ä¸ huggingface è¿›è¡Œæ•´åˆ
    # tb_writer=SummaryWriter(log_dir=f"{training_args.clone_repo}/logs/rjxai_graph")
    # tb_writer.add_graph(model, encoding_input)


    logger.info("************ è¯„ä¼°æ¨¡å‹ ***********************")
    # è¿è¡Œæ¨ç†
    # eval_result = trainer.evaluate(eval_dataset=tokenized_dataset["test"])
    # logger.info(eval_result)
    # # å°†è¯„ä¼°ç»“æœå†™å…¥æ–‡ä»¶ï¼Œç¨åå¯ä»¥åœ¨ s3 è¾“å‡ºä¸­è®¿é—®è¯¥æ–‡ä»¶
    # with open(os.path.join(f"{repository_id}/logs", "eval_results.txt"), "w") as writer:
    #     print(f"***** Eval results *****")
    #     for key, value in sorted(eval_result.items()):
    #         writer.write(f"{key} = {value}\n")
    
    # æŸ¥çœ‹æµ‹è¯•é›†å¤§å°
    logger.debug(datasets["test"])
    # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
    test_prediction = trainer.predict(datasets["test"])
    # å¯¹äºæ¯ä¸ªé¢„æµ‹ï¼Œä½¿ç”¨ argmax åˆ›å»ºæ ‡ç­¾ï¼ˆè·å–ç¬¬ä¸€åˆ—çš„æ ‡ç­¾ï¼‰
    test_predictions_argmax = np.argmax(test_prediction[0], axis=1)
    # ä»æµ‹è¯•é›†ä¸­æ£€ç´¢å‚è€ƒæ ‡ç­¾
    test_references=np.array(datasets["test"]["label"])
    # è®¡ç®—ç²¾åº¦
    results = metric.compute(predictions=test_predictions_argmax, references=test_references)
    logger.info(results)


    logger.info("******* ä¿å­˜æ¨¡å‹ huggingface hub ********")
    # ä¿å­˜åˆ° huggingface
    # TODOï¼šå»¶è¿Ÿä¿å­˜ä¼šå­˜åœ¨å¤¸å¤©è®­ç»ƒæ— æ³•ä¿å­˜çš„é—®é¢˜ï¼ˆè¯¥æœºåˆ¶æœ‰å¾…è¿›ä¸€æ­¥å®Œå–„ï¼‰
    hf_host="https://huggingface.co"
    # ä¸Šä¼ æœ€æ–°çš„æ¨¡å‹åˆ°å­˜å‚¨åº“
    logger.info("*** save model hub ***")
    api=HfApi()
    list_models=api.list_models(
        search=training_args.clone_repo, 
        token=model_args.hf_hub_token
    )
    if len(list_models) == 0:
        # åˆ›å»ºè¿œç¨‹å­˜å‚¨åº“ï¼ˆåç»­åˆ¤æ–­æ˜¯å¦éœ€è¦ï¼Ÿï¼‰
        create_repo(
            training_args.clone_repo, 
            private=True,
            token=model_args.write_hf_hub_token
        )
    else:
        logger.info(list_models[0])

    # æµ‹è¯•ä½¿ç”¨ä¸Šé¢çš„ä¿å­˜æŸ¥çœ‹æ•ˆæœ
    # ä¸Šä¼ ç›®å½•ä¸‹çš„æ–‡ä»¶åˆ°å­˜å‚¨åº“
    logger.info(f"folder_path:{training_args.clone_repo}")
    list_dir=os.listdir(training_args.clone_repo)
    logger.info(list_dir)
    api.upload_folder(
        folder_path=training_args.clone_repo,
        repo_id=training_args.clone_repo,
        token=model_args.write_hf_hub_token
    )
    # æŸ¥è¯¢å­˜å‚¨åº“å¹¶æ‰“å°(å†…å®¹)
    logger.info(f"{hf_host}/{training_args.clone_repo}")

if __name__ == "__main__":
    long_former_bert_train()